{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections.abc\n",
    "import functools\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import numpy.core.numeric as _nx\n",
    "from numpy.core import transpose\n",
    "from numpy.core.numeric import (\n",
    "    ones, zeros, arange, concatenate, array, asarray, asanyarray, empty,\n",
    "    ndarray, around, floor, ceil, take, dot, where, intp,\n",
    "    integer, isscalar, absolute\n",
    "    )\n",
    "from numpy.core.umath import (\n",
    "    pi, add, arctan2, frompyfunc, cos, less_equal, sqrt, sin,\n",
    "    mod, exp, not_equal, subtract\n",
    "    )\n",
    "from numpy.core.fromnumeric import (\n",
    "    ravel, nonzero, partition, mean, any, sum\n",
    "    )\n",
    "from numpy.core.numerictypes import typecodes\n",
    "from numpy.core.overrides import set_module\n",
    "from numpy.core import overrides\n",
    "from numpy.core.function_base import add_newdoc\n",
    "from numpy.lib.twodim_base import diag\n",
    "from numpy.core.multiarray import (\n",
    "    _insert, add_docstring, bincount, normalize_axis_index, _monotonicity,\n",
    "    interp as compiled_interp, interp_complex as compiled_interp_complex\n",
    "    )\n",
    "from numpy.core.umath import _add_newdoc_ufunc as add_newdoc_ufunc\n",
    "\n",
    "import builtins\n",
    "\n",
    "# needed in this module for compatibility\n",
    "from numpy.lib.histograms import histogram, histogramdd\n",
    "\n",
    "\n",
    "array_function_dispatch = functools.partial(\n",
    "    overrides.array_function_dispatch, module='numpy')\n",
    "\n",
    "\n",
    "__all__ = [\n",
    "    'select', 'piecewise', 'trim_zeros', 'copy', 'iterable', 'percentile',\n",
    "    'diff', 'gradient', 'angle', 'unwrap', 'sort_complex', 'disp', 'flip',\n",
    "    'rot90', 'extract', 'place', 'vectorize', 'asarray_chkfinite', 'average',\n",
    "    'bincount', 'digitize', 'cov', 'corrcoef',\n",
    "    'msort', 'median', 'sinc', 'hamming', 'hanning', 'bartlett',\n",
    "    'blackman', 'kaiser', 'trapz', 'i0', 'add_newdoc', 'add_docstring',\n",
    "    'meshgrid', 'delete', 'insert', 'append', 'interp', 'add_newdoc_ufunc',\n",
    "    'quantile'\n",
    "    ]\n",
    "\n",
    "\n",
    "def _rot90_dispatcher(m, k=None, axes=None):\n",
    "    return (m,)\n",
    "\n",
    "\n",
    "@array_function_dispatch(_rot90_dispatcher)\n",
    "def rot90(m, k=1, axes=(0, 1)):\n",
    "    \"\"\"\n",
    "    Rotate an array by 90 degrees in the plane specified by axes.\n",
    "    Rotation direction is from the first towards the second axis.\n",
    "    Parameters\n",
    "    ----------\n",
    "    m : array_like\n",
    "        Array of two or more dimensions.\n",
    "    k : integer\n",
    "        Number of times the array is rotated by 90 degrees.\n",
    "    axes: (2,) array_like\n",
    "        The array is rotated in the plane defined by the axes.\n",
    "        Axes must be different.\n",
    "        .. versionadded:: 1.12.0\n",
    "    Returns\n",
    "    -------\n",
    "    y : ndarray\n",
    "        A rotated view of `m`.\n",
    "    See Also\n",
    "    --------\n",
    "    flip : Reverse the order of elements in an array along the given axis.\n",
    "    fliplr : Flip an array horizontally.\n",
    "    flipud : Flip an array vertically.\n",
    "    Notes\n",
    "    -----\n",
    "    rot90(m, k=1, axes=(1,0)) is the reverse of rot90(m, k=1, axes=(0,1))\n",
    "    rot90(m, k=1, axes=(1,0)) is equivalent to rot90(m, k=-1, axes=(0,1))\n",
    "    Examples\n",
    "    --------\n",
    "    >>> m = np.array([[1,2],[3,4]], int)\n",
    "    >>> m\n",
    "    array([[1, 2],\n",
    "           [3, 4]])\n",
    "    >>> np.rot90(m)\n",
    "    array([[2, 4],\n",
    "           [1, 3]])\n",
    "    >>> np.rot90(m, 2)\n",
    "    array([[4, 3],\n",
    "           [2, 1]])\n",
    "    >>> m = np.arange(8).reshape((2,2,2))\n",
    "    >>> np.rot90(m, 1, (1,2))\n",
    "    array([[[1, 3],\n",
    "            [0, 2]],\n",
    "           [[5, 7],\n",
    "            [4, 6]]])\n",
    "    \"\"\"\n",
    "    axes = tuple(axes)\n",
    "    if len(axes) != 2:\n",
    "        raise ValueError(\"len(axes) must be 2.\")\n",
    "\n",
    "    m = asanyarray(m)\n",
    "\n",
    "    if axes[0] == axes[1] or absolute(axes[0] - axes[1]) == m.ndim:\n",
    "        raise ValueError(\"Axes must be different.\")\n",
    "\n",
    "    if (axes[0] >= m.ndim or axes[0] < -m.ndim\n",
    "        or axes[1] >= m.ndim or axes[1] < -m.ndim):\n",
    "        raise ValueError(\"Axes={} out of range for array of ndim={}.\"\n",
    "            .format(axes, m.ndim))\n",
    "\n",
    "    k %= 4\n",
    "\n",
    "    if k == 0:\n",
    "        return m[:]\n",
    "    if k == 2:\n",
    "        return flip(flip(m, axes[0]), axes[1])\n",
    "\n",
    "    axes_list = arange(0, m.ndim)\n",
    "    (axes_list[axes[0]], axes_list[axes[1]]) = (axes_list[axes[1]],\n",
    "                                                axes_list[axes[0]])\n",
    "\n",
    "    if k == 1:\n",
    "        return transpose(flip(m, axes[1]), axes_list)\n",
    "    else:\n",
    "        # k == 3\n",
    "        return flip(transpose(m, axes_list), axes[1])\n",
    "\n",
    "\n",
    "def _flip_dispatcher(m, axis=None):\n",
    "    return (m,)\n",
    "\n",
    "\n",
    "@array_function_dispatch(_flip_dispatcher)\n",
    "def flip(m, axis=None):\n",
    "    \"\"\"\n",
    "    Reverse the order of elements in an array along the given axis.\n",
    "    The shape of the array is preserved, but the elements are reordered.\n",
    "    .. versionadded:: 1.12.0\n",
    "    Parameters\n",
    "    ----------\n",
    "    m : array_like\n",
    "        Input array.\n",
    "    axis : None or int or tuple of ints, optional\n",
    "         Axis or axes along which to flip over. The default,\n",
    "         axis=None, will flip over all of the axes of the input array.\n",
    "         If axis is negative it counts from the last to the first axis.\n",
    "         If axis is a tuple of ints, flipping is performed on all of the axes\n",
    "         specified in the tuple.\n",
    "         .. versionchanged:: 1.15.0\n",
    "            None and tuples of axes are supported\n",
    "    Returns\n",
    "    -------\n",
    "    out : array_like\n",
    "        A view of `m` with the entries of axis reversed.  Since a view is\n",
    "        returned, this operation is done in constant time.\n",
    "    See Also\n",
    "    --------\n",
    "    flipud : Flip an array vertically (axis=0).\n",
    "    fliplr : Flip an array horizontally (axis=1).\n",
    "    Notes\n",
    "    -----\n",
    "    flip(m, 0) is equivalent to flipud(m).\n",
    "    flip(m, 1) is equivalent to fliplr(m).\n",
    "    flip(m, n) corresponds to ``m[...,::-1,...]`` with ``::-1`` at position n.\n",
    "    flip(m) corresponds to ``m[::-1,::-1,...,::-1]`` with ``::-1`` at all\n",
    "    positions.\n",
    "    flip(m, (0, 1)) corresponds to ``m[::-1,::-1,...]`` with ``::-1`` at\n",
    "    position 0 and position 1.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> A = np.arange(8).reshape((2,2,2))\n",
    "    >>> A\n",
    "    array([[[0, 1],\n",
    "            [2, 3]],\n",
    "           [[4, 5],\n",
    "            [6, 7]]])\n",
    "    >>> np.flip(A, 0)\n",
    "    array([[[4, 5],\n",
    "            [6, 7]],\n",
    "           [[0, 1],\n",
    "            [2, 3]]])\n",
    "    >>> np.flip(A, 1)\n",
    "    array([[[2, 3],\n",
    "            [0, 1]],\n",
    "           [[6, 7],\n",
    "            [4, 5]]])\n",
    "    >>> np.flip(A)\n",
    "    array([[[7, 6],\n",
    "            [5, 4]],\n",
    "           [[3, 2],\n",
    "            [1, 0]]])\n",
    "    >>> np.flip(A, (0, 2))\n",
    "    array([[[5, 4],\n",
    "            [7, 6]],\n",
    "           [[1, 0],\n",
    "            [3, 2]]])\n",
    "    >>> A = np.random.randn(3,4,5)\n",
    "    >>> np.all(np.flip(A,2) == A[:,:,::-1,...])\n",
    "    True\n",
    "    \"\"\"\n",
    "    if not hasattr(m, 'ndim'):\n",
    "        m = asarray(m)\n",
    "    if axis is None:\n",
    "        indexer = (np.s_[::-1],) * m.ndim\n",
    "    else:\n",
    "        axis = _nx.normalize_axis_tuple(axis, m.ndim)\n",
    "        indexer = [np.s_[:]] * m.ndim\n",
    "        for ax in axis:\n",
    "            indexer[ax] = np.s_[::-1]\n",
    "        indexer = tuple(indexer)\n",
    "    return m[indexer]\n",
    "\n",
    "\n",
    "@set_module('numpy')\n",
    "def iterable(y):\n",
    "    \"\"\"\n",
    "    Check whether or not an object can be iterated over.\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : object\n",
    "      Input object.\n",
    "    Returns\n",
    "    -------\n",
    "    b : bool\n",
    "      Return ``True`` if the object has an iterator method or is a\n",
    "      sequence and ``False`` otherwise.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> np.iterable([1, 2, 3])\n",
    "    True\n",
    "    >>> np.iterable(2)\n",
    "    False\n",
    "    \"\"\"\n",
    "    try:\n",
    "        iter(y)\n",
    "    except TypeError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def _average_dispatcher(a, axis=None, weights=None, returned=None):\n",
    "    return (a, weights)\n",
    "\n",
    "\n",
    "@array_function_dispatch(_average_dispatcher)\n",
    "def average(a, axis=None, weights=None, returned=False):\n",
    "    \"\"\"\n",
    "    Compute the weighted average along the specified axis.\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : array_like\n",
    "        Array containing data to be averaged. If `a` is not an array, a\n",
    "        conversion is attempted.\n",
    "    axis : None or int or tuple of ints, optional\n",
    "        Axis or axes along which to average `a`.  The default,\n",
    "        axis=None, will average over all of the elements of the input array.\n",
    "        If axis is negative it counts from the last to the first axis.\n",
    "        .. versionadded:: 1.7.0\n",
    "        If axis is a tuple of ints, averaging is performed on all of the axes\n",
    "        specified in the tuple instead of a single axis or all the axes as\n",
    "        before.\n",
    "    weights : array_like, optional\n",
    "        An array of weights associated with the values in `a`. Each value in\n",
    "        `a` contributes to the average according to its associated weight.\n",
    "        The weights array can either be 1-D (in which case its length must be\n",
    "        the size of `a` along the given axis) or of the same shape as `a`.\n",
    "        If `weights=None`, then all data in `a` are assumed to have a\n",
    "        weight equal to one.  The 1-D calculation is::\n",
    "            avg = sum(a * weights) / sum(weights)\n",
    "        The only constraint on `weights` is that `sum(weights)` must not be 0.\n",
    "    returned : bool, optional\n",
    "        Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)\n",
    "        is returned, otherwise only the average is returned.\n",
    "        If `weights=None`, `sum_of_weights` is equivalent to the number of\n",
    "        elements over which the average is taken.\n",
    "    Returns\n",
    "    -------\n",
    "    retval, [sum_of_weights] : array_type or double\n",
    "        Return the average along the specified axis. When `returned` is `True`,\n",
    "        return a tuple with the average as the first element and the sum\n",
    "        of the weights as the second element. `sum_of_weights` is of the\n",
    "        same type as `retval`. The result dtype follows a genereal pattern.\n",
    "        If `weights` is None, the result dtype will be that of `a` , or ``float64``\n",
    "        if `a` is integral. Otherwise, if `weights` is not None and `a` is non-\n",
    "        integral, the result type will be the type of lowest precision capable of\n",
    "        representing values of both `a` and `weights`. If `a` happens to be\n",
    "        integral, the previous rules still applies but the result dtype will\n",
    "        at least be ``float64``.\n",
    "    Raises\n",
    "    ------\n",
    "    ZeroDivisionError\n",
    "        When all weights along axis are zero. See `numpy.ma.average` for a\n",
    "        version robust to this type of error.\n",
    "    TypeError\n",
    "        When the length of 1D `weights` is not the same as the shape of `a`\n",
    "        along axis.\n",
    "    See Also\n",
    "    --------\n",
    "    mean\n",
    "    ma.average : average for masked arrays -- useful if your data contains\n",
    "                 \"missing\" values\n",
    "    numpy.result_type : Returns the type that results from applying the\n",
    "                        numpy type promotion rules to the arguments.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> data = np.arange(1, 5)\n",
    "    >>> data\n",
    "    array([1, 2, 3, 4])\n",
    "    >>> np.average(data)\n",
    "    2.5\n",
    "    >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))\n",
    "    4.0\n",
    "    >>> data = np.arange(6).reshape((3,2))\n",
    "    >>> data\n",
    "    array([[0, 1],\n",
    "           [2, 3],\n",
    "           [4, 5]])\n",
    "    >>> np.average(data, axis=1, weights=[1./4, 3./4])\n",
    "    array([0.75, 2.75, 4.75])\n",
    "    >>> np.average(data, weights=[1./4, 3./4])\n",
    "    Traceback (most recent call last):\n",
    "        ...\n",
    "    TypeError: Axis must be specified when shapes of a and weights differ.\n",
    "    >>> a = np.ones(5, dtype=np.float128)\n",
    "    >>> w = np.ones(5, dtype=np.complex64)\n",
    "    >>> avg = np.average(a, weights=w)\n",
    "    >>> print(avg.dtype)\n",
    "    complex256\n",
    "    \"\"\"\n",
    "    a = np.asanyarray(a)\n",
    "\n",
    "    if weights is None:\n",
    "        avg = a.mean(axis)\n",
    "        scl = avg.dtype.type(a.size/avg.size)\n",
    "    else:\n",
    "        wgt = np.asanyarray(weights)\n",
    "\n",
    "        if issubclass(a.dtype.type, (np.integer, np.bool_)):\n",
    "            result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')\n",
    "        else:\n",
    "            result_dtype = np.result_type(a.dtype, wgt.dtype)\n",
    "\n",
    "        # Sanity checks\n",
    "        if a.shape != wgt.shape:\n",
    "            if axis is None:\n",
    "                raise TypeError(\n",
    "                    \"Axis must be specified when shapes of a and weights \"\n",
    "                    \"differ.\")\n",
    "            if wgt.ndim != 1:\n",
    "                raise TypeError(\n",
    "                    \"1D weights expected when shapes of a and weights differ.\")\n",
    "            if wgt.shape[0] != a.shape[axis]:\n",
    "                raise ValueError(\n",
    "                    \"Length of weights not compatible with specified axis.\")\n",
    "\n",
    "            # setup wgt to broadcast along axis\n",
    "            wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)\n",
    "            wgt = wgt.swapaxes(-1, axis)\n",
    "\n",
    "        scl = wgt.sum(axis=axis, dtype=result_dtype)\n",
    "        if np.any(scl == 0.0):\n",
    "            raise ZeroDivisionError(\n",
    "                \"Weights sum to zero, can't be normalized\")\n",
    "\n",
    "        avg = np.multiply(a, wgt, dtype=result_dtype).sum(axis)/scl\n",
    "\n",
    "    if returned:\n",
    "        if scl.shape != avg.shape:\n",
    "            scl = np.broadcast_to(scl, avg.shape).copy()\n",
    "        return avg, scl\n",
    "    else:\n",
    "        return avg\n",
    "\n",
    "\n",
    "@set_module('numpy')\n",
    "def asarray_chkfinite(a, dtype=None, order=None):\n",
    "    \"\"\"Convert the input to an array, checking for NaNs or Infs.\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : array_like\n",
    "        Input data, in any form that can be converted to an array.  This\n",
    "        includes lists, lists of tuples, tuples, tuples of tuples, tuples\n",
    "        of lists and ndarrays.  Success requires no NaNs or Infs.\n",
    "    dtype : data-type, optional\n",
    "        By default, the data-type is inferred from the input data.\n",
    "    order : {'C', 'F'}, optional\n",
    "         Whether to use row-major (C-style) or\n",
    "         column-major (Fortran-style) memory representation.\n",
    "         Defaults to 'C'.\n",
    "    Returns\n",
    "    -------\n",
    "    out : ndarray\n",
    "        Array interpretation of `a`.  No copy is performed if the input\n",
    "        is already an ndarray.  If `a` is a subclass of ndarray, a base\n",
    "        class ndarray is returned.\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        Raises ValueError if `a` contains NaN (Not a Number) or Inf (Infinity).\n",
    "    See Also\n",
    "    --------\n",
    "    asarray : Create and array.\n",
    "    asanyarray : Similar function which passes through subclasses.\n",
    "    ascontiguousarray : Convert input to a contiguous array.\n",
    "    asfarray : Convert input to a floating point ndarray.\n",
    "    asfortranarray : Convert input to an ndarray with column-major\n",
    "                     memory order.\n",
    "    fromiter : Create an array from an iterator.\n",
    "    fromfunction : Construct an array by executing a function on grid\n",
    "                   positions.\n",
    "    Examples\n",
    "    --------\n",
    "    Convert a list into an array.  If all elements are finite\n",
    "    ``asarray_chkfinite`` is identical to ``asarray``.\n",
    "    >>> a = [1, 2]\n",
    "    >>> np.asarray_chkfinite(a, dtype=float)\n",
    "    array([1., 2.])\n",
    "    Raises ValueError if array_like contains Nans or Infs.\n",
    "    >>> a = [1, 2, np.inf]\n",
    "    >>> try:\n",
    "    ...     np.asarray_chkfinite(a)\n",
    "    ... except ValueError:\n",
    "    ...     print('ValueError')\n",
    "    ...\n",
    "    ValueError\n",
    "    \"\"\"\n",
    "    a = asarray(a, dtype=dtype, order=order)\n",
    "    if a.dtype.char in typecodes['AllFloat'] and not np.isfinite(a).all():\n",
    "        raise ValueError(\n",
    "            \"array must not contain infs or NaNs\")\n",
    "    return a\n",
    "\n",
    "\n",
    "def _piecewise_dispatcher(x, condlist, funclist, *args, **kw):\n",
    "    yield x\n",
    "    # support the undocumented behavior of allowing scalars\n",
    "    if np.iterable(condlist):\n",
    "        yield from condlist\n",
    "\n",
    "\n",
    "@array_function_dispatch(_piecewise_dispatcher)\n",
    "def piecewise(x, condlist, funclist, *args, **kw):\n",
    "    \"\"\"\n",
    "    Evaluate a piecewise-defined function.\n",
    "    Given a set of conditions and corresponding functions, evaluate each\n",
    "    function on the input data wherever its condition is true.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : ndarray or scalar\n",
    "        The input domain.\n",
    "    condlist : list of bool arrays or bool scalars\n",
    "        Each boolean array corresponds to a function in `funclist`.  Wherever\n",
    "        `condlist[i]` is True, `funclist[i](x)` is used as the output value.\n",
    "        Each boolean array in `condlist` selects a piece of `x`,\n",
    "        and should therefore be of the same shape as `x`.\n",
    "        The length of `condlist` must correspond to that of `funclist`.\n",
    "        If one extra function is given, i.e. if\n",
    "        ``len(funclist) == len(condlist) + 1``, then that extra function\n",
    "        is the default value, used wherever all conditions are false.\n",
    "    funclist : list of callables, f(x,*args,**kw), or scalars\n",
    "        Each function is evaluated over `x` wherever its corresponding\n",
    "        condition is True.  It should take a 1d array as input and give an 1d\n",
    "        array or a scalar value as output.  If, instead of a callable,\n",
    "        a scalar is provided then a constant function (``lambda x: scalar``) is\n",
    "        assumed.\n",
    "    args : tuple, optional\n",
    "        Any further arguments given to `piecewise` are passed to the functions\n",
    "        upon execution, i.e., if called ``piecewise(..., ..., 1, 'a')``, then\n",
    "        each function is called as ``f(x, 1, 'a')``.\n",
    "    kw : dict, optional\n",
    "        Keyword arguments used in calling `piecewise` are passed to the\n",
    "        functions upon execution, i.e., if called\n",
    "        ``piecewise(..., ..., alpha=1)``, then each function is called as\n",
    "        ``f(x, alpha=1)``.\n",
    "    Returns\n",
    "    -------\n",
    "    out : ndarray\n",
    "        The output is the same shape and type as x and is found by\n",
    "        calling the functions in `funclist` on the appropriate portions of `x`,\n",
    "        as defined by the boolean arrays in `condlist`.  Portions not covered\n",
    "        by any condition have a default value of 0.\n",
    "    See Also\n",
    "    --------\n",
    "    choose, select, where\n",
    "    Notes\n",
    "    -----\n",
    "    This is similar to choose or select, except that functions are\n",
    "    evaluated on elements of `x` that satisfy the corresponding condition from\n",
    "    `condlist`.\n",
    "    The result is::\n",
    "            |--\n",
    "            |funclist[0](x[condlist[0]])\n",
    "      out = |funclist[1](x[condlist[1]])\n",
    "            |...\n",
    "            |funclist[n2](x[condlist[n2]])\n",
    "            |--\n",
    "    Examples\n",
    "    --------\n",
    "    Define the sigma function, which is -1 for ``x < 0`` and +1 for ``x >= 0``.\n",
    "    >>> x = np.linspace(-2.5, 2.5, 6)\n",
    "    >>> np.piecewise(x, [x < 0, x >= 0], [-1, 1])\n",
    "    array([-1., -1., -1.,  1.,  1.,  1.])\n",
    "    Define the absolute value, which is ``-x`` for ``x <0`` and ``x`` for\n",
    "    ``x >= 0``.\n",
    "    >>> np.piecewise(x, [x < 0, x >= 0], [lambda x: -x, lambda x: x])\n",
    "    array([2.5,  1.5,  0.5,  0.5,  1.5,  2.5])\n",
    "    Apply the same function to a scalar value.\n",
    "    >>> y = -2\n",
    "    >>> np.piecewise(y, [y < 0, y >= 0], [lambda x: -x, lambda x: x])\n",
    "    array(2)\n",
    "    \"\"\"\n",
    "    x = asanyarray(x)\n",
    "    n2 = len(funclist)\n",
    "\n",
    "    # undocumented: single condition is promoted to a list of one condition\n",
    "    if isscalar(condlist) or (\n",
    "            not isinstance(condlist[0], (list, ndarray)) and x.ndim != 0):\n",
    "        condlist = [condlist]\n",
    "\n",
    "    condlist = array(condlist, dtype=bool)\n",
    "    n = len(condlist)\n",
    "\n",
    "    if n == n2 - 1:  # compute the \"otherwise\" condition.\n",
    "        condelse = ~np.any(condlist, axis=0, keepdims=True)\n",
    "        condlist = np.concatenate([condlist, condelse], axis=0)\n",
    "        n += 1\n",
    "    elif n != n2:\n",
    "        raise ValueError(\n",
    "            \"with {} condition(s), either {} or {} functions are expected\"\n",
    "            .format(n, n, n+1)\n",
    "        )\n",
    "\n",
    "    y = zeros(x.shape, x.dtype)\n",
    "    for cond, func in zip(condlist, funclist):\n",
    "        if not isinstance(func, collections.abc.Callable):\n",
    "            y[cond] = func\n",
    "        else:\n",
    "            vals = x[cond]\n",
    "            if vals.size > 0:\n",
    "                y[cond] = func(vals, *args, **kw)\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "def _select_dispatcher(condlist, choicelist, default=None):\n",
    "    yield from condlist\n",
    "    yield from choicelist\n",
    "\n",
    "\n",
    "@array_function_dispatch(_select_dispatcher)\n",
    "def select(condlist, choicelist, default=0):\n",
    "    \"\"\"\n",
    "    Return an array drawn from elements in choicelist, depending on conditions.\n",
    "    Parameters\n",
    "    ----------\n",
    "    condlist : list of bool ndarrays\n",
    "        The list of conditions which determine from which array in `choicelist`\n",
    "        the output elements are taken. When multiple conditions are satisfied,\n",
    "        the first one encountered in `condlist` is used.\n",
    "    choicelist : list of ndarrays\n",
    "        The list of arrays from which the output elements are taken. It has\n",
    "        to be of the same length as `condlist`.\n",
    "    default : scalar, optional\n",
    "        The element inserted in `output` when all conditions evaluate to False.\n",
    "    Returns\n",
    "    -------\n",
    "    output : ndarray\n",
    "        The output at position m is the m-th element of the array in\n",
    "        `choicelist` where the m-th element of the corresponding array in\n",
    "        `condlist` is True.\n",
    "    See Also\n",
    "    --------\n",
    "    where : Return elements from one of two arrays depending on condition.\n",
    "    take, choose, compress, diag, diagonal\n",
    "    Examples\n",
    "    --------\n",
    "    >>> x = np.arange(10)\n",
    "    >>> condlist = [x<3, x>5]\n",
    "    >>> choicelist = [x, x**2]\n",
    "    >>> np.select(condlist, choicelist)\n",
    "    array([ 0,  1,  2, ..., 49, 64, 81])\n",
    "    \"\"\"\n",
    "    # Check the size of condlist and choicelist are the same, or abort.\n",
    "    if len(condlist) != len(choicelist):\n",
    "        raise ValueError(\n",
    "            'list of cases must be same length as list of conditions')\n",
    "\n",
    "    # Now that the dtype is known, handle the deprecated select([], []) case\n",
    "    if len(condlist) == 0:\n",
    "        raise ValueError(\"select with an empty condition list is not possible\")\n",
    "\n",
    "    choicelist = [np.asarray(choice) for choice in choicelist]\n",
    "    choicelist.append(np.asarray(default))\n",
    "\n",
    "    # need to get the result type before broadcasting for correct scalar\n",
    "    # behaviour\n",
    "    dtype = np.result_type(*choicelist)\n",
    "\n",
    "    # Convert conditions to arrays and broadcast conditions and choices\n",
    "    # as the shape is needed for the result. Doing it separately optimizes\n",
    "    # for example when all choices are scalars.\n",
    "    condlist = np.broadcast_arrays(*condlist)\n",
    "    choicelist = np.broadcast_arrays(*choicelist)\n",
    "\n",
    "    # If cond array is not an ndarray in boolean format or scalar bool, abort.\n",
    "    for i, cond in enumerate(condlist):\n",
    "        if cond.dtype.type is not np.bool_:\n",
    "            raise TypeError(\n",
    "                'invalid entry {} in condlist: should be boolean ndarray'.format(i))\n",
    "\n",
    "    if choicelist[0].ndim == 0:\n",
    "        # This may be common, so avoid the call.\n",
    "        result_shape = condlist[0].shape\n",
    "    else:\n",
    "        result_shape = np.broadcast_arrays(condlist[0], choicelist[0])[0].shape\n",
    "\n",
    "    result = np.full(result_shape, choicelist[-1], dtype)\n",
    "\n",
    "    # Use np.copyto to burn each choicelist array onto result, using the\n",
    "    # corresponding condlist as a boolean mask. This is done in reverse\n",
    "    # order since the first choice should take precedence.\n",
    "    choicelist = choicelist[-2::-1]\n",
    "    condlist = condlist[::-1]\n",
    "    for choice, cond in zip(choicelist, condlist):\n",
    "        np.copyto(result, choice, where=cond)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def _copy_dispatcher(a, order=None, subok=None):\n",
    "    return (a,)\n",
    "\n",
    "\n",
    "@array_function_dispatch(_copy_dispatcher)\n",
    "def copy(a, order='K', subok=False):\n",
    "    \"\"\"\n",
    "    Return an array copy of the given object.\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : array_like\n",
    "        Input data.\n",
    "    order : {'C', 'F', 'A', 'K'}, optional\n",
    "        Controls the memory layout of the copy. 'C' means C-order,\n",
    "        'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,\n",
    "        'C' otherwise. 'K' means match the layout of `a` as closely\n",
    "        as possible. (Note that this function and :meth:`ndarray.copy` are very\n",
    "        similar, but have different default values for their order=\n",
    "        arguments.)\n",
    "    subok : bool, optional\n",
    "        If True, then sub-classes will be passed-through, otherwise the\n",
    "        returned array will be forced to be a base-class array (defaults to False).\n",
    "        .. versionadded:: 1.19.0\n",
    "    Returns\n",
    "    -------\n",
    "    arr : ndarray\n",
    "        Array interpretation of `a`.\n",
    "    See Also\n",
    "    --------\n",
    "    ndarray.copy : Preferred method for creating an array copy\n",
    "    Notes\n",
    "    -----\n",
    "    This is equivalent to:\n",
    "    >>> np.array(a, copy=True)  #doctest: +SKIP\n",
    "    Examples\n",
    "    --------\n",
    "    Create an array x, with a reference y and a copy z:\n",
    "    >>> x = np.array([1, 2, 3])\n",
    "    >>> y = x\n",
    "    >>> z = np.copy(x)\n",
    "    Note that, when we modify x, y changes, but not z:\n",
    "    >>> x[0] = 10\n",
    "    >>> x[0] == y[0]\n",
    "    True\n",
    "    >>> x[0] == z[0]\n",
    "    False\n",
    "    Note that np.copy is a shallow copy and will not copy object\n",
    "    elements within arrays. This is mainly important for arrays\n",
    "    containing Python objects. The new array will contain the\n",
    "    same object which may lead to surprises if that object can\n",
    "    be modified (is mutable):\n",
    "    >>> a = np.array([1, 'm', [2, 3, 4]], dtype=object)\n",
    "    >>> b = np.copy(a)\n",
    "    >>> b[2][0] = 10\n",
    "    >>> a\n",
    "    array([1, 'm', list([10, 3, 4])], dtype=object)\n",
    "    To ensure all elements within an ``object`` array are copied,\n",
    "    use `copy.deepcopy`:\n",
    "    >>> import copy\n",
    "    >>> a = np.array([1, 'm', [2, 3, 4]], dtype=object)\n",
    "    >>> c = copy.deepcopy(a)\n",
    "    >>> c[2][0] = 10\n",
    "    >>> c\n",
    "    array([1, 'm', list([10, 3, 4])], dtype=object)\n",
    "    >>> a\n",
    "    array([1, 'm', list([2, 3, 4])], dtype=object)\n",
    "    \"\"\"\n",
    "    return array(a, order=order, subok=subok, copy=True)\n",
    "\n",
    "# Basic operations\n",
    "\n",
    "\n",
    "def _gradient_dispatcher(f, *varargs, axis=None, edge_order=None):\n",
    "    yield f\n",
    "    yield from varargs\n",
    "\n",
    "\n",
    "@array_function_dispatch(_gradient_dispatcher)\n",
    "def gradient(f, *varargs, axis=None, edge_order=1):\n",
    "    \"\"\"\n",
    "    Return the gradient of an N-dimensional array.\n",
    "    The gradient is computed using second order accurate central differences\n",
    "    in the interior points and either first or second order accurate one-sides\n",
    "    (forward or backwards) differences at the boundaries.\n",
    "    The returned gradient hence has the same shape as the input array.\n",
    "    Parameters\n",
    "    ----------\n",
    "    f : array_like\n",
    "        An N-dimensional array containing samples of a scalar function.\n",
    "    varargs : list of scalar or array, optional\n",
    "        Spacing between f values. Default unitary spacing for all dimensions.\n",
    "        Spacing can be specified using:\n",
    "        1. single scalar to specify a sample distance for all dimensions.\n",
    "        2. N scalars to specify a constant sample distance for each dimension.\n",
    "           i.e. `dx`, `dy`, `dz`, ...\n",
    "        3. N arrays to specify the coordinates of the values along each\n",
    "           dimension of F. The length of the array must match the size of\n",
    "           the corresponding dimension\n",
    "        4. Any combination of N scalars/arrays with the meaning of 2. and 3.\n",
    "        If `axis` is given, the number of varargs must equal the number of axes.\n",
    "        Default: 1.\n",
    "    edge_order : {1, 2}, optional\n",
    "        Gradient is calculated using N-th order accurate differences\n",
    "        at the boundaries. Default: 1.\n",
    "        .. versionadded:: 1.9.1\n",
    "    axis : None or int or tuple of ints, optional\n",
    "        Gradient is calculated only along the given axis or axes\n",
    "        The default (axis = None) is to calculate the gradient for all the axes\n",
    "        of the input array. axis may be negative, in which case it counts from\n",
    "        the last to the first axis.\n",
    "        .. versionadded:: 1.11.0\n",
    "    Returns\n",
    "    -------\n",
    "    gradient : ndarray or list of ndarray\n",
    "        A set of ndarrays (or a single ndarray if there is only one dimension)\n",
    "        corresponding to the derivatives of f with respect to each dimension.\n",
    "        Each derivative has the same shape as f.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> f = np.array([1, 2, 4, 7, 11, 16], dtype=float)\n",
    "    >>> np.gradient(f)\n",
    "    array([1. , 1.5, 2.5, 3.5, 4.5, 5. ])\n",
    "    >>> np.gradient(f, 2)\n",
    "    array([0.5 ,  0.75,  1.25,  1.75,  2.25,  2.5 ])\n",
    "    Spacing can be also specified with an array that represents the coordinates\n",
    "    of the values F along the dimensions.\n",
    "    For instance a uniform spacing:\n",
    "    >>> x = np.arange(f.size)\n",
    "    >>> np.gradient(f, x)\n",
    "    array([1. ,  1.5,  2.5,  3.5,  4.5,  5. ])\n",
    "    Or a non uniform one:\n",
    "    >>> x = np.array([0., 1., 1.5, 3.5, 4., 6.], dtype=float)\n",
    "    >>> np.gradient(f, x)\n",
    "    array([1. ,  3. ,  3.5,  6.7,  6.9,  2.5])\n",
    "    For two dimensional arrays, the return will be two arrays ordered by\n",
    "    axis. In this example the first array stands for the gradient in\n",
    "    rows and the second one in columns direction:\n",
    "    >>> np.gradient(np.array([[1, 2, 6], [3, 4, 5]], dtype=float))\n",
    "    [array([[ 2.,  2., -1.],\n",
    "           [ 2.,  2., -1.]]), array([[1. , 2.5, 4. ],\n",
    "           [1. , 1. , 1. ]])]\n",
    "    In this example the spacing is also specified:\n",
    "    uniform for axis=0 and non uniform for axis=1\n",
    "    >>> dx = 2.\n",
    "    >>> y = [1., 1.5, 3.5]\n",
    "    >>> np.gradient(np.array([[1, 2, 6], [3, 4, 5]], dtype=float), dx, y)\n",
    "    [array([[ 1. ,  1. , -0.5],\n",
    "           [ 1. ,  1. , -0.5]]), array([[2. , 2. , 2. ],\n",
    "           [2. , 1.7, 0.5]])]\n",
    "    It is possible to specify how boundaries are treated using `edge_order`\n",
    "    >>> x = np.array([0, 1, 2, 3, 4])\n",
    "    >>> f = x**2\n",
    "    >>> np.gradient(f, edge_order=1)\n",
    "    array([1.,  2.,  4.,  6.,  7.])\n",
    "    >>> np.gradient(f, edge_order=2)\n",
    "    array([0., 2., 4., 6., 8.])\n",
    "    The `axis` keyword can be used to specify a subset of axes of which the\n",
    "    gradient is calculated\n",
    "    >>> np.gradient(np.array([[1, 2, 6], [3, 4, 5]], dtype=float), axis=0)\n",
    "    array([[ 2.,  2., -1.],\n",
    "           [ 2.,  2., -1.]])\n",
    "    Notes\n",
    "    -----\n",
    "    Assuming that :math:`f\\\\in C^{3}` (i.e., :math:`f` has at least 3 continuous\n",
    "    derivatives) and let :math:`h_{*}` be a non-homogeneous stepsize, we\n",
    "    minimize the \"consistency error\" :math:`\\\\eta_{i}` between the true gradient\n",
    "    and its estimate from a linear combination of the neighboring grid-points:\n",
    "    .. math::\n",
    "        \\\\eta_{i} = f_{i}^{\\\\left(1\\\\right)} -\n",
    "                    \\\\left[ \\\\alpha f\\\\left(x_{i}\\\\right) +\n",
    "                            \\\\beta f\\\\left(x_{i} + h_{d}\\\\right) +\n",
    "                            \\\\gamma f\\\\left(x_{i}-h_{s}\\\\right)\n",
    "                    \\\\right]\n",
    "    By substituting :math:`f(x_{i} + h_{d})` and :math:`f(x_{i} - h_{s})`\n",
    "    with their Taylor series expansion, this translates into solving\n",
    "    the following the linear system:\n",
    "    .. math::\n",
    "        \\\\left\\\\{\n",
    "            \\\\begin{array}{r}\n",
    "                \\\\alpha+\\\\beta+\\\\gamma=0 \\\\\\\\\n",
    "                \\\\beta h_{d}-\\\\gamma h_{s}=1 \\\\\\\\\n",
    "                \\\\beta h_{d}^{2}+\\\\gamma h_{s}^{2}=0\n",
    "            \\\\end{array}\n",
    "        \\\\right.\n",
    "    The resulting approximation of :math:`f_{i}^{(1)}` is the following:\n",
    "    .. math::\n",
    "        \\\\hat f_{i}^{(1)} =\n",
    "            \\\\frac{\n",
    "                h_{s}^{2}f\\\\left(x_{i} + h_{d}\\\\right)\n",
    "                + \\\\left(h_{d}^{2} - h_{s}^{2}\\\\right)f\\\\left(x_{i}\\\\right)\n",
    "                - h_{d}^{2}f\\\\left(x_{i}-h_{s}\\\\right)}\n",
    "                { h_{s}h_{d}\\\\left(h_{d} + h_{s}\\\\right)}\n",
    "            + \\\\mathcal{O}\\\\left(\\\\frac{h_{d}h_{s}^{2}\n",
    "                                + h_{s}h_{d}^{2}}{h_{d}\n",
    "                                + h_{s}}\\\\right)\n",
    "    It is worth noting that if :math:`h_{s}=h_{d}`\n",
    "    (i.e., data are evenly spaced)\n",
    "    we find the standard second order approximation:\n",
    "    .. math::\n",
    "        \\\\hat f_{i}^{(1)}=\n",
    "            \\\\frac{f\\\\left(x_{i+1}\\\\right) - f\\\\left(x_{i-1}\\\\right)}{2h}\n",
    "            + \\\\mathcal{O}\\\\left(h^{2}\\\\right)\n",
    "    With a similar procedure the forward/backward approximations used for\n",
    "    boundaries can be derived.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1]  Quarteroni A., Sacco R., Saleri F. (2007) Numerical Mathematics\n",
    "            (Texts in Applied Mathematics). New York: Springer.\n",
    "    .. [2]  Durran D. R. (1999) Numerical Methods for Wave Equations\n",
    "            in Geophysical Fluid Dynamics. New York: Springer.\n",
    "    .. [3]  Fornberg B. (1988) Generation of Finite Difference Formulas on\n",
    "            Arbitrarily Spaced Grids,\n",
    "            Mathematics of Computation 51, no. 184 : 699-706.\n",
    "            `PDF <http://www.ams.org/journals/mcom/1988-51-184/\n",
    "            S0025-5718-1988-0935077-0/S0025-5718-1988-0935077-0.pdf>`_.\n",
    "    \"\"\"\n",
    "    f = np.asanyarray(f)\n",
    "    N = f.ndim  # number of dimensions\n",
    "\n",
    "    if axis is None:\n",
    "        axes = tuple(range(N))\n",
    "    else:\n",
    "        axes = _nx.normalize_axis_tuple(axis, N)\n",
    "\n",
    "    len_axes = len(axes)\n",
    "    n = len(varargs)\n",
    "    if n == 0:\n",
    "        # no spacing argument - use 1 in all axes\n",
    "        dx = [1.0] * len_axes\n",
    "    elif n == 1 and np.ndim(varargs[0]) == 0:\n",
    "        # single scalar for all axes\n",
    "        dx = varargs * len_axes\n",
    "    elif n == len_axes:\n",
    "        # scalar or 1d array for each axis\n",
    "        dx = list(varargs)\n",
    "        for i, distances in enumerate(dx):\n",
    "            distances = np.asanyarray(distances)\n",
    "            if distances.ndim == 0:\n",
    "                continue\n",
    "            elif distances.ndim != 1:\n",
    "                raise ValueError(\"distances must be either scalars or 1d\")\n",
    "            if len(distances) != f.shape[axes[i]]:\n",
    "                raise ValueError(\"when 1d, distances must match \"\n",
    "                                 \"the length of the corresponding dimension\")\n",
    "            if np.issubdtype(distances.dtype, np.integer):\n",
    "                # Convert numpy integer types to float64 to avoid modular\n",
    "                # arithmetic in np.diff(distances).\n",
    "                distances = distances.astype(np.float64)\n",
    "            diffx = np.diff(distances)\n",
    "            # if distances are constant reduce to the scalar case\n",
    "            # since it brings a consistent speedup\n",
    "            if (diffx == diffx[0]).all():\n",
    "                diffx = diffx[0]\n",
    "            dx[i] = diffx\n",
    "    else:\n",
    "        raise TypeError(\"invalid number of arguments\")\n",
    "\n",
    "    if edge_order > 2:\n",
    "        raise ValueError(\"'edge_order' greater than 2 not supported\")\n",
    "\n",
    "    # use central differences on interior and one-sided differences on the\n",
    "    # endpoints. This preserves second order-accuracy over the full domain.\n",
    "\n",
    "    outvals = []\n",
    "\n",
    "    # create slice objects --- initially all are [:, :, ..., :]\n",
    "    slice1 = [slice(None)]*N\n",
    "    slice2 = [slice(None)]*N\n",
    "    slice3 = [slice(None)]*N\n",
    "    slice4 = [slice(None)]*N\n",
    "\n",
    "    otype = f.dtype\n",
    "    if otype.type is np.datetime64:\n",
    "        # the timedelta dtype with the same unit information\n",
    "        otype = np.dtype(otype.name.replace('datetime', 'timedelta'))\n",
    "        # view as timedelta to allow addition\n",
    "        f = f.view(otype)\n",
    "    elif otype.type is np.timedelta64:\n",
    "        pass\n",
    "    elif np.issubdtype(otype, np.inexact):\n",
    "        pass\n",
    "    else:\n",
    "        # All other types convert to floating point.\n",
    "        # First check if f is a numpy integer type; if so, convert f to float64\n",
    "        # to avoid modular arithmetic when computing the changes in f.\n",
    "        if np.issubdtype(otype, np.integer):\n",
    "            f = f.astype(np.float64)\n",
    "        otype = np.float64\n",
    "\n",
    "    for axis, ax_dx in zip(axes, dx):\n",
    "        if f.shape[axis] < edge_order + 1:\n",
    "            raise ValueError(\n",
    "                \"Shape of array too small to calculate a numerical gradient, \"\n",
    "                \"at least (edge_order + 1) elements are required.\")\n",
    "        # result allocation\n",
    "        out = np.empty_like(f, dtype=otype)\n",
    "\n",
    "        # spacing for the current axis\n",
    "        uniform_spacing = np.ndim(ax_dx) == 0\n",
    "\n",
    "        # Numerical differentiation: 2nd order interior\n",
    "        slice1[axis] = slice(1, -1)\n",
    "        slice2[axis] = slice(None, -2)\n",
    "        slice3[axis] = slice(1, -1)\n",
    "        slice4[axis] = slice(2, None)\n",
    "\n",
    "        if uniform_spacing:\n",
    "            out[tuple(slice1)] = (f[tuple(slice4)] - f[tuple(slice2)]) / (2. * ax_dx)\n",
    "        else:\n",
    "            dx1 = ax_dx[0:-1]\n",
    "            dx2 = ax_dx[1:]\n",
    "            a = -(dx2)/(dx1 * (dx1 + dx2))\n",
    "            b = (dx2 - dx1) / (dx1 * dx2)\n",
    "            c = dx1 / (dx2 * (dx1 + dx2))\n",
    "            # fix the shape for broadcasting\n",
    "            shape = np.ones(N, dtype=int)\n",
    "            shape[axis] = -1\n",
    "            a.shape = b.shape = c.shape = shape\n",
    "            # 1D equivalent -- out[1:-1] = a * f[:-2] + b * f[1:-1] + c * f[2:]\n",
    "            out[tuple(slice1)] = a * f[tuple(slice2)] + b * f[tuple(slice3)] + c * f[tuple(slice4)]\n",
    "\n",
    "        # Numerical differentiation: 1st order edges\n",
    "        if edge_order == 1:\n",
    "            slice1[axis] = 0\n",
    "            slice2[axis] = 1\n",
    "            slice3[axis] = 0\n",
    "            dx_0 = ax_dx if uniform_spacing else ax_dx[0]\n",
    "            # 1D equivalent -- out[0] = (f[1] - f[0]) / (x[1] - x[0])\n",
    "            out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_0\n",
    "\n",
    "            slice1[axis] = -1\n",
    "            slice2[axis] = -1\n",
    "            slice3[axis] = -2\n",
    "            dx_n = ax_dx if uniform_spacing else ax_dx[-1]\n",
    "            # 1D equivalent -- out[-1] = (f[-1] - f[-2]) / (x[-1] - x[-2])\n",
    "            out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_n\n",
    "\n",
    "        # Numerical differentiation: 2nd order edges\n",
    "        else:\n",
    "            slice1[axis] = 0\n",
    "            slice2[axis] = 0\n",
    "            slice3[axis] = 1\n",
    "            slice4[axis] = 2\n",
    "            if uniform_spacing:\n",
    "                a = -1.5 / ax_dx\n",
    "                b = 2. / ax_dx\n",
    "                c = -0.5 / ax_dx\n",
    "            else:\n",
    "                dx1 = ax_dx[0]\n",
    "                dx2 = ax_dx[1]\n",
    "                a = -(2. * dx1 + dx2)/(dx1 * (dx1 + dx2))\n",
    "                b = (dx1 + dx2) / (dx1 * dx2)\n",
    "                c = - dx1 / (dx2 * (dx1 + dx2))\n",
    "            # 1D equivalent -- out[0] = a * f[0] + b * f[1] + c * f[2]\n",
    "            out[tuple(slice1)] = a * f[tuple(slice2)] + b * f[tuple(slice3)] + c * f[tuple(slice4)]\n",
    "\n",
    "            slice1[axis] = -1\n",
    "            slice2[axis] = -3\n",
    "            slice3[axis] = -2\n",
    "            slice4[axis] = -1\n",
    "            if uniform_spacing:\n",
    "                a = 0.5 / ax_dx\n",
    "                b = -2. / ax_dx\n",
    "                c = 1.5 / ax_dx\n",
    "            else:\n",
    "                dx1 = ax_dx[-2]\n",
    "                dx2 = ax_dx[-1]\n",
    "                a = (dx2) / (dx1 * (dx1 + dx2))\n",
    "                b = - (dx2 + dx1) / (dx1 * dx2)\n",
    "                c = (2. * dx2 + dx1) / (dx2 * (dx1 + dx2))\n",
    "            # 1D equivalent -- out[-1] = a * f[-3] + b * f[-2] + c * f[-1]\n",
    "            out[tuple(slice1)] = a * f[tuple(slice2)] + b * f[tuple(slice3)] + c * f[tuple(slice4)]\n",
    "\n",
    "        outvals.append(out)\n",
    "\n",
    "        # reset the slice object in this dimension to \":\"\n",
    "        slice1[axis] = slice(None)\n",
    "        slice2[axis] = slice(None)\n",
    "        slice3[axis] = slice(None)\n",
    "        slice4[axis] = slice(None)\n",
    "\n",
    "    if len_axes == 1:\n",
    "        return outvals[0]\n",
    "    else:\n",
    "        return outvals\n",
    "\n",
    "\n",
    "def _diff_dispatcher(a, n=None, axis=None, prepend=None, append=None):\n",
    "    return (a, prepend, append)\n",
    "\n",
    "\n",
    "@array_function_dispatch(_diff_dispatcher)\n",
    "def diff(a, n=1, axis=-1, prepend=np._NoValue, append=np._NoValue):\n",
    "    \"\"\"\n",
    "    Calculate the n-th discrete difference along the given axis.\n",
    "    The first difference is given by ``out[i] = a[i+1] - a[i]`` along\n",
    "    the given axis, higher differences are calculated by using `diff`\n",
    "    recursively.\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : array_like\n",
    "        Input array\n",
    "    n : int, optional\n",
    "        The number of times values are differenced. If zero, the input\n",
    "        is returned as-is.\n",
    "    axis : int, optional\n",
    "        The axis along which the difference is taken, default is the\n",
    "        last axis.\n",
    "    prepend, append : array_like, optional\n",
    "        Values to prepend or append to `a` along axis prior to\n",
    "        performing the difference.  Scalar values are expanded to\n",
    "        arrays with length 1 in the direction of axis and the shape\n",
    "        of the input array in along all other axes.  Otherwise the\n",
    "        dimension and shape must match `a` except along axis.\n",
    "        .. versionadded:: 1.16.0\n",
    "    Returns\n",
    "    -------\n",
    "    diff : ndarray\n",
    "        The n-th differences. The shape of the output is the same as `a`\n",
    "        except along `axis` where the dimension is smaller by `n`. The\n",
    "        type of the output is the same as the type of the difference\n",
    "        between any two elements of `a`. This is the same as the type of\n",
    "        `a` in most cases. A notable exception is `datetime64`, which\n",
    "        results in a `timedelta64` output array.\n",
    "    See Also\n",
    "    --------\n",
    "    gradient, ediff1d, cumsum\n",
    "    Notes\n",
    "    -----\n",
    "    Type is preserved for boolean arrays, so the result will contain\n",
    "    `False` when consecutive elements are the same and `True` when they\n",
    "    differ.\n",
    "    For unsigned integer arrays, the results will also be unsigned. This\n",
    "    should not be surprising, as the result is consistent with\n",
    "    calculating the difference directly:\n",
    "    >>> u8_arr = np.array([1, 0], dtype=np.uint8)\n",
    "    >>> np.diff(u8_arr)\n",
    "    array([255], dtype=uint8)\n",
    "    >>> u8_arr[1,...] - u8_arr[0,...]\n",
    "    255\n",
    "    If this is not desirable, then the array should be cast to a larger\n",
    "    integer type first:\n",
    "    >>> i16_arr = u8_arr.astype(np.int16)\n",
    "    >>> np.diff(i16_arr)\n",
    "    array([-1], dtype=int16)\n",
    "    Examples\n",
    "    --------\n",
    "    >>> x = np.array([1, 2, 4, 7, 0])\n",
    "    >>> np.diff(x)\n",
    "    array([ 1,  2,  3, -7])\n",
    "    >>> np.diff(x, n=2)\n",
    "    array([  1,   1, -10])\n",
    "    >>> x = np.array([[1, 3, 6, 10], [0, 5, 6, 8]])\n",
    "    >>> np.diff(x)\n",
    "    array([[2, 3, 4],\n",
    "           [5, 1, 2]])\n",
    "    >>> np.diff(x, axis=0)\n",
    "    array([[-1,  2,  0, -2]])\n",
    "    >>> x = np.arange('1066-10-13', '1066-10-16', dtype=np.datetime64)\n",
    "    >>> np.diff(x)\n",
    "    array([1, 1], dtype='timedelta64[D]')\n",
    "    \"\"\"\n",
    "    if n == 0:\n",
    "        return a\n",
    "    if n < 0:\n",
    "        raise ValueError(\n",
    "            \"order must be non-negative but got \" + repr(n))\n",
    "\n",
    "    a = asanyarray(a)\n",
    "    nd = a.ndim\n",
    "    if nd == 0:\n",
    "        raise ValueError(\"diff requires input that is at least one dimensional\")\n",
    "    axis = normalize_axis_index(axis, nd)\n",
    "\n",
    "    combined = []\n",
    "    if prepend is not np._NoValue:\n",
    "        prepend = np.asanyarray(prepend)\n",
    "        if prepend.ndim == 0:\n",
    "            shape = list(a.shape)\n",
    "            shape[axis] = 1\n",
    "            prepend = np.broadcast_to(prepend, tuple(shape))\n",
    "        combined.append(prepend)\n",
    "\n",
    "    combined.append(a)\n",
    "\n",
    "    if append is not np._NoValue:\n",
    "        append = np.asanyarray(append)\n",
    "        if append.ndim == 0:\n",
    "            shape = list(a.shape)\n",
    "            shape[axis] = 1\n",
    "            append = np.broadcast_to(append, tuple(shape))\n",
    "        combined.append(append)\n",
    "\n",
    "    if len(combined) > 1:\n",
    "        a = np.concatenate(combined, axis)\n",
    "\n",
    "    slice1 = [slice(None)] * nd\n",
    "    slice2 = [slice(None)] * nd\n",
    "    slice1[axis] = slice(1, None)\n",
    "    slice2[axis] = slice(None, -1)\n",
    "    slice1 = tuple(slice1)\n",
    "    slice2 = tuple(slice2)\n",
    "\n",
    "    op = not_equal if a.dtype == np.bool_ else subtract\n",
    "    for _ in range(n):\n",
    "        a = op(a[slice1], a[slice2])\n",
    "\n",
    "    return a\n",
    "\n",
    "\n",
    "def _interp_dispatcher(x, xp, fp, left=None, right=None, period=None):\n",
    "    return (x, xp, fp)\n",
    "\n",
    "\n",
    "@array_function_dispatch(_interp_dispatcher)\n",
    "def interp(x, xp, fp, left=None, right=None, period=None):\n",
    "    \"\"\"\n",
    "    One-dimensional linear interpolation.\n",
    "    Returns the one-dimensional piecewise linear interpolant to a function\n",
    "    with given discrete data points (`xp`, `fp`), evaluated at `x`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array_like\n",
    "        The x-coordinates at which to evaluate the interpolated values.\n",
    "    xp : 1-D sequence of floats\n",
    "        The x-coordinates of the data points, must be increasing if argument\n",
    "        `period` is not specified. Otherwise, `xp` is internally sorted after\n",
    "        normalizing the periodic boundaries with ``xp = xp % period``.\n",
    "    fp : 1-D sequence of float or complex\n",
    "        The y-coordinates of the data points, same length as `xp`.\n",
    "    left : optional float or complex corresponding to fp\n",
    "        Value to return for `x < xp[0]`, default is `fp[0]`.\n",
    "    right : optional float or complex corresponding to fp\n",
    "        Value to return for `x > xp[-1]`, default is `fp[-1]`.\n",
    "    period : None or float, optional\n",
    "        A period for the x-coordinates. This parameter allows the proper\n",
    "        interpolation of angular x-coordinates. Parameters `left` and `right`\n",
    "        are ignored if `period` is specified.\n",
    "        .. versionadded:: 1.10.0\n",
    "    Returns\n",
    "    -------\n",
    "    y : float or complex (corresponding to fp) or ndarray\n",
    "        The interpolated values, same shape as `x`.\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If `xp` and `fp` have different length\n",
    "        If `xp` or `fp` are not 1-D sequences\n",
    "        If `period == 0`\n",
    "    See Also\n",
    "    --------\n",
    "    scipy.interpolate\n",
    "    Notes\n",
    "    -----\n",
    "    The x-coordinate sequence is expected to be increasing, but this is not\n",
    "    explicitly enforced.  However, if the sequence `xp` is non-increasing,\n",
    "    interpolation results are meaningless.\n",
    "    Note that, since NaN is unsortable, `xp` also cannot contain NaNs.\n",
    "    A simple check for `xp` being strictly increasing is::\n",
    "        np.all(np.diff(xp) > 0)\n",
    "    Examples\n",
    "    --------\n",
    "    >>> xp = [1, 2, 3]\n",
    "    >>> fp = [3, 2, 0]\n",
    "    >>> np.interp(2.5, xp, fp)\n",
    "    1.0\n",
    "    >>> np.interp([0, 1, 1.5, 2.72, 3.14], xp, fp)\n",
    "    array([3.  , 3.  , 2.5 , 0.56, 0.  ])\n",
    "    >>> UNDEF = -99.0\n",
    "    >>> np.interp(3.14, xp, fp, right=UNDEF)\n",
    "    -99.0\n",
    "    Plot an interpolant to the sine function:\n",
    "    >>> x = np.linspace(0, 2*np.pi, 10)\n",
    "    >>> y = np.sin(x)\n",
    "    >>> xvals = np.linspace(0, 2*np.pi, 50)\n",
    "    >>> yinterp = np.interp(xvals, x, y)\n",
    "    >>> import matplotlib.pyplot as plt\n",
    "    >>> plt.plot(x, y, 'o')\n",
    "    [<matplotlib.lines.Line2D object at 0x...>]\n",
    "    >>> plt.plot(xvals, yinterp, '-x')\n",
    "    [<matplotlib.lines.Line2D object at 0x...>]\n",
    "    >>> plt.show()\n",
    "    Interpolation with periodic x-coordinates:\n",
    "    >>> x = [-180, -170, -185, 185, -10, -5, 0, 365]\n",
    "    >>> xp = [190, -190, 350, -350]\n",
    "    >>> fp = [5, 10, 3, 4]\n",
    "    >>> np.interp(x, xp, fp, period=360)\n",
    "    array([7.5 , 5.  , 8.75, 6.25, 3.  , 3.25, 3.5 , 3.75])\n",
    "    Complex interpolation:\n",
    "    >>> x = [1.5, 4.0]\n",
    "    >>> xp = [2,3,5]\n",
    "    >>> fp = [1.0j, 0, 2+3j]\n",
    "    >>> np.interp(x, xp, fp)\n",
    "    array([0.+1.j , 1.+1.5j])\n",
    "    \"\"\"\n",
    "\n",
    "    fp = np.asarray(fp)\n",
    "\n",
    "    if np.iscomplexobj(fp):\n",
    "        interp_func = compiled_interp_complex\n",
    "        input_dtype = np.complex128\n",
    "    else:\n",
    "        interp_func = compiled_interp\n",
    "        input_dtype = np.float64\n",
    "\n",
    "    if period is not None:\n",
    "        if period == 0:\n",
    "            raise ValueError(\"period must be a non-zero value\")\n",
    "        period = abs(period)\n",
    "        left = None\n",
    "        right = None\n",
    "\n",
    "        x = np.asarray(x, dtype=np.float64)\n",
    "        xp = np.asarray(xp, dtype=np.float64)\n",
    "        fp = np.asarray(fp, dtype=input_dtype)\n",
    "\n",
    "        if xp.ndim != 1 or fp.ndim != 1:\n",
    "            raise ValueError(\"Data points must be 1-D sequences\")\n",
    "        if xp.shape[0] != fp.shape[0]:\n",
    "            raise ValueError(\"fp and xp are not of the same length\")\n",
    "        # normalizing periodic boundaries\n",
    "        x = x % period\n",
    "        xp = xp % period\n",
    "        asort_xp = np.argsort(xp)\n",
    "        xp = xp[asort_xp]\n",
    "        fp = fp[asort_xp]\n",
    "        xp = np.concatenate((xp[-1:]-period, xp, xp[0:1]+period))\n",
    "        fp = np.concatenate((fp[-1:], fp, fp[0:1]))\n",
    "\n",
    "    return interp_func(x, xp, fp, left, right)\n",
    "\n",
    "\n",
    "def _angle_dispatcher(z, deg=None):\n",
    "    return (z,)\n",
    "\n",
    "\n",
    "@array_function_dispatch(_angle_dispatcher)\n",
    "def angle(z, deg=False):\n",
    "    \"\"\"\n",
    "    Return the angle of the complex argument.\n",
    "    Parameters\n",
    "    ----------\n",
    "    z : array_like\n",
    "        A complex number or sequence of complex numbers.\n",
    "    deg : bool, optional\n",
    "        Return angle in degrees if True, radians if False (default).\n",
    "    Returns\n",
    "    -------\n",
    "    angle : ndarray or scalar\n",
    "        The counterclockwise angle from the positive real axis on the complex\n",
    "        plane in the range ``(-pi, pi]``, with dtype as numpy.float64.\n",
    "        ..versionchanged:: 1.16.0\n",
    "            This function works on subclasses of ndarray like `ma.array`.\n",
    "    See Also\n",
    "    --------\n",
    "    arctan2\n",
    "    absolute\n",
    "    Notes\n",
    "    -----\n",
    "    Although the angle of the complex number 0 is undefined, ``numpy.angle(0)``\n",
    "    returns the value 0.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> np.angle([1.0, 1.0j, 1+1j])               # in radians\n",
    "    array([ 0.        ,  1.57079633,  0.78539816]) # may vary\n",
    "    >>> np.angle(1+1j, deg=True)                  # in degrees\n",
    "    45.0\n",
    "    \"\"\"\n",
    "    z = asanyarray(z)\n",
    "    if issubclass(z.dtype.type, _nx.complexfloating):\n",
    "        zimag = z.imag\n",
    "        zreal = z.real\n",
    "    else:\n",
    "        zimag = 0\n",
    "        zreal = z\n",
    "\n",
    "    a = arctan2(zimag, zreal)\n",
    "    if deg:\n",
    "        a *= 180/pi\n",
    "    return a\n",
    "\n",
    "\n",
    "def _unwrap_dispatcher(p, discont=None, axis=None):\n",
    "    return (p,)\n",
    "\n",
    "\n",
    "@array_function_dispatch(_unwrap_dispatcher)\n",
    "def unwrap(p, discont=pi, axis=-1):\n",
    "    \"\"\"\n",
    "    Unwrap by changing deltas between values to 2*pi complement.\n",
    "    Unwrap radian phase `p` by changing absolute jumps greater than\n",
    "    `discont` to their 2*pi complement along the given axis.\n",
    "    Parameters\n",
    "    ----------\n",
    "    p : array_like\n",
    "        Input array.\n",
    "    discont : float, optional\n",
    "        Maximum discontinuity between values, default is ``pi``.\n",
    "    axis : int, optional\n",
    "        Axis along which unwrap will operate, default is the last axis.\n",
    "    Returns\n",
    "    -------\n",
    "    out : ndarray\n",
    "        Output array.\n",
    "    See Also\n",
    "    --------\n",
    "    rad2deg, deg2rad\n",
    "    Notes\n",
    "    -----\n",
    "    If the discontinuity in `p` is smaller than ``pi``, but larger than\n",
    "    `discont`, no unwrapping is done because taking the 2*pi complement\n",
    "    would only make the discontinuity larger.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> phase = np.linspace(0, np.pi, num=5)\n",
    "    >>> phase[3:] += np.pi\n",
    "    >>> phase\n",
    "    array([ 0.        ,  0.78539816,  1.57079633,  5.49778714,  6.28318531]) # may vary\n",
    "    >>> np.unwrap(phase)\n",
    "    array([ 0.        ,  0.78539816,  1.57079633, -0.78539816,  0.        ]) # may vary\n",
    "    \"\"\"\n",
    "    p = asarray(p)\n",
    "    nd = p.ndim\n",
    "    dd = diff(p, axis=axis)\n",
    "    slice1 = [slice(None, None)]*nd     # full slices\n",
    "    slice1[axis] = slice(1, None)\n",
    "    slice1 = tuple(slice1)\n",
    "    ddmod = mod(dd + pi, 2*pi) - pi\n",
    "    _nx.copyto(ddmod, pi, where=(ddmod == -pi) & (dd > 0))\n",
    "    ph_correct = ddmod - dd\n",
    "    _nx.copyto(ph_correct, 0, where=abs(dd) < discont)\n",
    "    up = array(p, copy=True, dtype='d')\n",
    "    up[slice1] = p[slice1] + ph_correct.cumsum(axis)\n",
    "    return up\n",
    "\n",
    "\n",
    "def _sort_complex(a):\n",
    "    return (a,)\n",
    "\n",
    "\n",
    "@array_function_dispatch(_sort_complex)\n",
    "def sort_complex(a):\n",
    "    \"\"\"\n",
    "    Sort a complex array using the real part first, then the imaginary part.\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : array_like\n",
    "        Input array\n",
    "    Returns\n",
    "    -------\n",
    "    out : complex ndarray\n",
    "        Always returns a sorted complex array.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> np.sort_complex([5, 3, 6, 2, 1])\n",
    "    array([1.+0.j, 2.+0.j, 3.+0.j, 5.+0.j, 6.+0.j])\n",
    "    >>> np.sort_complex([1 + 2j, 2 - 1j, 3 - 2j, 3 - 3j, 3 + 5j])\n",
    "    array([1.+2.j,  2.-1.j,  3.-3.j,  3.-2.j,  3.+5.j])\n",
    "    \"\"\"\n",
    "    b = array(a, copy=True)\n",
    "    b.sort()\n",
    "    if not issubclass(b.dtype.type, _nx.complexfloating):\n",
    "        if b.dtype.char in 'bhBH':\n",
    "            return b.astype('F')\n",
    "        elif b.dtype.char == 'g':\n",
    "            return b.astype('G')\n",
    "        else:\n",
    "            return b.astype('D')\n",
    "    else:\n",
    "        return b\n",
    "\n",
    "\n",
    "def _trim_zeros(filt, trim=None):\n",
    "    return (filt,)\n",
    "\n",
    "\n",
    "@array_function_dispatch(_trim_zeros)\n",
    "def trim_zeros(filt, trim='fb'):\n",
    "    \"\"\"\n",
    "    Trim the leading and/or trailing zeros from a 1-D array or sequence.\n",
    "    Parameters\n",
    "    ----------\n",
    "    filt : 1-D array or sequence\n",
    "        Input array.\n",
    "    trim : str, optional\n",
    "        A string with 'f' representing trim from front and 'b' to trim from\n",
    "        back. Default is 'fb', trim zeros from both front and back of the\n",
    "        array.\n",
    "    Returns\n",
    "    -------\n",
    "    trimmed : 1-D array or sequence\n",
    "        The result of trimming the input. The input data type is preserved.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> a = np.array((0, 0, 0, 1, 2, 3, 0, 2, 1, 0))\n",
    "    >>> np.trim_zeros(a)\n",
    "    array([1, 2, 3, 0, 2, 1])\n",
    "    >>> np.trim_zeros(a, 'b')\n",
    "    array([0, 0, 0, ..., 0, 2, 1])\n",
    "    The input data type is preserved, list/tuple in means list/tuple out.\n",
    "    >>> np.trim_zeros([0, 1, 2, 0])\n",
    "    [1, 2]\n",
    "    \"\"\"\n",
    "    first = 0\n",
    "    trim = trim.upper()\n",
    "    if 'F' in trim:\n",
    "        for i in filt:\n",
    "            if i != 0.:\n",
    "                break\n",
    "            else:\n",
    "                first = first + 1\n",
    "    last = len(filt)\n",
    "    if 'B' in trim:\n",
    "        for i in filt[::-1]:\n",
    "            if i != 0.:\n",
    "                break\n",
    "            else:\n",
    "                last = last - 1\n",
    "    return filt[first:last]\n",
    "\n",
    "\n",
    "def _extract_dispatcher(condition, arr):\n",
    "    return (condition, arr)\n",
    "\n",
    "\n",
    "@array_function_dispatch(_extract_dispatcher)\n",
    "def extract(condition, arr):\n",
    "    \"\"\"\n",
    "    Return the elements of an array that satisfy some condition.\n",
    "    This is equivalent to ``np.compress(ravel(condition), ravel(arr))``.  If\n",
    "    `condition` is boolean ``np.extract`` is equivalent to ``arr[condition]``.\n",
    "    Note that `place` does the exact opposite of `extract`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    condition : array_like\n",
    "        An array whose nonzero or True entries indicate the elements of `arr`\n",
    "        to extract.\n",
    "    arr : array_like\n",
    "        Input array of the same size as `condition`.\n",
    "    Returns\n",
    "    -------\n",
    "    extract : ndarray\n",
    "        Rank 1 array of values from `arr` where `condition` is True.\n",
    "    See Also\n",
    "    --------\n",
    "    take, put, copyto, compress, place\n",
    "    Examples\n",
    "    --------\n",
    "    >>> arr = np.arange(12).reshape((3, 4))\n",
    "    >>> arr\n",
    "    array([[ 0,  1,  2,  3],\n",
    "           [ 4,  5,  6,  7],\n",
    "           [ 8,  9, 10, 11]])\n",
    "    >>> condition = np.mod(arr, 3)==0\n",
    "    >>> condition\n",
    "    array([[ True, False, False,  True],\n",
    "           [False, False,  True, False],\n",
    "           [False,  True, False, False]])\n",
    "    >>> np.extract(condition, arr)\n",
    "    array([0, 3, 6, 9])\n",
    "    If `condition` is boolean:\n",
    "    >>> arr[condition]\n",
    "    array([0, 3, 6, 9])\n",
    "    \"\"\"\n",
    "    return _nx.take(ravel(arr), nonzero(ravel(condition))[0])\n",
    "\n",
    "\n",
    "def _place_dispatcher(arr, mask, vals):\n",
    "    return (arr, mask, vals)\n",
    "\n",
    "\n",
    "@array_function_dispatch(_place_dispatcher)\n",
    "def place(arr, mask, vals):\n",
    "    \"\"\"\n",
    "    Change elements of an array based on conditional and input values.\n",
    "    Similar to ``np.copyto(arr, vals, where=mask)``, the difference is that\n",
    "    `place` uses the first N elements of `vals`, where N is the number of\n",
    "    True values in `mask`, while `copyto` uses the elements where `mask`\n",
    "    is True.\n",
    "    Note that `extract` does the exact opposite of `place`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : ndarray\n",
    "        Array to put data into.\n",
    "    mask : array_like\n",
    "        Boolean mask array. Must have the same size as `a`.\n",
    "    vals : 1-D sequence\n",
    "        Values to put into `a`. Only the first N elements are used, where\n",
    "        N is the number of True values in `mask`. If `vals` is smaller\n",
    "        than N, it will be repeated, and if elements of `a` are to be masked,\n",
    "        this sequence must be non-empty.\n",
    "    See Also\n",
    "    --------\n",
    "    copyto, put, take, extract\n",
    "    Examples\n",
    "    --------\n",
    "    >>> arr = np.arange(6).reshape(2, 3)\n",
    "    >>> np.place(arr, arr>2, [44, 55])\n",
    "    >>> arr\n",
    "    array([[ 0,  1,  2],\n",
    "           [44, 55, 44]])\n",
    "    \"\"\"\n",
    "    if not isinstance(arr, np.ndarray):\n",
    "        raise TypeError(\"argument 1 must be numpy.ndarray, \"\n",
    "                        \"not {name}\".format(name=type(arr).__name__))\n",
    "\n",
    "    return _insert(arr, mask, vals)\n",
    "\n",
    "\n",
    "def disp(mesg, device=None, linefeed=True):\n",
    "    \"\"\"\n",
    "    Display a message on a device.\n",
    "    Parameters\n",
    "    ----------\n",
    "    mesg : str\n",
    "        Message to display.\n",
    "    device : object\n",
    "        Device to write message. If None, defaults to ``sys.stdout`` which is\n",
    "        very similar to ``print``. `device` needs to have ``write()`` and\n",
    "        ``flush()`` methods.\n",
    "    linefeed : bool, optional\n",
    "        Option whether to print a line feed or not. Defaults to True.\n",
    "    Raises\n",
    "    ------\n",
    "    AttributeError\n",
    "        If `device` does not have a ``write()`` or ``flush()`` method.\n",
    "    Examples\n",
    "    --------\n",
    "    Besides ``sys.stdout``, a file-like object can also be used as it has\n",
    "    both required methods:\n",
    "    >>> from io import StringIO\n",
    "    >>> buf = StringIO()\n",
    "    >>> np.disp(u'\"Display\" in a file', device=buf)\n",
    "    >>> buf.getvalue()\n",
    "    '\"Display\" in a file\\\\n'\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = sys.stdout\n",
    "    if linefeed:\n",
    "        device.write('%s\\n' % mesg)\n",
    "    else:\n",
    "        device.write('%s' % mesg)\n",
    "    device.flush()\n",
    "    return\n",
    "\n",
    "\n",
    "# See https://docs.scipy.org/doc/numpy/reference/c-api.generalized-ufuncs.html\n",
    "_DIMENSION_NAME = r'\\w+'\n",
    "_CORE_DIMENSION_LIST = '(?:{0:}(?:,{0:})*)?'.format(_DIMENSION_NAME)\n",
    "_ARGUMENT = r'\\({}\\)'.format(_CORE_DIMENSION_LIST)\n",
    "_ARGUMENT_LIST = '{0:}(?:,{0:})*'.format(_ARGUMENT)\n",
    "_SIGNATURE = '^{0:}->{0:}$'.format(_ARGUMENT_LIST)\n",
    "\n",
    "\n",
    "def _parse_gufunc_signature(signature):\n",
    "    \"\"\"\n",
    "    Parse string signatures for a generalized universal function.\n",
    "    Arguments\n",
    "    ---------\n",
    "    signature : string\n",
    "        Generalized universal function signature, e.g., ``(m,n),(n,p)->(m,p)``\n",
    "        for ``np.matmul``.\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple of input and output core dimensions parsed from the signature, each\n",
    "    of the form List[Tuple[str, ...]].\n",
    "    \"\"\"\n",
    "    if not re.match(_SIGNATURE, signature):\n",
    "        raise ValueError(\n",
    "            'not a valid gufunc signature: {}'.format(signature))\n",
    "    return tuple([tuple(re.findall(_DIMENSION_NAME, arg))\n",
    "                  for arg in re.findall(_ARGUMENT, arg_list)]\n",
    "                 for arg_list in signature.split('->'))\n",
    "\n",
    "\n",
    "def _update_dim_sizes(dim_sizes, arg, core_dims):\n",
    "    \"\"\"\n",
    "    Incrementally check and update core dimension sizes for a single argument.\n",
    "    Arguments\n",
    "    ---------\n",
    "    dim_sizes : Dict[str, int]\n",
    "        Sizes of existing core dimensions. Will be updated in-place.\n",
    "    arg : ndarray\n",
    "        Argument to examine.\n",
    "    core_dims : Tuple[str, ...]\n",
    "        Core dimensions for this argument.\n",
    "    \"\"\"\n",
    "    if not core_dims:\n",
    "        return\n",
    "\n",
    "    num_core_dims = len(core_dims)\n",
    "    if arg.ndim < num_core_dims:\n",
    "        raise ValueError(\n",
    "            '%d-dimensional argument does not have enough '\n",
    "            'dimensions for all core dimensions %r'\n",
    "            % (arg.ndim, core_dims))\n",
    "\n",
    "    core_shape = arg.shape[-num_core_dims:]\n",
    "    for dim, size in zip(core_dims, core_shape):\n",
    "        if dim in dim_sizes:\n",
    "            if size != dim_sizes[dim]:\n",
    "                raise ValueError(\n",
    "                    'inconsistent size for core dimension %r: %r vs %r'\n",
    "                    % (dim, size, dim_sizes[dim]))\n",
    "        else:\n",
    "            dim_sizes[dim] = size\n",
    "\n",
    "\n",
    "def _parse_input_dimensions(args, input_core_dims):\n",
    "    \"\"\"\n",
    "    Parse broadcast and core dimensions for vectorize with a signature.\n",
    "    Arguments\n",
    "    ---------\n",
    "    args : Tuple[ndarray, ...]\n",
    "        Tuple of input arguments to examine.\n",
    "    input_core_dims : List[Tuple[str, ...]]\n",
    "        List of core dimensions corresponding to each input.\n",
    "    Returns\n",
    "    -------\n",
    "    broadcast_shape : Tuple[int, ...]\n",
    "        Common shape to broadcast all non-core dimensions to.\n",
    "    dim_sizes : Dict[str, int]\n",
    "        Common sizes for named core dimensions.\n",
    "    \"\"\"\n",
    "    broadcast_args = []\n",
    "    dim_sizes = {}\n",
    "    for arg, core_dims in zip(args, input_core_dims):\n",
    "        _update_dim_sizes(dim_sizes, arg, core_dims)\n",
    "        ndim = arg.ndim - len(core_dims)\n",
    "        dummy_array = np.lib.stride_tricks.as_strided(0, arg.shape[:ndim])\n",
    "        broadcast_args.append(dummy_array)\n",
    "    broadcast_shape = np.lib.stride_tricks._broadcast_shape(*broadcast_args)\n",
    "    return broadcast_shape, dim_sizes\n",
    "\n",
    "\n",
    "def _calculate_shapes(broadcast_shape, dim_sizes, list_of_core_dims):\n",
    "    \"\"\"Helper for calculating broadcast shapes with core dimensions.\"\"\"\n",
    "    return [broadcast_shape + tuple(dim_sizes[dim] for dim in core_dims)\n",
    "            for core_dims in list_of_core_dims]\n",
    "\n",
    "\n",
    "def _create_arrays(broadcast_shape, dim_sizes, list_of_core_dims, dtypes):\n",
    "    \"\"\"Helper for creating output arrays in vectorize.\"\"\"\n",
    "    shapes = _calculate_shapes(broadcast_shape, dim_sizes, list_of_core_dims)\n",
    "    arrays = tuple(np.empty(shape, dtype=dtype)\n",
    "                   for shape, dtype in zip(shapes, dtypes))\n",
    "    return arrays\n",
    "\n",
    "\n",
    "@set_module('numpy')\n",
    "class vectorize:\n",
    "    \"\"\"\n",
    "    vectorize(pyfunc, otypes=None, doc=None, excluded=None, cache=False,\n",
    "              signature=None)\n",
    "    Generalized function class.\n",
    "    Define a vectorized function which takes a nested sequence of objects or\n",
    "    numpy arrays as inputs and returns a single numpy array or a tuple of numpy\n",
    "    arrays. The vectorized function evaluates `pyfunc` over successive tuples\n",
    "    of the input arrays like the python map function, except it uses the\n",
    "    broadcasting rules of numpy.\n",
    "    The data type of the output of `vectorized` is determined by calling\n",
    "    the function with the first element of the input.  This can be avoided\n",
    "    by specifying the `otypes` argument.\n",
    "    Parameters\n",
    "    ----------\n",
    "    pyfunc : callable\n",
    "        A python function or method.\n",
    "    otypes : str or list of dtypes, optional\n",
    "        The output data type. It must be specified as either a string of\n",
    "        typecode characters or a list of data type specifiers. There should\n",
    "        be one data type specifier for each output.\n",
    "    doc : str, optional\n",
    "        The docstring for the function. If None, the docstring will be the\n",
    "        ``pyfunc.__doc__``.\n",
    "    excluded : set, optional\n",
    "        Set of strings or integers representing the positional or keyword\n",
    "        arguments for which the function will not be vectorized.  These will be\n",
    "        passed directly to `pyfunc` unmodified.\n",
    "        .. versionadded:: 1.7.0\n",
    "    cache : bool, optional\n",
    "       If `True`, then cache the first function call that determines the number\n",
    "       of outputs if `otypes` is not provided.\n",
    "        .. versionadded:: 1.7.0\n",
    "    signature : string, optional\n",
    "        Generalized universal function signature, e.g., ``(m,n),(n)->(m)`` for\n",
    "        vectorized matrix-vector multiplication. If provided, ``pyfunc`` will\n",
    "        be called with (and expected to return) arrays with shapes given by the\n",
    "        size of corresponding core dimensions. By default, ``pyfunc`` is\n",
    "        assumed to take scalars as input and output.\n",
    "        .. versionadded:: 1.12.0\n",
    "    Returns\n",
    "    -------\n",
    "    vectorized : callable\n",
    "        Vectorized function.\n",
    "    See Also\n",
    "    --------\n",
    "    frompyfunc : Takes an arbitrary Python function and returns a ufunc\n",
    "    Notes\n",
    "    -----\n",
    "    The `vectorize` function is provided primarily for convenience, not for\n",
    "    performance. The implementation is essentially a for loop.\n",
    "    If `otypes` is not specified, then a call to the function with the\n",
    "    first argument will be used to determine the number of outputs.  The\n",
    "    results of this call will be cached if `cache` is `True` to prevent\n",
    "    calling the function twice.  However, to implement the cache, the\n",
    "    original function must be wrapped which will slow down subsequent\n",
    "    calls, so only do this if your function is expensive.\n",
    "    The new keyword argument interface and `excluded` argument support\n",
    "    further degrades performance.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] :doc:`/reference/c-api/generalized-ufuncs`\n",
    "    Examples\n",
    "    --------\n",
    "    >>> def myfunc(a, b):\n",
    "    ...     \"Return a-b if a>b, otherwise return a+b\"\n",
    "    ...     if a > b:\n",
    "    ...         return a - b\n",
    "    ...     else:\n",
    "    ...         return a + b\n",
    "    >>> vfunc = np.vectorize(myfunc)\n",
    "    >>> vfunc([1, 2, 3, 4], 2)\n",
    "    array([3, 4, 1, 2])\n",
    "    The docstring is taken from the input function to `vectorize` unless it\n",
    "    is specified:\n",
    "    >>> vfunc.__doc__\n",
    "    'Return a-b if a>b, otherwise return a+b'\n",
    "    >>> vfunc = np.vectorize(myfunc, doc='Vectorized `myfunc`')\n",
    "    >>> vfunc.__doc__\n",
    "    'Vectorized `myfunc`'\n",
    "    The output type is determined by evaluating the first element of the input,\n",
    "    unless it is specified:\n",
    "    >>> out = vfunc([1, 2, 3, 4], 2)\n",
    "    >>> type(out[0])\n",
    "    <class 'numpy.int64'>\n",
    "    >>> vfunc = np.vectorize(myfunc, otypes=[float])\n",
    "    >>> out = vfunc([1, 2, 3, 4], 2)\n",
    "    >>> type(out[0])\n",
    "    <class 'numpy.float64'>\n",
    "    The `excluded` argument can be used to prevent vectorizing over certain\n",
    "    arguments.  This can be useful for array-like arguments of a fixed length\n",
    "    such as the coefficients for a polynomial as in `polyval`:\n",
    "    >>> def mypolyval(p, x):\n",
    "    ...     _p = list(p)\n",
    "    ...     res = _p.pop(0)\n",
    "    ...     while _p:\n",
    "    ...         res = res*x + _p.pop(0)\n",
    "    ...     return res\n",
    "    >>> vpolyval = np.vectorize(mypolyval, excluded=['p'])\n",
    "    >>> vpolyval(p=[1, 2, 3], x=[0, 1])\n",
    "    array([3, 6])\n",
    "    Positional arguments may also be excluded by specifying their position:\n",
    "    >>> vpolyval.excluded.add(0)\n",
    "    >>> vpolyval([1, 2, 3], x=[0, 1])\n",
    "    array([3, 6])\n",
    "    The `signature` argument allows for vectorizing functions that act on\n",
    "    non-scalar arrays of fixed length. For example, you can use it for a\n",
    "    vectorized calculation of Pearson correlation coefficient and its p-value:\n",
    "    >>> import scipy.stats\n",
    "    >>> pearsonr = np.vectorize(scipy.stats.pearsonr,\n",
    "    ...                 signature='(n),(n)->(),()')\n",
    "    >>> pearsonr([[0, 1, 2, 3]], [[1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "    (array([ 1., -1.]), array([ 0.,  0.]))\n",
    "    Or for a vectorized convolution:\n",
    "    >>> convolve = np.vectorize(np.convolve, signature='(n),(m)->(k)')\n",
    "    >>> convolve(np.eye(4), [1, 2, 1])\n",
    "    array([[1., 2., 1., 0., 0., 0.],\n",
    "           [0., 1., 2., 1., 0., 0.],\n",
    "           [0., 0., 1., 2., 1., 0.],\n",
    "           [0., 0., 0., 1., 2., 1.]])\n",
    "    \"\"\"\n",
    "    def __init__(self, pyfunc, otypes=None, doc=None, excluded=None,\n",
    "                 cache=False, signature=None):\n",
    "        self.pyfunc = pyfunc\n",
    "        self.cache = cache\n",
    "        self.signature = signature\n",
    "        self._ufunc = {}    # Caching to improve default performance\n",
    "\n",
    "        if doc is None:\n",
    "            self.__doc__ = pyfunc.__doc__\n",
    "        else:\n",
    "            self.__doc__ = doc\n",
    "\n",
    "        if isinstance(otypes, str):\n",
    "            for char in otypes:\n",
    "                if char not in typecodes['All']:\n",
    "                    raise ValueError(\"Invalid otype specified: %s\" % (char,))\n",
    "        elif iterable(otypes):\n",
    "            otypes = ''.join([_nx.dtype(x).char for x in otypes])\n",
    "        elif otypes is not None:\n",
    "            raise ValueError(\"Invalid otype specification\")\n",
    "        self.otypes = otypes\n",
    "\n",
    "        # Excluded variable support\n",
    "        if excluded is None:\n",
    "            excluded = set()\n",
    "        self.excluded = set(excluded)\n",
    "\n",
    "        if signature is not None:\n",
    "            self._in_and_out_core_dims = _parse_gufunc_signature(signature)\n",
    "        else:\n",
    "            self._in_and_out_core_dims = None\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Return arrays with the results of `pyfunc` broadcast (vectorized) over\n",
    "        `args` and `kwargs` not in `excluded`.\n",
    "        \"\"\"\n",
    "        excluded = self.excluded\n",
    "        if not kwargs and not excluded:\n",
    "            func = self.pyfunc\n",
    "            vargs = args\n",
    "        else:\n",
    "            # The wrapper accepts only positional arguments: we use `names` and\n",
    "            # `inds` to mutate `the_args` and `kwargs` to pass to the original\n",
    "            # function.\n",
    "            nargs = len(args)\n",
    "\n",
    "            names = [_n for _n in kwargs if _n not in excluded]\n",
    "            inds = [_i for _i in range(nargs) if _i not in excluded]\n",
    "            the_args = list(args)\n",
    "\n",
    "            def func(*vargs):\n",
    "                for _n, _i in enumerate(inds):\n",
    "                    the_args[_i] = vargs[_n]\n",
    "                kwargs.update(zip(names, vargs[len(inds):]))\n",
    "                return self.pyfunc(*the_args, **kwargs)\n",
    "\n",
    "            vargs = [args[_i] for _i in inds]\n",
    "            vargs.extend([kwargs[_n] for _n in names])\n",
    "\n",
    "        return self._vectorize_call(func=func, args=vargs)\n",
    "\n",
    "    def _get_ufunc_and_otypes(self, func, args):\n",
    "        \"\"\"Return (ufunc, otypes).\"\"\"\n",
    "        # frompyfunc will fail if args is empty\n",
    "        if not args:\n",
    "            raise ValueError('args can not be empty')\n",
    "\n",
    "        if self.otypes is not None:\n",
    "            otypes = self.otypes\n",
    "\n",
    "            # self._ufunc is a dictionary whose keys are the number of\n",
    "            # arguments (i.e. len(args)) and whose values are ufuncs created\n",
    "            # by frompyfunc. len(args) can be different for different calls if\n",
    "            # self.pyfunc has parameters with default values.  We only use the\n",
    "            # cache when func is self.pyfunc, which occurs when the call uses\n",
    "            # only positional arguments and no arguments are excluded.\n",
    "\n",
    "            nin = len(args)\n",
    "            nout = len(self.otypes)\n",
    "            if func is not self.pyfunc or nin not in self._ufunc:\n",
    "                ufunc = frompyfunc(func, nin, nout)\n",
    "            else:\n",
    "                ufunc = None  # We'll get it from self._ufunc\n",
    "            if func is self.pyfunc:\n",
    "                ufunc = self._ufunc.setdefault(nin, ufunc)\n",
    "        else:\n",
    "            # Get number of outputs and output types by calling the function on\n",
    "            # the first entries of args.  We also cache the result to prevent\n",
    "            # the subsequent call when the ufunc is evaluated.\n",
    "            # Assumes that ufunc first evaluates the 0th elements in the input\n",
    "            # arrays (the input values are not checked to ensure this)\n",
    "            args = [asarray(arg) for arg in args]\n",
    "            if builtins.any(arg.size == 0 for arg in args):\n",
    "                raise ValueError('cannot call `vectorize` on size 0 inputs '\n",
    "                                 'unless `otypes` is set')\n",
    "\n",
    "            inputs = [arg.flat[0] for arg in args]\n",
    "            outputs = func(*inputs)\n",
    "\n",
    "            # Performance note: profiling indicates that -- for simple\n",
    "            # functions at least -- this wrapping can almost double the\n",
    "            # execution time.\n",
    "            # Hence we make it optional.\n",
    "            if self.cache:\n",
    "                _cache = [outputs]\n",
    "\n",
    "                def _func(*vargs):\n",
    "                    if _cache:\n",
    "                        return _cache.pop()\n",
    "                    else:\n",
    "                        return func(*vargs)\n",
    "            else:\n",
    "                _func = func\n",
    "\n",
    "            if isinstance(outputs, tuple):\n",
    "                nout = len(outputs)\n",
    "            else:\n",
    "                nout = 1\n",
    "                outputs = (outputs,)\n",
    "\n",
    "            otypes = ''.join([asarray(outputs[_k]).dtype.char\n",
    "                              for _k in range(nout)])\n",
    "\n",
    "            # Performance note: profiling indicates that creating the ufunc is\n",
    "            # not a significant cost compared with wrapping so it seems not\n",
    "            # worth trying to cache this.\n",
    "            ufunc = frompyfunc(_func, len(args), nout)\n",
    "\n",
    "        return ufunc, otypes\n",
    "\n",
    "    def _vectorize_call(self, func, args):\n",
    "        \"\"\"Vectorized call to `func` over positional `args`.\"\"\"\n",
    "        if self.signature is not None:\n",
    "            res = self._vectorize_call_with_signature(func, args)\n",
    "        elif not args:\n",
    "            res = func()\n",
    "        else:\n",
    "            ufunc, otypes = self._get_ufunc_and_otypes(func=func, args=args)\n",
    "\n",
    "            # Convert args to object arrays first\n",
    "            inputs = [array(a, copy=False, subok=True, dtype=object)\n",
    "                      for a in args]\n",
    "\n",
    "            outputs = ufunc(*inputs)\n",
    "\n",
    "            if ufunc.nout == 1:\n",
    "                res = array(outputs, copy=False, subok=True, dtype=otypes[0])\n",
    "            else:\n",
    "                res = tuple([array(x, copy=False, subok=True, dtype=t)\n",
    "                             for x, t in zip(outputs, otypes)])\n",
    "        return res\n",
    "\n",
    "    def _vectorize_call_with_signature(self, func, args):\n",
    "        \"\"\"Vectorized call over positional arguments with a signature.\"\"\"\n",
    "        input_core_dims, output_core_dims = self._in_and_out_core_dims\n",
    "\n",
    "        if len(args) != len(input_core_dims):\n",
    "            raise TypeError('wrong number of positional arguments: '\n",
    "                            'expected %r, got %r'\n",
    "                            % (len(input_core_dims), len(args)))\n",
    "        args = tuple(asanyarray(arg) for arg in args)\n",
    "\n",
    "        broadcast_shape, dim_sizes = _parse_input_dimensions(\n",
    "            args, input_core_dims)\n",
    "        input_shapes = _calculate_shapes(broadcast_shape, dim_sizes,\n",
    "                                         input_core_dims)\n",
    "        args = [np.broadcast_to(arg, shape, subok=True)\n",
    "                for arg, shape in zip(args, input_shapes)]\n",
    "\n",
    "        outputs = None\n",
    "        otypes = self.otypes\n",
    "        nout = len(output_core_dims)\n",
    "\n",
    "        for index in np.ndindex(*broadcast_shape):\n",
    "            results = func(*(arg[index] for arg in args))\n",
    "\n",
    "            n_results = len(results) if isinstance(results, tuple) else 1\n",
    "\n",
    "            if nout != n_results:\n",
    "                raise ValueError(\n",
    "                    'wrong number of outputs from pyfunc: expected %r, got %r'\n",
    "                    % (nout, n_results))\n",
    "\n",
    "            if nout == 1:\n",
    "                results = (results,)\n",
    "\n",
    "            if outputs is None:\n",
    "                for result, core_dims in zip(results, output_core_dims):\n",
    "                    _update_dim_sizes(dim_sizes, result, core_dims)\n",
    "\n",
    "                if otypes is None:\n",
    "                    otypes = [asarray(result).dtype for result in results]\n",
    "\n",
    "                outputs = _create_arrays(broadcast_shape, dim_sizes,\n",
    "                                         output_core_dims, otypes)\n",
    "\n",
    "            for output, result in zip(outputs, results):\n",
    "                output[index] = result\n",
    "\n",
    "        if outputs is None:\n",
    "            # did not call the function even once\n",
    "            if otypes is None:\n",
    "                raise ValueError('cannot call `vectorize` on size 0 inputs '\n",
    "                                 'unless `otypes` is set')\n",
    "            if builtins.any(dim not in dim_sizes\n",
    "                            for dims in output_core_dims\n",
    "                            for dim in dims):\n",
    "                raise ValueError('cannot call `vectorize` with a signature '\n",
    "                                 'including new output dimensions on size 0 '\n",
    "                                 'inputs')\n",
    "            outputs = _create_arrays(broadcast_shape, dim_sizes,\n",
    "                                     output_core_dims, otypes)\n",
    "\n",
    "        return outputs[0] if nout == 1 else outputs\n",
    "\n",
    "\n",
    "def _cov_dispatcher(m, y=None, rowvar=None, bias=None, ddof=None,\n",
    "                    fweights=None, aweights=None):\n",
    "    return (m, y, fweights, aweights)\n",
    "\n",
    "\n",
    "@array_function_dispatch(_cov_dispatcher)\n",
    "def cov(m, y=None, rowvar=True, bias=False, ddof=None, fweights=None,\n",
    "        aweights=None):\n",
    "    \"\"\"\n",
    "    Estimate a covariance matrix, given data and weights.\n",
    "    Covariance indicates the level to which two variables vary together.\n",
    "    If we examine N-dimensional samples, :math:`X = [x_1, x_2, ... x_N]^T`,\n",
    "    then the covariance matrix element :math:`C_{ij}` is the covariance of\n",
    "    :math:`x_i` and :math:`x_j`. The element :math:`C_{ii}` is the variance\n",
    "    of :math:`x_i`.\n",
    "    See the notes for an outline of the algorithm.\n",
    "    Parameters\n",
    "    ----------\n",
    "    m : array_like\n",
    "        A 1-D or 2-D array containing multiple variables and observations.\n",
    "        Each row of `m` represents a variable, and each column a single\n",
    "        observation of all those variables. Also see `rowvar` below.\n",
    "    y : array_like, optional\n",
    "        An additional set of variables and observations. `y` has the same form\n",
    "        as that of `m`.\n",
    "    rowvar : bool, optional\n",
    "        If `rowvar` is True (default), then each row represents a\n",
    "        variable, with observations in the columns. Otherwise, the relationship\n",
    "        is transposed: each column represents a variable, while the rows\n",
    "        contain observations.\n",
    "    bias : bool, optional\n",
    "        Default normalization (False) is by ``(N - 1)``, where ``N`` is the\n",
    "        number of observations given (unbiased estimate). If `bias` is True,\n",
    "        then normalization is by ``N``. These values can be overridden by using\n",
    "        the keyword ``ddof`` in numpy versions >= 1.5.\n",
    "    ddof : int, optional\n",
    "        If not ``None`` the default value implied by `bias` is overridden.\n",
    "        Note that ``ddof=1`` will return the unbiased estimate, even if both\n",
    "        `fweights` and `aweights` are specified, and ``ddof=0`` will return\n",
    "        the simple average. See the notes for the details. The default value\n",
    "        is ``None``.\n",
    "        .. versionadded:: 1.5\n",
    "    fweights : array_like, int, optional\n",
    "        1-D array of integer frequency weights; the number of times each\n",
    "        observation vector should be repeated.\n",
    "        .. versionadded:: 1.10\n",
    "    aweights : array_like, optional\n",
    "        1-D array of observation vector weights. These relative weights are\n",
    "        typically large for observations considered \"important\" and smaller for\n",
    "        observations considered less \"important\". If ``ddof=0`` the array of\n",
    "        weights can be used to assign probabilities to observation vectors.\n",
    "        .. versionadded:: 1.10\n",
    "    Returns\n",
    "    -------\n",
    "    out : ndarray\n",
    "        The covariance matrix of the variables.\n",
    "    See Also\n",
    "    --------\n",
    "    corrcoef : Normalized covariance matrix\n",
    "    Notes\n",
    "    -----\n",
    "    Assume that the observations are in the columns of the observation\n",
    "    array `m` and let ``f = fweights`` and ``a = aweights`` for brevity. The\n",
    "    steps to compute the weighted covariance are as follows::\n",
    "        >>> m = np.arange(10, dtype=np.float64)\n",
    "        >>> f = np.arange(10) * 2\n",
    "        >>> a = np.arange(10) ** 2.\n",
    "        >>> ddof = 1\n",
    "        >>> w = f * a\n",
    "        >>> v1 = np.sum(w)\n",
    "        >>> v2 = np.sum(w * a)\n",
    "        >>> m -= np.sum(m * w, axis=None, keepdims=True) / v1\n",
    "        >>> cov = np.dot(m * w, m.T) * v1 / (v1**2 - ddof * v2)\n",
    "    Note that when ``a == 1``, the normalization factor\n",
    "    ``v1 / (v1**2 - ddof * v2)`` goes over to ``1 / (np.sum(f) - ddof)``\n",
    "    as it should.\n",
    "    Examples\n",
    "    --------\n",
    "    Consider two variables, :math:`x_0` and :math:`x_1`, which\n",
    "    correlate perfectly, but in opposite directions:\n",
    "    >>> x = np.array([[0, 2], [1, 1], [2, 0]]).T\n",
    "    >>> x\n",
    "    array([[0, 1, 2],\n",
    "           [2, 1, 0]])\n",
    "    Note how :math:`x_0` increases while :math:`x_1` decreases. The covariance\n",
    "    matrix shows this clearly:\n",
    "    >>> np.cov(x)\n",
    "    array([[ 1., -1.],\n",
    "           [-1.,  1.]])\n",
    "    Note that element :math:`C_{0,1}`, which shows the correlation between\n",
    "    :math:`x_0` and :math:`x_1`, is negative.\n",
    "    Further, note how `x` and `y` are combined:\n",
    "    >>> x = [-2.1, -1,  4.3]\n",
    "    >>> y = [3,  1.1,  0.12]\n",
    "    >>> X = np.stack((x, y), axis=0)\n",
    "    >>> np.cov(X)\n",
    "    array([[11.71      , -4.286     ], # may vary\n",
    "           [-4.286     ,  2.144133]])\n",
    "    >>> np.cov(x, y)\n",
    "    array([[11.71      , -4.286     ], # may vary\n",
    "           [-4.286     ,  2.144133]])\n",
    "    >>> np.cov(x)\n",
    "    array(11.71)\n",
    "    \"\"\"\n",
    "    # Check inputs\n",
    "    if ddof is not None and ddof != int(ddof):\n",
    "        raise ValueError(\n",
    "            \"ddof must be integer\")\n",
    "\n",
    "    # Handles complex arrays too\n",
    "    m = np.asarray(m)\n",
    "    if m.ndim > 2:\n",
    "        raise ValueError(\"m has more than 2 dimensions\")\n",
    "\n",
    "    if y is None:\n",
    "        dtype = np.result_type(m, np.float64)\n",
    "    else:\n",
    "        y = np.asarray(y)\n",
    "        if y.ndim > 2:\n",
    "            raise ValueError(\"y has more than 2 dimensions\")\n",
    "        dtype = np.result_type(m, y, np.float64)\n",
    "\n",
    "    X = array(m, ndmin=2, dtype=dtype)\n",
    "    if not rowvar and X.shape[0] != 1:\n",
    "        X = X.T\n",
    "    if X.shape[0] == 0:\n",
    "        return np.array([]).reshape(0, 0)\n",
    "    if y is not None:\n",
    "        y = array(y, copy=False, ndmin=2, dtype=dtype)\n",
    "        if not rowvar and y.shape[0] != 1:\n",
    "            y = y.T\n",
    "        X = np.concatenate((X, y), axis=0)\n",
    "\n",
    "    if ddof is None:\n",
    "        if bias == 0:\n",
    "            ddof = 1\n",
    "        else:\n",
    "            ddof = 0\n",
    "\n",
    "    # Get the product of frequencies and weights\n",
    "    w = None\n",
    "    if fweights is not None:\n",
    "        fweights = np.asarray(fweights, dtype=float)\n",
    "        if not np.all(fweights == np.around(fweights)):\n",
    "            raise TypeError(\n",
    "                \"fweights must be integer\")\n",
    "        if fweights.ndim > 1:\n",
    "            raise RuntimeError(\n",
    "                \"cannot handle multidimensional fweights\")\n",
    "        if fweights.shape[0] != X.shape[1]:\n",
    "            raise RuntimeError(\n",
    "                \"incompatible numbers of samples and fweights\")\n",
    "        if any(fweights < 0):\n",
    "            raise ValueError(\n",
    "                \"fweights cannot be negative\")\n",
    "        w = fweights\n",
    "    if aweights is not None:\n",
    "        aweights = np.asarray(aweights, dtype=float)\n",
    "        if aweights.ndim > 1:\n",
    "            raise RuntimeError(\n",
    "                \"cannot handle multidimensional aweights\")\n",
    "        if aweights.shape[0] != X.shape[1]:\n",
    "            raise RuntimeError(\n",
    "                \"incompatible numbers of samples and aweights\")\n",
    "        if any(aweights < 0):\n",
    "            raise ValueError(\n",
    "                \"aweights cannot be negative\")\n",
    "        if w is None:\n",
    "            w = aweights\n",
    "        else:\n",
    "            w *= aweights\n",
    "\n",
    "    avg, w_sum = average(X, axis=1, weights=w, returned=True)\n",
    "    w_sum = w_sum[0]\n",
    "\n",
    "    # Determine the normalization\n",
    "    if w is None:\n",
    "        fact = X.shape[1] - ddof\n",
    "    elif ddof == 0:\n",
    "        fact = w_sum\n",
    "    elif aweights is None:\n",
    "        fact = w_sum - ddof\n",
    "    else:\n",
    "        fact = w_sum - ddof*sum(w*aweights)/w_sum\n",
    "\n",
    "    if fact <= 0:\n",
    "        warnings.warn(\"Degrees of freedom <= 0 for slice\",\n",
    "                      RuntimeWarning, stacklevel=3)\n",
    "        fact = 0.0\n",
    "\n",
    "    X -= avg[:, None]\n",
    "    if w is None:\n",
    "        X_T = X.T\n",
    "    else:\n",
    "        X_T = (X*w).T\n",
    "    c = dot(X, X_T.conj())\n",
    "    c *= np.true_divide(1, fact)\n",
    "    return c.squeeze()\n",
    "\n",
    "\n",
    "def _corrcoef_dispatcher(x, y=None, rowvar=None, bias=None, ddof=None):\n",
    "    return (x, y)\n",
    "\n",
    "\n",
    "@array_function_dispatch(_corrcoef_dispatcher)\n",
    "def corrcoef(x, y=None, rowvar=True, bias=np._NoValue, ddof=np._NoValue):\n",
    "    \"\"\"\n",
    "    Return Pearson product-moment correlation coefficients.\n",
    "    Please refer to the documentation for `cov` for more detail.  The\n",
    "    relationship between the correlation coefficient matrix, `R`, and the\n",
    "    covariance matrix, `C`, is\n",
    "    .. math:: R_{ij} = \\\\frac{ C_{ij} } { \\\\sqrt{ C_{ii} * C_{jj} } }\n",
    "    The values of `R` are between -1 and 1, inclusive.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array_like\n",
    "        A 1-D or 2-D array containing multiple variables and observations.\n",
    "        Each row of `x` represents a variable, and each column a single\n",
    "        observation of all those variables. Also see `rowvar` below.\n",
    "    y : array_like, optional\n",
    "        An additional set of variables and observations. `y` has the same\n",
    "        shape as `x`.\n",
    "    rowvar : bool, optional\n",
    "        If `rowvar` is True (default), then each row represents a\n",
    "        variable, with observations in the columns. Otherwise, the relationship\n",
    "        is transposed: each column represents a variable, while the rows\n",
    "        contain observations.\n",
    "    bias : _NoValue, optional\n",
    "        Has no effect, do not use.\n",
    "        .. deprecated:: 1.10.0\n",
    "    ddof : _NoValue, optional\n",
    "        Has no effect, do not use.\n",
    "        .. deprecated:: 1.10.0\n",
    "    Returns\n",
    "    -------\n",
    "    R : ndarray\n",
    "        The correlation coefficient matrix of the variables.\n",
    "    See Also\n",
    "    --------\n",
    "    cov : Covariance matrix\n",
    "    Notes\n",
    "    -----\n",
    "    Due to floating point rounding the resulting array may not be Hermitian,\n",
    "    the diagonal elements may not be 1, and the elements may not satisfy the\n",
    "    inequality abs(a) <= 1. The real and imaginary parts are clipped to the\n",
    "    interval [-1,  1] in an attempt to improve on that situation but is not\n",
    "    much help in the complex case.\n",
    "    This function accepts but discards arguments `bias` and `ddof`.  This is\n",
    "    for backwards compatibility with previous versions of this function.  These\n",
    "    arguments had no effect on the return values of the function and can be\n",
    "    safely ignored in this and previous versions of numpy.\n",
    "    \n",
    "    Examples\n",
    "    --------   \n",
    "    In this example we generate two random arrays, ``xarr`` and ``yarr``, and\n",
    "    compute the row-wise and column-wise Pearson correlation coefficients, \n",
    "    ``R``. Since ``rowvar`` is  true by  default, we first find the row-wise\n",
    "    Pearson correlation coefficients between the variables of ``xarr``.\n",
    "    >>> import numpy as np\n",
    "    >>> rng = np.random.default_rng(seed=42)\n",
    "    >>> xarr = rng.random((3, 3))\n",
    "    >>> xarr\n",
    "    array([[0.77395605, 0.43887844, 0.85859792],\n",
    "           [0.69736803, 0.09417735, 0.97562235],\n",
    "           [0.7611397 , 0.78606431, 0.12811363]])\n",
    "    >>> R1 = np.corrcoef(xarr)\n",
    "    >>> R1\n",
    "    array([[ 1.        ,  0.99256089, -0.68080986],\n",
    "           [ 0.99256089,  1.        , -0.76492172],\n",
    "           [-0.68080986, -0.76492172,  1.        ]])\n",
    "    \n",
    "    If we add another set of variables and observations ``yarr``, we can \n",
    "    compute the row-wise Pearson correlation coefficients between the\n",
    "    variables in ``xarr`` and ``yarr``.\n",
    "   \n",
    "    >>> yarr = rng.random((3, 3))\n",
    "    >>> yarr\n",
    "    array([[0.45038594, 0.37079802, 0.92676499],\n",
    "           [0.64386512, 0.82276161, 0.4434142 ],\n",
    "           [0.22723872, 0.55458479, 0.06381726]])\n",
    "    >>> R2 = np.corrcoef(xarr, yarr)\n",
    "    >>> R2\n",
    "    array([[ 1.        ,  0.99256089, -0.68080986,  0.75008178, -0.934284  ,\n",
    "            -0.99004057],\n",
    "           [ 0.99256089,  1.        , -0.76492172,  0.82502011, -0.97074098,\n",
    "            -0.99981569],\n",
    "           [-0.68080986, -0.76492172,  1.        , -0.99507202,  0.89721355,\n",
    "             0.77714685],\n",
    "           [ 0.75008178,  0.82502011, -0.99507202,  1.        , -0.93657855,\n",
    "            -0.83571711],\n",
    "           [-0.934284  , -0.97074098,  0.89721355, -0.93657855,  1.        ,\n",
    "             0.97517215],\n",
    "           [-0.99004057, -0.99981569,  0.77714685, -0.83571711,  0.97517215,\n",
    "             1.        ]])\n",
    "    Finally if we use the option ``rowvar=False``, the columns are now\n",
    "    being treated as the variables and we will find the column-wise Pearson \n",
    "    correlation coefficients between variables in ``xarr`` and ``yarr``.\n",
    "    >>> R3 = np.corrcoef(xarr, yarr, rowvar=False)\n",
    "    >>> R3\n",
    "    array([[ 1.        ,  0.77598074, -0.47458546, -0.75078643, -0.9665554 ,\n",
    "             0.22423734],\n",
    "           [ 0.77598074,  1.        , -0.92346708, -0.99923895, -0.58826587,\n",
    "            -0.44069024],\n",
    "           [-0.47458546, -0.92346708,  1.        ,  0.93773029,  0.23297648,\n",
    "             0.75137473],\n",
    "           [-0.75078643, -0.99923895,  0.93773029,  1.        ,  0.55627469,\n",
    "             0.47536961],\n",
    "           [-0.9665554 , -0.58826587,  0.23297648,  0.55627469,  1.        ,\n",
    "            -0.46666491],\n",
    "           [ 0.22423734, -0.44069024,  0.75137473,  0.47536961, -0.46666491,\n",
    "             1.        ]])\n",
    "    \"\"\"\n",
    "    if bias is not np._NoValue or ddof is not np._NoValue:\n",
    "        # 2015-03-15, 1.10\n",
    "        warnings.warn('bias and ddof have no effect and are deprecated',\n",
    "                      DeprecationWarning, stacklevel=3)\n",
    "    c = cov(x, y, rowvar)\n",
    "    try:\n",
    "        d = diag(c)\n",
    "    except ValueError:\n",
    "        # scalar covariance\n",
    "        # nan if incorrect value (nan, inf, 0), 1 otherwise\n",
    "        return c / c\n",
    "    stddev = sqrt(d.real)\n",
    "    c /= stddev[:, None]\n",
    "    c /= stddev[None, :]\n",
    "\n",
    "    # Clip real and imaginary parts to [-1, 1].  This does not guarantee\n",
    "    # abs(a[i,j]) <= 1 for complex arrays, but is the best we can do without\n",
    "    # excessive work.\n",
    "    np.clip(c.real, -1, 1, out=c.real)\n",
    "    if np.iscomplexobj(c):\n",
    "        np.clip(c.imag, -1, 1, out=c.imag)\n",
    "\n",
    "    return c\n",
    "\n",
    "\n",
    "@set_module('numpy')\n",
    "def blackman(M):\n",
    "    \"\"\"\n",
    "    Return the Blackman window.\n",
    "    The Blackman window is a taper formed by using the first three\n",
    "    terms of a summation of cosines. It was designed to have close to the\n",
    "    minimal leakage possible.  It is close to optimal, only slightly worse\n",
    "    than a Kaiser window.\n",
    "    Parameters\n",
    "    ----------\n",
    "    M : int\n",
    "        Number of points in the output window. If zero or less, an empty\n",
    "        array is returned.\n",
    "    Returns\n",
    "    -------\n",
    "    out : ndarray\n",
    "        The window, with the maximum value normalized to one (the value one\n",
    "        appears only if the number of samples is odd).\n",
    "    See Also\n",
    "    --------\n",
    "    bartlett, hamming, hanning, kaiser\n",
    "    Notes\n",
    "    -----\n",
    "    The Blackman window is defined as\n",
    "    .. math::  w(n) = 0.42 - 0.5 \\\\cos(2\\\\pi n/M) + 0.08 \\\\cos(4\\\\pi n/M)\n",
    "    Most references to the Blackman window come from the signal processing\n",
    "    literature, where it is used as one of many windowing functions for\n",
    "    smoothing values.  It is also known as an apodization (which means\n",
    "    \"removing the foot\", i.e. smoothing discontinuities at the beginning\n",
    "    and end of the sampled signal) or tapering function. It is known as a\n",
    "    \"near optimal\" tapering function, almost as good (by some measures)\n",
    "    as the kaiser window.\n",
    "    References\n",
    "    ----------\n",
    "    Blackman, R.B. and Tukey, J.W., (1958) The measurement of power spectra,\n",
    "    Dover Publications, New York.\n",
    "    Oppenheim, A.V., and R.W. Schafer. Discrete-Time Signal Processing.\n",
    "    Upper Saddle River, NJ: Prentice-Hall, 1999, pp. 468-471.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import matplotlib.pyplot as plt\n",
    "    >>> np.blackman(12)\n",
    "    array([-1.38777878e-17,   3.26064346e-02,   1.59903635e-01, # may vary\n",
    "            4.14397981e-01,   7.36045180e-01,   9.67046769e-01,\n",
    "            9.67046769e-01,   7.36045180e-01,   4.14397981e-01,\n",
    "            1.59903635e-01,   3.26064346e-02,  -1.38777878e-17])\n",
    "    Plot the window and the frequency response:\n",
    "    >>> from numpy.fft import fft, fftshift\n",
    "    >>> window = np.blackman(51)\n",
    "    >>> plt.plot(window)\n",
    "    [<matplotlib.lines.Line2D object at 0x...>]\n",
    "    >>> plt.title(\"Blackman window\")\n",
    "    Text(0.5, 1.0, 'Blackman window')\n",
    "    >>> plt.ylabel(\"Amplitude\")\n",
    "    Text(0, 0.5, 'Amplitude')\n",
    "    >>> plt.xlabel(\"Sample\")\n",
    "    Text(0.5, 0, 'Sample')\n",
    "    >>> plt.show()\n",
    "    >>> plt.figure()\n",
    "    <Figure size 640x480 with 0 Axes>\n",
    "    >>> A = fft(window, 2048) / 25.5\n",
    "    >>> mag = np.abs(fftshift(A))\n",
    "    >>> freq = np.linspace(-0.5, 0.5, len(A))\n",
    "    >>> with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    ...     response = 20 * np.log10(mag)\n",
    "    ...\n",
    "    >>> response = np.clip(response, -100, 100)\n",
    "    >>> plt.plot(freq, response)\n",
    "    [<matplotlib.lines.Line2D object at 0x...>]\n",
    "    >>> plt.title(\"Frequency response of Blackman window\")\n",
    "    Text(0.5, 1.0, 'Frequency response of Blackman window')\n",
    "    >>> plt.ylabel(\"Magnitude [dB]\")\n",
    "    Text(0, 0.5, 'Magnitude [dB]')\n",
    "    >>> plt.xlabel(\"Normalized frequency [cycles per sample]\")\n",
    "    Text(0.5, 0, 'Normalized frequency [cycles per sample]')\n",
    "    >>> _ = plt.axis('tight')\n",
    "    >>> plt.show()\n",
    "    \"\"\"\n",
    "    if M < 1:\n",
    "        return array([])\n",
    "    if M == 1:\n",
    "        return ones(1, float)\n",
    "    n = arange(0, M)\n",
    "    return 0.42 - 0.5*cos(2.0*pi*n/(M-1)) + 0.08*cos(4.0*pi*n/(M-1))\n",
    "\n",
    "\n",
    "@set_module('numpy')\n",
    "def bartlett(M):\n",
    "    \"\"\"\n",
    "    Return the Bartlett window.\n",
    "    The Bartlett window is very similar to a triangular window, except\n",
    "    that the end points are at zero.  It is often used in signal\n",
    "    processing for tapering a signal, without generating too much\n",
    "    ripple in the frequency domain.\n",
    "    Parameters\n",
    "    ----------\n",
    "    M : int\n",
    "        Number of points in the output window. If zero or less, an\n",
    "        empty array is returned.\n",
    "    Returns\n",
    "    -------\n",
    "    out : array\n",
    "        The triangular window, with the maximum value normalized to one\n",
    "        (the value one appears only if the number of samples is odd), with\n",
    "        the first and last samples equal to zero.\n",
    "    See Also\n",
    "    --------\n",
    "    blackman, hamming, hanning, kaiser\n",
    "    Notes\n",
    "    -----\n",
    "    The Bartlett window is defined as\n",
    "    .. math:: w(n) = \\\\frac{2}{M-1} \\\\left(\n",
    "              \\\\frac{M-1}{2} - \\\\left|n - \\\\frac{M-1}{2}\\\\right|\n",
    "              \\\\right)\n",
    "    Most references to the Bartlett window come from the signal\n",
    "    processing literature, where it is used as one of many windowing\n",
    "    functions for smoothing values.  Note that convolution with this\n",
    "    window produces linear interpolation.  It is also known as an\n",
    "    apodization (which means\"removing the foot\", i.e. smoothing\n",
    "    discontinuities at the beginning and end of the sampled signal) or\n",
    "    tapering function. The fourier transform of the Bartlett is the product\n",
    "    of two sinc functions.\n",
    "    Note the excellent discussion in Kanasewich.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] M.S. Bartlett, \"Periodogram Analysis and Continuous Spectra\",\n",
    "           Biometrika 37, 1-16, 1950.\n",
    "    .. [2] E.R. Kanasewich, \"Time Sequence Analysis in Geophysics\",\n",
    "           The University of Alberta Press, 1975, pp. 109-110.\n",
    "    .. [3] A.V. Oppenheim and R.W. Schafer, \"Discrete-Time Signal\n",
    "           Processing\", Prentice-Hall, 1999, pp. 468-471.\n",
    "    .. [4] Wikipedia, \"Window function\",\n",
    "           https://en.wikipedia.org/wiki/Window_function\n",
    "    .. [5] W.H. Press,  B.P. Flannery, S.A. Teukolsky, and W.T. Vetterling,\n",
    "           \"Numerical Recipes\", Cambridge University Press, 1986, page 429.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import matplotlib.pyplot as plt\n",
    "    >>> np.bartlett(12)\n",
    "    array([ 0.        ,  0.18181818,  0.36363636,  0.54545455,  0.72727273, # may vary\n",
    "            0.90909091,  0.90909091,  0.72727273,  0.54545455,  0.36363636,\n",
    "            0.18181818,  0.        ])\n",
    "    Plot the window and its frequency response (requires SciPy and matplotlib):\n",
    "    >>> from numpy.fft import fft, fftshift\n",
    "    >>> window = np.bartlett(51)\n",
    "    >>> plt.plot(window)\n",
    "    [<matplotlib.lines.Line2D object at 0x...>]\n",
    "    >>> plt.title(\"Bartlett window\")\n",
    "    Text(0.5, 1.0, 'Bartlett window')\n",
    "    >>> plt.ylabel(\"Amplitude\")\n",
    "    Text(0, 0.5, 'Amplitude')\n",
    "    >>> plt.xlabel(\"Sample\")\n",
    "    Text(0.5, 0, 'Sample')\n",
    "    >>> plt.show()\n",
    "    >>> plt.figure()\n",
    "    <Figure size 640x480 with 0 Axes>\n",
    "    >>> A = fft(window, 2048) / 25.5\n",
    "    >>> mag = np.abs(fftshift(A))\n",
    "    >>> freq = np.linspace(-0.5, 0.5, len(A))\n",
    "    >>> with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    ...     response = 20 * np.log10(mag)\n",
    "    ...\n",
    "    >>> response = np.clip(response, -100, 100)\n",
    "    >>> plt.plot(freq, response)\n",
    "    [<matplotlib.lines.Line2D object at 0x...>]\n",
    "    >>> plt.title(\"Frequency response of Bartlett window\")\n",
    "    Text(0.5, 1.0, 'Frequency response of Bartlett window')\n",
    "    >>> plt.ylabel(\"Magnitude [dB]\")\n",
    "    Text(0, 0.5, 'Magnitude [dB]')\n",
    "    >>> plt.xlabel(\"Normalized frequency [cycles per sample]\")\n",
    "    Text(0.5, 0, 'Normalized frequency [cycles per sample]')\n",
    "    >>> _ = plt.axis('tight')\n",
    "    >>> plt.show()\n",
    "    \"\"\"\n",
    "    if M < 1:\n",
    "        return array([])\n",
    "    if M == 1:\n",
    "        return ones(1, float)\n",
    "    n = arange(0, M)\n",
    "    return where(less_equal(n, (M-1)/2.0), 2.0*n/(M-1), 2.0 - 2.0*n/(M-1))\n",
    "\n",
    "\n",
    "@set_module('numpy')\n",
    "def hanning(M):\n",
    "    \"\"\"\n",
    "    Return the Hanning window.\n",
    "    The Hanning window is a taper formed by using a weighted cosine.\n",
    "    Parameters\n",
    "    ----------\n",
    "    M : int\n",
    "        Number of points in the output window. If zero or less, an\n",
    "        empty array is returned.\n",
    "    Returns\n",
    "    -------\n",
    "    out : ndarray, shape(M,)\n",
    "        The window, with the maximum value normalized to one (the value\n",
    "        one appears only if `M` is odd).\n",
    "    See Also\n",
    "    --------\n",
    "    bartlett, blackman, hamming, kaiser\n",
    "    Notes\n",
    "    -----\n",
    "    The Hanning window is defined as\n",
    "    .. math::  w(n) = 0.5 - 0.5cos\\\\left(\\\\frac{2\\\\pi{n}}{M-1}\\\\right)\n",
    "               \\\\qquad 0 \\\\leq n \\\\leq M-1\n",
    "    The Hanning was named for Julius von Hann, an Austrian meteorologist.\n",
    "    It is also known as the Cosine Bell. Some authors prefer that it be\n",
    "    called a Hann window, to help avoid confusion with the very similar\n",
    "    Hamming window.\n",
    "    Most references to the Hanning window come from the signal processing\n",
    "    literature, where it is used as one of many windowing functions for\n",
    "    smoothing values.  It is also known as an apodization (which means\n",
    "    \"removing the foot\", i.e. smoothing discontinuities at the beginning\n",
    "    and end of the sampled signal) or tapering function.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Blackman, R.B. and Tukey, J.W., (1958) The measurement of power\n",
    "           spectra, Dover Publications, New York.\n",
    "    .. [2] E.R. Kanasewich, \"Time Sequence Analysis in Geophysics\",\n",
    "           The University of Alberta Press, 1975, pp. 106-108.\n",
    "    .. [3] Wikipedia, \"Window function\",\n",
    "           https://en.wikipedia.org/wiki/Window_function\n",
    "    .. [4] W.H. Press,  B.P. Flannery, S.A. Teukolsky, and W.T. Vetterling,\n",
    "           \"Numerical Recipes\", Cambridge University Press, 1986, page 425.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> np.hanning(12)\n",
    "    array([0.        , 0.07937323, 0.29229249, 0.57115742, 0.82743037,\n",
    "           0.97974649, 0.97974649, 0.82743037, 0.57115742, 0.29229249,\n",
    "           0.07937323, 0.        ])\n",
    "    Plot the window and its frequency response:\n",
    "    >>> import matplotlib.pyplot as plt\n",
    "    >>> from numpy.fft import fft, fftshift\n",
    "    >>> window = np.hanning(51)\n",
    "    >>> plt.plot(window)\n",
    "    [<matplotlib.lines.Line2D object at 0x...>]\n",
    "    >>> plt.title(\"Hann window\")\n",
    "    Text(0.5, 1.0, 'Hann window')\n",
    "    >>> plt.ylabel(\"Amplitude\")\n",
    "    Text(0, 0.5, 'Amplitude')\n",
    "    >>> plt.xlabel(\"Sample\")\n",
    "    Text(0.5, 0, 'Sample')\n",
    "    >>> plt.show()\n",
    "    >>> plt.figure()\n",
    "    <Figure size 640x480 with 0 Axes>\n",
    "    >>> A = fft(window, 2048) / 25.5\n",
    "    >>> mag = np.abs(fftshift(A))\n",
    "    >>> freq = np.linspace(-0.5, 0.5, len(A))\n",
    "    >>> with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    ...     response = 20 * np.log10(mag)\n",
    "    ...\n",
    "    >>> response = np.clip(response, -100, 100)\n",
    "    >>> plt.plot(freq, response)\n",
    "    [<matplotlib.lines.Line2D object at 0x...>]\n",
    "    >>> plt.title(\"Frequency response of the Hann window\")\n",
    "    Text(0.5, 1.0, 'Frequency response of the Hann window')\n",
    "    >>> plt.ylabel(\"Magnitude [dB]\")\n",
    "    Text(0, 0.5, 'Magnitude [dB]')\n",
    "    >>> plt.xlabel(\"Normalized frequency [cycles per sample]\")\n",
    "    Text(0.5, 0, 'Normalized frequency [cycles per sample]')\n",
    "    >>> plt.axis('tight')\n",
    "    ...\n",
    "    >>> plt.show()\n",
    "    \"\"\"\n",
    "    if M < 1:\n",
    "        return array([])\n",
    "    if M == 1:\n",
    "        return ones(1, float)\n",
    "    n = arange(0, M)\n",
    "    return 0.5 - 0.5*cos(2.0*pi*n/(M-1))\n",
    "\n",
    "\n",
    "@set_module('numpy')\n",
    "def hamming(M):\n",
    "    \"\"\"\n",
    "    Return the Hamming window.\n",
    "    The Hamming window is a taper formed by using a weighted cosine.\n",
    "    Parameters\n",
    "    ----------\n",
    "    M : int\n",
    "        Number of points in the output window. If zero or less, an\n",
    "        empty array is returned.\n",
    "    Returns\n",
    "    -------\n",
    "    out : ndarray\n",
    "        The window, with the maximum value normalized to one (the value\n",
    "        one appears only if the number of samples is odd).\n",
    "    See Also\n",
    "    --------\n",
    "    bartlett, blackman, hanning, kaiser\n",
    "    Notes\n",
    "    -----\n",
    "    The Hamming window is defined as\n",
    "    .. math::  w(n) = 0.54 - 0.46cos\\\\left(\\\\frac{2\\\\pi{n}}{M-1}\\\\right)\n",
    "               \\\\qquad 0 \\\\leq n \\\\leq M-1\n",
    "    The Hamming was named for R. W. Hamming, an associate of J. W. Tukey\n",
    "    and is described in Blackman and Tukey. It was recommended for\n",
    "    smoothing the truncated autocovariance function in the time domain.\n",
    "    Most references to the Hamming window come from the signal processing\n",
    "    literature, where it is used as one of many windowing functions for\n",
    "    smoothing values.  It is also known as an apodization (which means\n",
    "    \"removing the foot\", i.e. smoothing discontinuities at the beginning\n",
    "    and end of the sampled signal) or tapering function.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Blackman, R.B. and Tukey, J.W., (1958) The measurement of power\n",
    "           spectra, Dover Publications, New York.\n",
    "    .. [2] E.R. Kanasewich, \"Time Sequence Analysis in Geophysics\", The\n",
    "           University of Alberta Press, 1975, pp. 109-110.\n",
    "    .. [3] Wikipedia, \"Window function\",\n",
    "           https://en.wikipedia.org/wiki/Window_function\n",
    "    .. [4] W.H. Press,  B.P. Flannery, S.A. Teukolsky, and W.T. Vetterling,\n",
    "           \"Numerical Recipes\", Cambridge University Press, 1986, page 425.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> np.hamming(12)\n",
    "    array([ 0.08      ,  0.15302337,  0.34890909,  0.60546483,  0.84123594, # may vary\n",
    "            0.98136677,  0.98136677,  0.84123594,  0.60546483,  0.34890909,\n",
    "            0.15302337,  0.08      ])\n",
    "    Plot the window and the frequency response:\n",
    "    >>> import matplotlib.pyplot as plt\n",
    "    >>> from numpy.fft import fft, fftshift\n",
    "    >>> window = np.hamming(51)\n",
    "    >>> plt.plot(window)\n",
    "    [<matplotlib.lines.Line2D object at 0x...>]\n",
    "    >>> plt.title(\"Hamming window\")\n",
    "    Text(0.5, 1.0, 'Hamming window')\n",
    "    >>> plt.ylabel(\"Amplitude\")\n",
    "    Text(0, 0.5, 'Amplitude')\n",
    "    >>> plt.xlabel(\"Sample\")\n",
    "    Text(0.5, 0, 'Sample')\n",
    "    >>> plt.show()\n",
    "    >>> plt.figure()\n",
    "    <Figure size 640x480 with 0 Axes>\n",
    "    >>> A = fft(window, 2048) / 25.5\n",
    "    >>> mag = np.abs(fftshift(A))\n",
    "    >>> freq = np.linspace(-0.5, 0.5, len(A))\n",
    "    >>> response = 20 * np.log10(mag)\n",
    "    >>> response = np.clip(response, -100, 100)\n",
    "    >>> plt.plot(freq, response)\n",
    "    [<matplotlib.lines.Line2D object at 0x...>]\n",
    "    >>> plt.title(\"Frequency response of Hamming window\")\n",
    "    Text(0.5, 1.0, 'Frequency response of Hamming window')\n",
    "    >>> plt.ylabel(\"Magnitude [dB]\")\n",
    "    Text(0, 0.5, 'Magnitude [dB]')\n",
    "    >>> plt.xlabel(\"Normalized frequency [cycles per sample]\")\n",
    "    Text(0.5, 0, 'Normalized frequency [cycles per sample]')\n",
    "    >>> plt.axis('tight')\n",
    "    ...\n",
    "    >>> plt.show()\n",
    "    \"\"\"\n",
    "    if M < 1:\n",
    "        return array([])\n",
    "    if M == 1:\n",
    "        return ones(1, float)\n",
    "    n = arange(0, M)\n",
    "    return 0.54 - 0.46*cos(2.0*pi*n/(M-1))\n",
    "\n",
    "\n",
    "## Code from cephes for i0\n",
    "\n",
    "_i0A = [\n",
    "    -4.41534164647933937950E-18,\n",
    "    3.33079451882223809783E-17,\n",
    "    -2.43127984654795469359E-16,\n",
    "    1.71539128555513303061E-15,\n",
    "    -1.16853328779934516808E-14,\n",
    "    7.67618549860493561688E-14,\n",
    "    -4.85644678311192946090E-13,\n",
    "    2.95505266312963983461E-12,\n",
    "    -1.72682629144155570723E-11,\n",
    "    9.67580903537323691224E-11,\n",
    "    -5.18979560163526290666E-10,\n",
    "    2.65982372468238665035E-9,\n",
    "    -1.30002500998624804212E-8,\n",
    "    6.04699502254191894932E-8,\n",
    "    -2.67079385394061173391E-7,\n",
    "    1.11738753912010371815E-6,\n",
    "    -4.41673835845875056359E-6,\n",
    "    1.64484480707288970893E-5,\n",
    "    -5.75419501008210370398E-5,\n",
    "    1.88502885095841655729E-4,\n",
    "    -5.76375574538582365885E-4,\n",
    "    1.63947561694133579842E-3,\n",
    "    -4.32430999505057594430E-3,\n",
    "    1.05464603945949983183E-2,\n",
    "    -2.37374148058994688156E-2,\n",
    "    4.93052842396707084878E-2,\n",
    "    -9.49010970480476444210E-2,\n",
    "    1.71620901522208775349E-1,\n",
    "    -3.04682672343198398683E-1,\n",
    "    6.76795274409476084995E-1\n",
    "    ]\n",
    "\n",
    "_i0B = [\n",
    "    -7.23318048787475395456E-18,\n",
    "    -4.83050448594418207126E-18,\n",
    "    4.46562142029675999901E-17,\n",
    "    3.46122286769746109310E-17,\n",
    "    -2.82762398051658348494E-16,\n",
    "    -3.42548561967721913462E-16,\n",
    "    1.77256013305652638360E-15,\n",
    "    3.81168066935262242075E-15,\n",
    "    -9.55484669882830764870E-15,\n",
    "    -4.15056934728722208663E-14,\n",
    "    1.54008621752140982691E-14,\n",
    "    3.85277838274214270114E-13,\n",
    "    7.18012445138366623367E-13,\n",
    "    -1.79417853150680611778E-12,\n",
    "    -1.32158118404477131188E-11,\n",
    "    -3.14991652796324136454E-11,\n",
    "    1.18891471078464383424E-11,\n",
    "    4.94060238822496958910E-10,\n",
    "    3.39623202570838634515E-9,\n",
    "    2.26666899049817806459E-8,\n",
    "    2.04891858946906374183E-7,\n",
    "    2.89137052083475648297E-6,\n",
    "    6.88975834691682398426E-5,\n",
    "    3.36911647825569408990E-3,\n",
    "    8.04490411014108831608E-1\n",
    "    ]\n",
    "\n",
    "\n",
    "def _chbevl(x, vals):\n",
    "    b0 = vals[0]\n",
    "    b1 = 0.0\n",
    "\n",
    "    for i in range(1, len(vals)):\n",
    "        b2 = b1\n",
    "        b1 = b0\n",
    "        b0 = x*b1 - b2 + vals[i]\n",
    "\n",
    "    return 0.5*(b0 - b2)\n",
    "\n",
    "\n",
    "def _i0_1(x):\n",
    "    return exp(x) * _chbevl(x/2.0-2, _i0A)\n",
    "\n",
    "\n",
    "def _i0_2(x):\n",
    "    return exp(x) * _chbevl(32.0/x - 2.0, _i0B) / sqrt(x)\n",
    "\n",
    "\n",
    "def _i0_dispatcher(x):\n",
    "    return (x,)\n",
    "\n",
    "\n",
    "@array_function_dispatch(_i0_dispatcher)\n",
    "def i0(x):\n",
    "    \"\"\"\n",
    "    Modified Bessel function of the first kind, order 0.\n",
    "    Usually denoted :math:`I_0`.  This function does broadcast, but will *not*\n",
    "    \"up-cast\" int dtype arguments unless accompanied by at least one float or\n",
    "    complex dtype argument (see Raises below).\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array_like, dtype float or complex\n",
    "        Argument of the Bessel function.\n",
    "    Returns\n",
    "    -------\n",
    "    out : ndarray, shape = x.shape, dtype = x.dtype\n",
    "        The modified Bessel function evaluated at each of the elements of `x`.\n",
    "    Raises\n",
    "    ------\n",
    "    TypeError: array cannot be safely cast to required type\n",
    "        If argument consists exclusively of int dtypes.\n",
    "    See Also\n",
    "    --------\n",
    "    scipy.special.i0, scipy.special.iv, scipy.special.ive\n",
    "    Notes\n",
    "    -----\n",
    "    The scipy implementation is recommended over this function: it is a\n",
    "    proper ufunc written in C, and more than an order of magnitude faster.\n",
    "    We use the algorithm published by Clenshaw [1]_ and referenced by\n",
    "    Abramowitz and Stegun [2]_, for which the function domain is\n",
    "    partitioned into the two intervals [0,8] and (8,inf), and Chebyshev\n",
    "    polynomial expansions are employed in each interval. Relative error on\n",
    "    the domain [0,30] using IEEE arithmetic is documented [3]_ as having a\n",
    "    peak of 5.8e-16 with an rms of 1.4e-16 (n = 30000).\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] C. W. Clenshaw, \"Chebyshev series for mathematical functions\", in\n",
    "           *National Physical Laboratory Mathematical Tables*, vol. 5, London:\n",
    "           Her Majesty's Stationery Office, 1962.\n",
    "    .. [2] M. Abramowitz and I. A. Stegun, *Handbook of Mathematical\n",
    "           Functions*, 10th printing, New York: Dover, 1964, pp. 379.\n",
    "           http://www.math.sfu.ca/~cbm/aands/page_379.htm\n",
    "    .. [3] https://metacpan.org/pod/distribution/Math-Cephes/lib/Math/Cephes.pod#i0:-Modified-Bessel-function-of-order-zero\n",
    "    Examples\n",
    "    --------\n",
    "    >>> np.i0(0.)\n",
    "    array(1.0)  # may vary\n",
    "    >>> np.i0([0., 1. + 2j])\n",
    "    array([ 1.00000000+0.j        ,  0.18785373+0.64616944j])  # may vary\n",
    "    \"\"\"\n",
    "    x = np.asanyarray(x)\n",
    "    x = np.abs(x)\n",
    "    return piecewise(x, [x <= 8.0], [_i0_1, _i0_2])\n",
    "\n",
    "## End of cephes code for i0\n",
    "\n",
    "\n",
    "@set_module('numpy')\n",
    "def kaiser(M, beta):\n",
    "    \"\"\"\n",
    "    Return the Kaiser window.\n",
    "    The Kaiser window is a taper formed by using a Bessel function.\n",
    "    Parameters\n",
    "    ----------\n",
    "    M : int\n",
    "        Number of points in the output window. If zero or less, an\n",
    "        empty array is returned.\n",
    "    beta : float\n",
    "        Shape parameter for window.\n",
    "    Returns\n",
    "    -------\n",
    "    out : array\n",
    "        The window, with the maximum value normalized to one (the value\n",
    "        one appears only if the number of samples is odd).\n",
    "    See Also\n",
    "    --------\n",
    "    bartlett, blackman, hamming, hanning\n",
    "    Notes\n",
    "    -----\n",
    "    The Kaiser window is defined as\n",
    "    .. math::  w(n) = I_0\\\\left( \\\\beta \\\\sqrt{1-\\\\frac{4n^2}{(M-1)^2}}\n",
    "               \\\\right)/I_0(\\\\beta)\n",
    "    with\n",
    "    .. math:: \\\\quad -\\\\frac{M-1}{2} \\\\leq n \\\\leq \\\\frac{M-1}{2},\n",
    "    where :math:`I_0` is the modified zeroth-order Bessel function.\n",
    "    The Kaiser was named for Jim Kaiser, who discovered a simple\n",
    "    approximation to the DPSS window based on Bessel functions.  The Kaiser\n",
    "    window is a very good approximation to the Digital Prolate Spheroidal\n",
    "    Sequence, or Slepian window, which is the transform which maximizes the\n",
    "    energy in the main lobe of the window relative to total energy.\n",
    "    The Kaiser can approximate many other windows by varying the beta\n",
    "    parameter.\n",
    "    ====  =======================\n",
    "    beta  Window shape\n",
    "    ====  =======================\n",
    "    0     Rectangular\n",
    "    5     Similar to a Hamming\n",
    "    6     Similar to a Hanning\n",
    "    8.6   Similar to a Blackman\n",
    "    ====  =======================\n",
    "    A beta value of 14 is probably a good starting point. Note that as beta\n",
    "    gets large, the window narrows, and so the number of samples needs to be\n",
    "    large enough to sample the increasingly narrow spike, otherwise NaNs will\n",
    "    get returned.\n",
    "    Most references to the Kaiser window come from the signal processing\n",
    "    literature, where it is used as one of many windowing functions for\n",
    "    smoothing values.  It is also known as an apodization (which means\n",
    "    \"removing the foot\", i.e. smoothing discontinuities at the beginning\n",
    "    and end of the sampled signal) or tapering function.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] J. F. Kaiser, \"Digital Filters\" - Ch 7 in \"Systems analysis by\n",
    "           digital computer\", Editors: F.F. Kuo and J.F. Kaiser, p 218-285.\n",
    "           John Wiley and Sons, New York, (1966).\n",
    "    .. [2] E.R. Kanasewich, \"Time Sequence Analysis in Geophysics\", The\n",
    "           University of Alberta Press, 1975, pp. 177-178.\n",
    "    .. [3] Wikipedia, \"Window function\",\n",
    "           https://en.wikipedia.org/wiki/Window_function\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import matplotlib.pyplot as plt\n",
    "    >>> np.kaiser(12, 14)\n",
    "     array([7.72686684e-06, 3.46009194e-03, 4.65200189e-02, # may vary\n",
    "            2.29737120e-01, 5.99885316e-01, 9.45674898e-01,\n",
    "            9.45674898e-01, 5.99885316e-01, 2.29737120e-01,\n",
    "            4.65200189e-02, 3.46009194e-03, 7.72686684e-06])\n",
    "    Plot the window and the frequency response:\n",
    "    >>> from numpy.fft import fft, fftshift\n",
    "    >>> window = np.kaiser(51, 14)\n",
    "    >>> plt.plot(window)\n",
    "    [<matplotlib.lines.Line2D object at 0x...>]\n",
    "    >>> plt.title(\"Kaiser window\")\n",
    "    Text(0.5, 1.0, 'Kaiser window')\n",
    "    >>> plt.ylabel(\"Amplitude\")\n",
    "    Text(0, 0.5, 'Amplitude')\n",
    "    >>> plt.xlabel(\"Sample\")\n",
    "    Text(0.5, 0, 'Sample')\n",
    "    >>> plt.show()\n",
    "    >>> plt.figure()\n",
    "    <Figure size 640x480 with 0 Axes>\n",
    "    >>> A = fft(window, 2048) / 25.5\n",
    "    >>> mag = np.abs(fftshift(A))\n",
    "    >>> freq = np.linspace(-0.5, 0.5, len(A))\n",
    "    >>> response = 20 * np.log10(mag)\n",
    "    >>> response = np.clip(response, -100, 100)\n",
    "    >>> plt.plot(freq, response)\n",
    "    [<matplotlib.lines.Line2D object at 0x...>]\n",
    "    >>> plt.title(\"Frequency response of Kaiser window\")\n",
    "    Text(0.5, 1.0, 'Frequency response of Kaiser window')\n",
    "    >>> plt.ylabel(\"Magnitude [dB]\")\n",
    "    Text(0, 0.5, 'Magnitude [dB]')\n",
    "    >>> plt.xlabel(\"Normalized frequency [cycles per sample]\")\n",
    "    Text(0.5, 0, 'Normalized frequency [cycles per sample]')\n",
    "    >>> plt.axis('tight')\n",
    "    (-0.5, 0.5, -100.0, ...) # may vary\n",
    "    >>> plt.show()\n",
    "    \"\"\"\n",
    "    if M == 1:\n",
    "        return np.array([1.])\n",
    "    n = arange(0, M)\n",
    "    alpha = (M-1)/2.0\n",
    "    return i0(beta * sqrt(1-((n-alpha)/alpha)**2.0))/i0(float(beta))\n",
    "\n",
    "\n",
    "def _sinc_dispatcher(x):\n",
    "    return (x,)\n",
    "\n",
    "\n",
    "@array_function_dispatch(_sinc_dispatcher)\n",
    "def sinc(x):\n",
    "    r\"\"\"\n",
    "    Return the normalized sinc function.\n",
    "    The sinc function is :math:`\\sin(\\pi x)/(\\pi x)`.\n",
    "    .. note::\n",
    "        Note the normalization factor of ``pi`` used in the definition.\n",
    "        This is the most commonly used definition in signal processing.\n",
    "        Use ``sinc(x / np.pi)`` to obtain the unnormalized sinc function\n",
    "        :math:`\\sin(x)/(x)` that is more common in mathematics.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : ndarray\n",
    "        Array (possibly multi-dimensional) of values for which to to\n",
    "        calculate ``sinc(x)``.\n",
    "    Returns\n",
    "    -------\n",
    "    out : ndarray\n",
    "        ``sinc(x)``, which has the same shape as the input.\n",
    "    Notes\n",
    "    -----\n",
    "    ``sinc(0)`` is the limit value 1.\n",
    "    The name sinc is short for \"sine cardinal\" or \"sinus cardinalis\".\n",
    "    The sinc function is used in various signal processing applications,\n",
    "    including in anti-aliasing, in the construction of a Lanczos resampling\n",
    "    filter, and in interpolation.\n",
    "    For bandlimited interpolation of discrete-time signals, the ideal\n",
    "    interpolation kernel is proportional to the sinc function.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Weisstein, Eric W. \"Sinc Function.\" From MathWorld--A Wolfram Web\n",
    "           Resource. http://mathworld.wolfram.com/SincFunction.html\n",
    "    .. [2] Wikipedia, \"Sinc function\",\n",
    "           https://en.wikipedia.org/wiki/Sinc_function\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import matplotlib.pyplot as plt\n",
    "    >>> x = np.linspace(-4, 4, 41)\n",
    "    >>> np.sinc(x)\n",
    "     array([-3.89804309e-17,  -4.92362781e-02,  -8.40918587e-02, # may vary\n",
    "            -8.90384387e-02,  -5.84680802e-02,   3.89804309e-17,\n",
    "            6.68206631e-02,   1.16434881e-01,   1.26137788e-01,\n",
    "            8.50444803e-02,  -3.89804309e-17,  -1.03943254e-01,\n",
    "            -1.89206682e-01,  -2.16236208e-01,  -1.55914881e-01,\n",
    "            3.89804309e-17,   2.33872321e-01,   5.04551152e-01,\n",
    "            7.56826729e-01,   9.35489284e-01,   1.00000000e+00,\n",
    "            9.35489284e-01,   7.56826729e-01,   5.04551152e-01,\n",
    "            2.33872321e-01,   3.89804309e-17,  -1.55914881e-01,\n",
    "           -2.16236208e-01,  -1.89206682e-01,  -1.03943254e-01,\n",
    "           -3.89804309e-17,   8.50444803e-02,   1.26137788e-01,\n",
    "            1.16434881e-01,   6.68206631e-02,   3.89804309e-17,\n",
    "            -5.84680802e-02,  -8.90384387e-02,  -8.40918587e-02,\n",
    "            -4.92362781e-02,  -3.89804309e-17])\n",
    "    >>> plt.plot(x, np.sinc(x))\n",
    "    [<matplotlib.lines.Line2D object at 0x...>]\n",
    "    >>> plt.title(\"Sinc Function\")\n",
    "    Text(0.5, 1.0, 'Sinc Function')\n",
    "    >>> plt.ylabel(\"Amplitude\")\n",
    "    Text(0, 0.5, 'Amplitude')\n",
    "    >>> plt.xlabel(\"X\")\n",
    "    Text(0.5, 0, 'X')\n",
    "    >>> plt.show()\n",
    "    \"\"\"\n",
    "    x = np.asanyarray(x)\n",
    "    y = pi * where(x == 0, 1.0e-20, x)\n",
    "    return sin(y)/y\n",
    "\n",
    "\n",
    "def _msort_dispatcher(a):\n",
    "    return (a,)\n",
    "\n",
    "\n",
    "@array_function_dispatch(_msort_dispatcher)\n",
    "def msort(a):\n",
    "    \"\"\"\n",
    "    Return a copy of an array sorted along the first axis.\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : array_like\n",
    "        Array to be sorted.\n",
    "    Returns\n",
    "    -------\n",
    "    sorted_array : ndarray\n",
    "        Array of the same type and shape as `a`.\n",
    "    See Also\n",
    "    --------\n",
    "    sort\n",
    "    Notes\n",
    "    -----\n",
    "    ``np.msort(a)`` is equivalent to  ``np.sort(a, axis=0)``.\n",
    "    \"\"\"\n",
    "    b = array(a, subok=True, copy=True)\n",
    "    b.sort(0)\n",
    "    return b\n",
    "\n",
    "\n",
    "def _ureduce(a, func, **kwargs):\n",
    "    \"\"\"\n",
    "    Internal Function.\n",
    "    Call `func` with `a` as first argument swapping the axes to use extended\n",
    "    axis on functions that don't support it natively.\n",
    "    Returns result and a.shape with axis dims set to 1.\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : array_like\n",
    "        Input array or object that can be converted to an array.\n",
    "    func : callable\n",
    "        Reduction function capable of receiving a single axis argument.\n",
    "        It is called with `a` as first argument followed by `kwargs`.\n",
    "    kwargs : keyword arguments\n",
    "        additional keyword arguments to pass to `func`.\n",
    "    Returns\n",
    "    -------\n",
    "    result : tuple\n",
    "        Result of func(a, **kwargs) and a.shape with axis dims set to 1\n",
    "        which can be used to reshape the result to the same shape a ufunc with\n",
    "        keepdims=True would produce.\n",
    "    \"\"\"\n",
    "    a = np.asanyarray(a)\n",
    "    axis = kwargs.get('axis', None)\n",
    "    if axis is not None:\n",
    "        keepdim = list(a.shape)\n",
    "        nd = a.ndim\n",
    "        axis = _nx.normalize_axis_tuple(axis, nd)\n",
    "\n",
    "        for ax in axis:\n",
    "            keepdim[ax] = 1\n",
    "\n",
    "        if len(axis) == 1:\n",
    "            kwargs['axis'] = axis[0]\n",
    "        else:\n",
    "            keep = set(range(nd)) - set(axis)\n",
    "            nkeep = len(keep)\n",
    "            # swap axis that should not be reduced to front\n",
    "            for i, s in enumerate(sorted(keep)):\n",
    "                a = a.swapaxes(i, s)\n",
    "            # merge reduced axis\n",
    "            a = a.reshape(a.shape[:nkeep] + (-1,))\n",
    "            kwargs['axis'] = -1\n",
    "        keepdim = tuple(keepdim)\n",
    "    else:\n",
    "        keepdim = (1,) * a.ndim\n",
    "\n",
    "    r = func(a, **kwargs)\n",
    "    return r, keepdim\n",
    "\n",
    "\n",
    "def _median_dispatcher(\n",
    "        a, axis=None, out=None, overwrite_input=None, keepdims=None):\n",
    "    return (a, out)\n",
    "\n",
    "\n",
    "@array_function_dispatch(_median_dispatcher)\n",
    "def median(a, axis=None, out=None, overwrite_input=False, keepdims=False):\n",
    "    \"\"\"\n",
    "    Compute the median along the specified axis.\n",
    "    Returns the median of the array elements.\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : array_like\n",
    "        Input array or object that can be converted to an array.\n",
    "    axis : {int, sequence of int, None}, optional\n",
    "        Axis or axes along which the medians are computed. The default\n",
    "        is to compute the median along a flattened version of the array.\n",
    "        A sequence of axes is supported since version 1.9.0.\n",
    "    out : ndarray, optional\n",
    "        Alternative output array in which to place the result. It must\n",
    "        have the same shape and buffer length as the expected output,\n",
    "        but the type (of the output) will be cast if necessary.\n",
    "    overwrite_input : bool, optional\n",
    "       If True, then allow use of memory of input array `a` for\n",
    "       calculations. The input array will be modified by the call to\n",
    "       `median`. This will save memory when you do not need to preserve\n",
    "       the contents of the input array. Treat the input as undefined,\n",
    "       but it will probably be fully or partially sorted. Default is\n",
    "       False. If `overwrite_input` is ``True`` and `a` is not already an\n",
    "       `ndarray`, an error will be raised.\n",
    "    keepdims : bool, optional\n",
    "        If this is set to True, the axes which are reduced are left\n",
    "        in the result as dimensions with size one. With this option,\n",
    "        the result will broadcast correctly against the original `arr`.\n",
    "        .. versionadded:: 1.9.0\n",
    "    Returns\n",
    "    -------\n",
    "    median : ndarray\n",
    "        A new array holding the result. If the input contains integers\n",
    "        or floats smaller than ``float64``, then the output data-type is\n",
    "        ``np.float64``.  Otherwise, the data-type of the output is the\n",
    "        same as that of the input. If `out` is specified, that array is\n",
    "        returned instead.\n",
    "    See Also\n",
    "    --------\n",
    "    mean, percentile\n",
    "    Notes\n",
    "    -----\n",
    "    Given a vector ``V`` of length ``N``, the median of ``V`` is the\n",
    "    middle value of a sorted copy of ``V``, ``V_sorted`` - i\n",
    "    e., ``V_sorted[(N-1)/2]``, when ``N`` is odd, and the average of the\n",
    "    two middle values of ``V_sorted`` when ``N`` is even.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> a = np.array([[10, 7, 4], [3, 2, 1]])\n",
    "    >>> a\n",
    "    array([[10,  7,  4],\n",
    "           [ 3,  2,  1]])\n",
    "    >>> np.median(a)\n",
    "    3.5\n",
    "    >>> np.median(a, axis=0)\n",
    "    array([6.5, 4.5, 2.5])\n",
    "    >>> np.median(a, axis=1)\n",
    "    array([7.,  2.])\n",
    "    >>> m = np.median(a, axis=0)\n",
    "    >>> out = np.zeros_like(m)\n",
    "    >>> np.median(a, axis=0, out=m)\n",
    "    array([6.5,  4.5,  2.5])\n",
    "    >>> m\n",
    "    array([6.5,  4.5,  2.5])\n",
    "    >>> b = a.copy()\n",
    "    >>> np.median(b, axis=1, overwrite_input=True)\n",
    "    array([7.,  2.])\n",
    "    >>> assert not np.all(a==b)\n",
    "    >>> b = a.copy()\n",
    "    >>> np.median(b, axis=None, overwrite_input=True)\n",
    "    3.5\n",
    "    >>> assert not np.all(a==b)\n",
    "    \"\"\"\n",
    "    r, k = _ureduce(a, func=_median, axis=axis, out=out,\n",
    "                    overwrite_input=overwrite_input)\n",
    "    if keepdims:\n",
    "        return r.reshape(k)\n",
    "    else:\n",
    "        return r\n",
    "\n",
    "\n",
    "def _median(a, axis=None, out=None, overwrite_input=False):\n",
    "    # can't be reasonably be implemented in terms of percentile as we have to\n",
    "    # call mean to not break astropy\n",
    "    a = np.asanyarray(a)\n",
    "\n",
    "    # Set the partition indexes\n",
    "    if axis is None:\n",
    "        sz = a.size\n",
    "    else:\n",
    "        sz = a.shape[axis]\n",
    "    if sz % 2 == 0:\n",
    "        szh = sz // 2\n",
    "        kth = [szh - 1, szh]\n",
    "    else:\n",
    "        kth = [(sz - 1) // 2]\n",
    "    # Check if the array contains any nan's\n",
    "    if np.issubdtype(a.dtype, np.inexact):\n",
    "        kth.append(-1)\n",
    "\n",
    "    if overwrite_input:\n",
    "        if axis is None:\n",
    "            part = a.ravel()\n",
    "            part.partition(kth)\n",
    "        else:\n",
    "            a.partition(kth, axis=axis)\n",
    "            part = a\n",
    "    else:\n",
    "        part = partition(a, kth, axis=axis)\n",
    "\n",
    "    if part.shape == ():\n",
    "        # make 0-D arrays work\n",
    "        return part.item()\n",
    "    if axis is None:\n",
    "        axis = 0\n",
    "\n",
    "    indexer = [slice(None)] * part.ndim\n",
    "    index = part.shape[axis] // 2\n",
    "    if part.shape[axis] % 2 == 1:\n",
    "        # index with slice to allow mean (below) to work\n",
    "        indexer[axis] = slice(index, index+1)\n",
    "    else:\n",
    "        indexer[axis] = slice(index-1, index+1)\n",
    "    indexer = tuple(indexer)\n",
    "\n",
    "    # Check if the array contains any nan's\n",
    "    if np.issubdtype(a.dtype, np.inexact) and sz > 0:\n",
    "        # warn and return nans like mean would\n",
    "        rout = mean(part[indexer], axis=axis, out=out)\n",
    "        return np.lib.utils._median_nancheck(part, rout, axis, out)\n",
    "    else:\n",
    "        # if there are no nans\n",
    "        # Use mean in odd and even case to coerce data type\n",
    "        # and check, use out array.\n",
    "        return mean(part[indexer], axis=axis, out=out)\n",
    "\n",
    "\n",
    "def _percentile_dispatcher(a, q, axis=None, out=None, overwrite_input=None,\n",
    "                           interpolation=None, keepdims=None):\n",
    "    return (a, q, out)\n",
    "\n",
    "\n",
    "@array_function_dispatch(_percentile_dispatcher)\n",
    "def percentile(a, q, axis=None, out=None,\n",
    "               overwrite_input=False, interpolation='linear', keepdims=False):\n",
    "    \"\"\"\n",
    "    Compute the q-th percentile of the data along the specified axis.\n",
    "    Returns the q-th percentile(s) of the array elements.\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : array_like\n",
    "        Input array or object that can be converted to an array.\n",
    "    q : array_like of float\n",
    "        Percentile or sequence of percentiles to compute, which must be between\n",
    "        0 and 100 inclusive.\n",
    "    axis : {int, tuple of int, None}, optional\n",
    "        Axis or axes along which the percentiles are computed. The\n",
    "        default is to compute the percentile(s) along a flattened\n",
    "        version of the array.\n",
    "        .. versionchanged:: 1.9.0\n",
    "            A tuple of axes is supported\n",
    "    out : ndarray, optional\n",
    "        Alternative output array in which to place the result. It must\n",
    "        have the same shape and buffer length as the expected output,\n",
    "        but the type (of the output) will be cast if necessary.\n",
    "    overwrite_input : bool, optional\n",
    "        If True, then allow the input array `a` to be modified by intermediate\n",
    "        calculations, to save memory. In this case, the contents of the input\n",
    "        `a` after this function completes is undefined.\n",
    "    interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
    "        This optional parameter specifies the interpolation method to\n",
    "        use when the desired percentile lies between two data points\n",
    "        ``i < j``:\n",
    "        * 'linear': ``i + (j - i) * fraction``, where ``fraction``\n",
    "          is the fractional part of the index surrounded by ``i``\n",
    "          and ``j``.\n",
    "        * 'lower': ``i``.\n",
    "        * 'higher': ``j``.\n",
    "        * 'nearest': ``i`` or ``j``, whichever is nearest.\n",
    "        * 'midpoint': ``(i + j) / 2``.\n",
    "        .. versionadded:: 1.9.0\n",
    "    keepdims : bool, optional\n",
    "        If this is set to True, the axes which are reduced are left in\n",
    "        the result as dimensions with size one. With this option, the\n",
    "        result will broadcast correctly against the original array `a`.\n",
    "        .. versionadded:: 1.9.0\n",
    "    Returns\n",
    "    -------\n",
    "    percentile : scalar or ndarray\n",
    "        If `q` is a single percentile and `axis=None`, then the result\n",
    "        is a scalar. If multiple percentiles are given, first axis of\n",
    "        the result corresponds to the percentiles. The other axes are\n",
    "        the axes that remain after the reduction of `a`. If the input\n",
    "        contains integers or floats smaller than ``float64``, the output\n",
    "        data-type is ``float64``. Otherwise, the output data-type is the\n",
    "        same as that of the input. If `out` is specified, that array is\n",
    "        returned instead.\n",
    "    See Also\n",
    "    --------\n",
    "    mean\n",
    "    median : equivalent to ``percentile(..., 50)``\n",
    "    nanpercentile\n",
    "    quantile : equivalent to percentile, except with q in the range [0, 1].\n",
    "    Notes\n",
    "    -----\n",
    "    Given a vector ``V`` of length ``N``, the q-th percentile of\n",
    "    ``V`` is the value ``q/100`` of the way from the minimum to the\n",
    "    maximum in a sorted copy of ``V``. The values and distances of\n",
    "    the two nearest neighbors as well as the `interpolation` parameter\n",
    "    will determine the percentile if the normalized ranking does not\n",
    "    match the location of ``q`` exactly. This function is the same as\n",
    "    the median if ``q=50``, the same as the minimum if ``q=0`` and the\n",
    "    same as the maximum if ``q=100``.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> a = np.array([[10, 7, 4], [3, 2, 1]])\n",
    "    >>> a\n",
    "    array([[10,  7,  4],\n",
    "           [ 3,  2,  1]])\n",
    "    >>> np.percentile(a, 50)\n",
    "    3.5\n",
    "    >>> np.percentile(a, 50, axis=0)\n",
    "    array([6.5, 4.5, 2.5])\n",
    "    >>> np.percentile(a, 50, axis=1)\n",
    "    array([7.,  2.])\n",
    "    >>> np.percentile(a, 50, axis=1, keepdims=True)\n",
    "    array([[7.],\n",
    "           [2.]])\n",
    "    >>> m = np.percentile(a, 50, axis=0)\n",
    "    >>> out = np.zeros_like(m)\n",
    "    >>> np.percentile(a, 50, axis=0, out=out)\n",
    "    array([6.5, 4.5, 2.5])\n",
    "    >>> m\n",
    "    array([6.5, 4.5, 2.5])\n",
    "    >>> b = a.copy()\n",
    "    >>> np.percentile(b, 50, axis=1, overwrite_input=True)\n",
    "    array([7.,  2.])\n",
    "    >>> assert not np.all(a == b)\n",
    "    The different types of interpolation can be visualized graphically:\n",
    "    .. plot::\n",
    "        import matplotlib.pyplot as plt\n",
    "        a = np.arange(4)\n",
    "        p = np.linspace(0, 100, 6001)\n",
    "        ax = plt.gca()\n",
    "        lines = [\n",
    "            ('linear', None),\n",
    "            ('higher', '--'),\n",
    "            ('lower', '--'),\n",
    "            ('nearest', '-.'),\n",
    "            ('midpoint', '-.'),\n",
    "        ]\n",
    "        for interpolation, style in lines:\n",
    "            ax.plot(\n",
    "                p, np.percentile(a, p, interpolation=interpolation),\n",
    "                label=interpolation, linestyle=style)\n",
    "        ax.set(\n",
    "            title='Interpolation methods for list: ' + str(a),\n",
    "            xlabel='Percentile',\n",
    "            ylabel='List item returned',\n",
    "            yticks=a)\n",
    "        ax.legend()\n",
    "        plt.show()\n",
    "    \"\"\"\n",
    "    q = np.true_divide(q, 100)\n",
    "    q = asanyarray(q)  # undo any decay that the ufunc performed (see gh-13105)\n",
    "    if not _quantile_is_valid(q):\n",
    "        raise ValueError(\"Percentiles must be in the range [0, 100]\")\n",
    "    return _quantile_unchecked(\n",
    "        a, q, axis, out, overwrite_input, interpolation, keepdims)\n",
    "\n",
    "\n",
    "def _weighted_ureduce(a, func, w, **kwargs):\n",
    "    \"\"\"\n",
    "    Internal Function.\n",
    "    Call `func` with `a` and `w` as arguments swapping the axes to use extended\n",
    "    axis on functions that don't support it natively.\n",
    "    Returns result and a.shape with axis dims set to 1.\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : array_like\n",
    "        Input array or object that can be converted to an array.\n",
    "    func : callable\n",
    "        Reduction function capable of receiving a single axis argument.\n",
    "        It is called with `a` as first argument followed by `kwargs`.\n",
    "    w : array_like\n",
    "        It has the sample shape with a.shape.\n",
    "    kwargs : keyword arguments\n",
    "        additional keyword arguments to pass to `func`.\n",
    "    Returns\n",
    "    -------\n",
    "    result : tuple\n",
    "        Result of func(a, w, **kwargs) and a.shape and with axis dims set to 1\n",
    "        which can be used to reshape the result to the same shape a ufunc with\n",
    "        keepdims=True would produce.\n",
    "    \"\"\"        \n",
    "    axis = kwargs.get('axis', None)\n",
    "    if axis is not None:\n",
    "        keepdim = list(a.shape)\n",
    "        nd = a.ndim\n",
    "        axis = _nx.normalize_axis_tuple(axis, nd)\n",
    "\n",
    "        for ax in axis:\n",
    "            keepdim[ax] = 1\n",
    "\n",
    "        if len(axis) == 1:\n",
    "            kwargs['axis'] = axis[0]\n",
    "        else:\n",
    "            keep = set(range(nd)) - set(axis)\n",
    "            nkeep = len(keep)\n",
    "            # Swap axis that should not be reduced to front\n",
    "            for i, s in enumerate(sorted(keep)):\n",
    "                a = a.swapaxes(i, s)\n",
    "                w = w.swapaxes(i, s)\n",
    "            # Merge reduced axis\n",
    "            a = a.reshape(a.shape[:nkeep] + (-1,))\n",
    "            w = w.reshape(a.shape[:nkeep] + (-1,))\n",
    "            kwargs['axis'] = -1\n",
    "        keepdim = tuple(keepdim)\n",
    "    else:\n",
    "        keepdim = (1,) * a.ndim\n",
    "\n",
    "    r = func(a, w, **kwargs)\n",
    "    return r, keepdim\n",
    "\n",
    "\n",
    "def quantile_dispatcher(a, q, w=None, axis=None, out=None,\n",
    "                        overwrite_input=None, interpolation=None,\n",
    "                        keepdims=None):\n",
    "    return (a, q, w, out)\n",
    "\n",
    "\n",
    "@array_function_dispatch(quantile_dispatcher)\n",
    "def quantile(a, q, w=None, axis=None, out=None,\n",
    "             overwrite_input=False, interpolation='linear',\n",
    "             keepdims=False):\n",
    "    \"\"\"\n",
    "    Compute the q-th weighted quantile of the data along the specified axis.\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : array_like\n",
    "        Input array or object that can be converted to an array.\n",
    "    q : array_like of float\n",
    "        Quantile or sequence of quantiles to compute, which must be between\n",
    "        0 and 1 inclusive.\n",
    "    w : array_like\n",
    "        The positive weights of samples.\n",
    "        It must have the same shape with a or be a 1d array for broadcast.\n",
    "        When it's a 1d array, axis should be an integer or None and\n",
    "        w.size == a.shape[axis] or w.size == a.size.\n",
    "        If this is set to None, all the weights are equal to each other.\n",
    "    axis : {int, tuple of int, None}, optional\n",
    "        Axis or axes along which the quantiles are computed. The\n",
    "        default is to compute the quantile(s) along a flattened\n",
    "        version of the array.\n",
    "    out : ndarray, optional\n",
    "        Alternative output array in which to place the result. It must\n",
    "        have the same shape and buffer length as the expected output,\n",
    "        but the type (of the output) will be cast if necessary.\n",
    "    overwrite_input : bool, optional\n",
    "        If True, then allow the input array `a` to be modified by intermediate\n",
    "        calculations, to save memory. In this case, the contents of the input\n",
    "        `a` after this function completes is undefined.\n",
    "    interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
    "        This optional parameter specifies the interpolation method to\n",
    "        use when the desired quantile lies between two data points\n",
    "        ``i < j``:\n",
    "            * linear: ``i + (j - i) * fraction``, where ``fraction``\n",
    "              is the fractional part of the index surrounded by ``i``\n",
    "              and ``j``.\n",
    "            * lower: ``i``.\n",
    "            * higher: ``j``.\n",
    "            * nearest: ``i`` or ``j``, whichever is nearest.\n",
    "            * midpoint: ``(i + j) / 2``.\n",
    "    keepdims : bool, optional\n",
    "        If this is set to True, the axes which are reduced are left in\n",
    "        the result as dimensions with size one. With this option, the\n",
    "        result will broadcast correctly against the original array `a`.\n",
    "    Returns\n",
    "    -------\n",
    "    quantile : scalar or ndarray\n",
    "        If `q` is a single quantile and `axis=None`, then the result\n",
    "        is a scalar. If multiple quantiles are given, first axis of\n",
    "        the result corresponds to the quantiles. The other axes are\n",
    "        the axes that remain after the reduction of `a`. If the input\n",
    "        contains integers or floats smaller than ``float64``, the output\n",
    "        data-type is ``float64``. Otherwise, the output data-type is the\n",
    "        same as that of the input. If `out` is specified, that array is\n",
    "        returned instead.\n",
    "    See Also\n",
    "    --------\n",
    "    mean\n",
    "    percentile : equivalent to quantile, but with q in the range [0, 100].\n",
    "    median : equivalent to ``quantile(..., 0.5)``\n",
    "    nanquantile\n",
    "    Notes\n",
    "    -----\n",
    "    Given a vector ``V`` of length ``N``, the q-th quantile of\n",
    "    ``V`` is the value ``q`` of the way from the minimum to the\n",
    "    maximum in a sorted copy of ``V``. The values and distances of\n",
    "    the two nearest neighbors as well as the `interpolation` parameter\n",
    "    will determine the quantile if the normalized ranking does not\n",
    "    match the location of ``q`` exactly. This function is the same as\n",
    "    the median if ``q=0.5``, the same as the minimum if ``q=0.0`` and the\n",
    "    same as the maximum if ``q=1.0``.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> a = np.array([[10, 7, 4], [3, 2, 1]])\n",
    "    >>> a\n",
    "    array([[10,  7,  4],\n",
    "           [ 3,  2,  1]])\n",
    "    >>> np.quantile(a, 0.5)\n",
    "    3.5\n",
    "    >>> w = np.ones((2,3))\n",
    "    >>> quantile(a, 0.5, w)\n",
    "    3.5\n",
    "    >>> np.quantile(a, 0.5, axis=0)\n",
    "    array([6.5, 4.5, 2.5])\n",
    "    >>> w = np.ones(2)\n",
    "    >>> np.quantile(a, 0.5, w, axis=0)\n",
    "    array([6.5, 4.5, 2.5])\n",
    "    >>> np.quantile(a, 0.5, axis=1)\n",
    "    array([7.,  2.])\n",
    "    >>> np.quantile(a, 0.5, axis=1, keepdims=True)\n",
    "    array([[7.],\n",
    "           [2.]])\n",
    "    >>> m = np.quantile(a, 0.5, axis=0)\n",
    "    >>> out = np.zeros_like(m)\n",
    "    >>> np.quantile(a, 0.5, axis=0, out=out)\n",
    "    array([6.5, 4.5, 2.5])\n",
    "    >>> m\n",
    "    array([6.5, 4.5, 2.5])\n",
    "    >>> b = a.copy()\n",
    "    >>> np.quantile(b, 0.5, axis=1, overwrite_input=True)\n",
    "    array([7.,  2.])\n",
    "    >>> assert not np.all(a == b)\n",
    "    \"\"\"\n",
    "    q = np.asanyarray(q)\n",
    "    \n",
    "    if not _quantile_is_valid(q):\n",
    "        raise ValueError(\"Quantiles must be in the range [0, 1]\")\n",
    "        \n",
    "    if w is not None:\n",
    "        a = np.asanyarray(a)\n",
    "        w = np.asanyarray(w)\n",
    "\n",
    "        if w.shape != a.shape:\n",
    "            if w.ndim != 1:\n",
    "                raise TypeError(\n",
    "                    \"1D weights expected when shapes of a and weights differ.\"\n",
    "                )\n",
    "            if axis is None:\n",
    "                if w.size != a.size:\n",
    "                    raise TypeError(\n",
    "                        \"Length of weights not compatible with a's size\"\n",
    "                    )\n",
    "            else:\n",
    "                if w.shape[0] != a.shape[axis]:\n",
    "                    raise ValueError(\n",
    "                        \"Length of weights not compatible with specified axis.\"\n",
    "                    )\n",
    "                w = np.broadcast_to(w, (a.ndim-1) * (1,) + w.shape)\n",
    "                w = w.swapaxes(-1, axis) * np.ones(a.shape)\n",
    "        if not _weight_is_valid(w):\n",
    "            raise ValueError(\"All the weights must be positive\")\n",
    "\n",
    "    return _quantile_unchecked(\n",
    "        a, q, w, axis, out, overwrite_input, interpolation, keepdims)\n",
    "\n",
    "\n",
    "def _quantile_unchecked(a, q, w, axis=None, out=None,\n",
    "                        overwrite_input=False, interpolation='linear',\n",
    "                        keepdims=False):\n",
    "    \"\"\"Assumes that q is in [0, 1], and is an ndarray\"\"\"\n",
    "    if w is None:\n",
    "        r, k = _ureduce(a, func=_quantile_ureduce_func, q=q, axis=axis, out=out,\n",
    "                        overwrite_input=overwrite_input,\n",
    "                        interpolation=interpolation)\n",
    "    else:\n",
    "        r, k = _weighted_ureduce(a, func=_weighted_quantile_ureduce_func, w=w,\n",
    "                                 q=q, axis=axis, out=out,\n",
    "                                 overwrite_input=overwrite_input,\n",
    "                                 interpolation=interpolation)\n",
    "    if keepdims:\n",
    "        return r.reshape(q.shape + k)\n",
    "    else:\n",
    "        return r\n",
    "\n",
    "\n",
    "def _quantile_is_valid(q):\n",
    "    # Avoid expensive reductions, relevant for arrays with < O(1000) elements\n",
    "    if q.ndim == 1 and q.size < 10:\n",
    "        for i in range(q.size):\n",
    "            if q[i] < 0.0 or q[i] > 1.0:\n",
    "                return False\n",
    "    else:\n",
    "        # Faster than any()\n",
    "        if np.count_nonzero(q < 0.0) or np.count_nonzero(q > 1.0):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def _weight_is_valid(w):\n",
    "    # Avoid expensive reductions, relevant for arrays with < O(1000) elements\n",
    "    if np.count_nonzero(np.isnan(w)):\n",
    "        return False\n",
    "    if w.ndim == 1 and w.size < 10:\n",
    "        for i in range(w.size):\n",
    "            if w[i] <= 0.0:\n",
    "                return False\n",
    "    else:\n",
    "        # Faster than any()\n",
    "        if np.count_nonzero(w <= 0.0):\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def _lerp(a, b, t, out=None):\n",
    "    \"\"\" Linearly interpolate from a to b by a factor of t \"\"\"\n",
    "    diff_b_a = subtract(b, a)\n",
    "    # asanyarray is a stop-gap until gh-13105\n",
    "    lerp_interpolation = asanyarray(add(a, diff_b_a*t, out=out))\n",
    "    subtract(b, diff_b_a * (1 - t), out=lerp_interpolation, where=t>=0.5)\n",
    "    if lerp_interpolation.ndim == 0 and out is None:\n",
    "        lerp_interpolation = lerp_interpolation[()]  # unpack 0d arrays\n",
    "    return lerp_interpolation\n",
    "\n",
    "\n",
    "def _weighted_lerp(a, b, sa,\n",
    "                   sb, qsn, out=None):\n",
    "    \"\"\" Linearly interpolate from a to b by a factor of sk \n",
    "    The weighted quantile formulation is\n",
    "        [X_k + (X_{k+1}-X_k)*(q*S_n-S_k)/(S_{k+1}-S_k)]\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : X_k\n",
    "    b : X_{k+1}\n",
    "    sa : S_k\n",
    "    sb : S_b\n",
    "    qsn : q*Sn\n",
    "    \"\"\"\n",
    "    diff_b_a = subtract(b, a)\n",
    "    # asanyarray is a stop-gap until gh-13105\n",
    "    t = (qsn-sa) / (sb-sa)\n",
    "    lerp_interpolation = asanyarray(add(a, diff_b_a * t, out=out))\n",
    "    subtract(b, diff_b_a * (1-t), out=lerp_interpolation, where=(t >= 0.5))\n",
    "    if lerp_interpolation.ndim == 0 and out is None:\n",
    "        lerp_interpolation = lerp_interpolation[()]  # unpack 0d arrays\n",
    "    return lerp_interpolation\n",
    "\n",
    "\n",
    "def _find_weighted_index(sk, qsn, interpolation='linear'):\n",
    "    dim = sk.shape # (N, d1, d2,..., dk)\n",
    "    Nx = dim[0]\n",
    "    _sk = sk.reshape(dim[0], -1) # (N,-1)\n",
    "    _qsn = qsn.reshape(qsn.shape[0], -1) # (q,-1)\n",
    "    indices = []\n",
    "    \n",
    "    for  j in range(_qsn.shape[1]):\n",
    "        k = 0\n",
    "        for i in range(_qsn.shape[0]):\n",
    "            qsn_j = _qsn[i, j]\n",
    "            sk_j = _sk[:, j]\n",
    "            # Find Sk\n",
    "            while(True):\n",
    "                if qsn_j == sk_j[k]:\n",
    "                    indices.append(k)\n",
    "                    break\n",
    "                elif sk_j[k] < qsn_j < sk_j[k+1]:\n",
    "                    if interpolation == 'lower':\n",
    "                        indices.append(k)\n",
    "                    elif interpolation == 'higher':\n",
    "                        indices.append(k+1)\n",
    "                    elif interpolation == 'midpoint':\n",
    "                        indices.append(0.5 * (2*k + 1))\n",
    "                    elif interpolation == 'nearest':\n",
    "                        if (qsn_j-sk_j[k] < sk_j[k+1]-qsn_j or\n",
    "                            (k%2 == 0 and qsn_j-sk_j[k] == sk_j[k+1]-qsn_j)):\n",
    "                            # To get the same result with np.quantile(),\n",
    "                            # test if k%2==0 and |q*S_n-S_k| == |q*S_n*S_{k+1}|.\n",
    "                            indices.append(k)\n",
    "                        else:\n",
    "                            indices.append(k+1)\n",
    "                    elif interpolation == 'linear':\n",
    "                        # Just let the indices to be float temporally\n",
    "                        indices.append(0.5 * (2*k + 1))\n",
    "                    else:\n",
    "                        raise ValueError(\n",
    "                            \"interpolation can only be 'linear',\"\n",
    "                            \"'lower' 'higher', 'midpoint', or 'nearest'\"\n",
    "                        )\n",
    "                    break\n",
    "                k = k + 1\n",
    "    indices = np.asanyarray(indices).reshape(dim[1:] + (qsn.shape[0],))\n",
    "    indices = np.moveaxis(indices, -1, 0)\n",
    "    return indices\n",
    "    \n",
    "    \n",
    "def _weighted_quantile_ureduce_func(a, w, q, axis=None, out=None,\n",
    "                                    overwrite_input=False,\n",
    "                                    interpolation='linear', keepdims=False):\n",
    "    # ufuncs cause 0d array results to decay to scalars (see gh-13105), which\n",
    "    # makes them problematic for __setitem__ and attribute access. As a\n",
    "    # workaround, we call this on the result of every ufunc on a possibly-0d\n",
    "    # array.\n",
    "    not_scalar = np.asanyarray\n",
    "    # Prepare a for partitioning\n",
    "    if overwrite_input:\n",
    "        if axis is None:\n",
    "            ap = a.ravel()\n",
    "            wp = w.ravel()\n",
    "        else:\n",
    "            ap = a\n",
    "            wp = w\n",
    "    else:\n",
    "        if axis is None:\n",
    "            ap = a.flatten()\n",
    "            wp = w.flatten()\n",
    "        else:\n",
    "            ap = a.copy()\n",
    "            wp = w.copy()\n",
    "\n",
    "    if axis is None:\n",
    "        axis = 0\n",
    "\n",
    "    d = q.ndim\n",
    "    if d > 2:\n",
    "        # The code below works fine for nd, but it might not have useful\n",
    "        # semantics. For now, keep the supported dimensions the same as it was\n",
    "        # before.\n",
    "        raise ValueError(\"q must be a scalar or 1d\")\n",
    "    \n",
    "    Nx = ap.shape[axis]\n",
    "    \n",
    "    # Reshape to (Nx, d1,d2,...,dk)\n",
    "    ap = np.moveaxis(ap, axis, 0)\n",
    "    wp = np.moveaxis(wp, axis, 0)\n",
    "    # Sort ap and wp to compute Sk\n",
    "    sorted_index = ap.argsort(axis=0)\n",
    "    ap = np.take_along_axis(ap, sorted_index, axis=0)\n",
    "    wp = np.take_along_axis(wp, sorted_index, axis=0)\n",
    "    \n",
    "    # Compute Sk for k = 1,...,n\n",
    "    sk = np.asarray(\n",
    "        [k*wp[k,...] + (Nx-1) * sum(wp[:k,...], axis=0) for k in range(Nx)]\n",
    "        )\n",
    "    sn = sk[-1,...]\n",
    "\n",
    "    # Sort q to save time when compute indices.\n",
    "    qp = np.atleast_1d(q)\n",
    "    sorted_index_q = qp.argsort(axis=0)\n",
    "    qp = np.take_along_axis(qp, sorted_index_q, axis=0)\n",
    "    # Reshape qp to broadcast\n",
    "    qsn = qp.reshape((-1,) + (1,)*(sn.ndim)) * sn # (q,d1,d2,...,dk)\n",
    "    # Round fractional indices according to interpolation method\n",
    "    indices = _find_weighted_index(sk, qsn, interpolation)\n",
    "\n",
    "    if np.issubdtype(indices.dtype, np.integer):\n",
    "        # Take the points along axis\n",
    "        if np.issubdtype(a.dtype, np.inexact):\n",
    "            n = np.isnan(ap[-1])\n",
    "        else:\n",
    "            # Cannot contain nan\n",
    "            n = np.array(False, dtype=bool)          \n",
    "        r = np.take_along_axis(ap, indices, 0)\n",
    "\n",
    "    else:\n",
    "        if np.issubdtype(a.dtype, np.inexact):\n",
    "            # May contain nan, which would sort to the end\n",
    "            n = np.isnan(ap[-1])\n",
    "        else:\n",
    "            # Cannot contain nan\n",
    "            n = np.array(False, dtype=bool)\n",
    "\n",
    "        # Weight the points above and below the indices\n",
    "        indices_below = not_scalar(floor(indices)).astype(intp)\n",
    "        x_below = np.take_along_axis(ap, indices_below, 0)\n",
    "        \n",
    "        if interpolation == 'midpoint':\n",
    "            indices_above = not_scalar(ceil(indices)).astype(intp)\n",
    "            x_above = np.take_along_axis(ap, indices_above, 0)\n",
    "            r = 0.5 * (x_below+x_above)\n",
    "        else:\n",
    "            # compute indices_above seperately to avoid division by zero problem \n",
    "            indices_above = not_scalar(indices_below + 1).astype(intp)\n",
    "            x_above = np.take_along_axis(ap, indices_above, 0)\n",
    "            # Get Xk, Xk+1, Sk, Sk+1 to do interpolation\n",
    "            s_below = np.take_along_axis(sk, indices_below, 0)\n",
    "            s_above = np.take_along_axis(sk, indices_above, 0)\n",
    "            r = _weighted_lerp(x_below, x_above, s_below, s_above,qsn, out=out)\n",
    "\n",
    "    inverse_index_q = sorted_index_q.argsort(axis=0)\n",
    "    # If any slice contained a nan, then all results on that slice are also nan\n",
    "    if np.any(n):\n",
    "        r[..., n] = a.dtype.type(np.nan)\n",
    "\n",
    "    r = r[inverse_index_q]\n",
    "    if d == 0:\n",
    "        return r[0]\n",
    "    else:\n",
    "        return r\n",
    "\n",
    "\n",
    "def _quantile_ureduce_func(a, q, axis=None, out=None, overwrite_input=False,\n",
    "                           interpolation='linear', keepdims=False):\n",
    "    a = asarray(a)\n",
    "    if q.ndim == 0:\n",
    "        # Do not allow 0-d arrays because following code fails for scalar\n",
    "        zerod = True\n",
    "        q = q[None]\n",
    "    else:\n",
    "        zerod = False\n",
    "\n",
    "    # prepare a for partitioning\n",
    "    if overwrite_input:\n",
    "        if axis is None:\n",
    "            ap = a.ravel()\n",
    "        else:\n",
    "            ap = a\n",
    "    else:\n",
    "        if axis is None:\n",
    "            ap = a.flatten()\n",
    "        else:\n",
    "            ap = a.copy()\n",
    "\n",
    "    if axis is None:\n",
    "        axis = 0\n",
    "\n",
    "    Nx = ap.shape[axis]\n",
    "    indices = q * (Nx - 1)\n",
    "\n",
    "    # round fractional indices according to interpolation method\n",
    "    if interpolation == 'lower':\n",
    "        indices = floor(indices).astype(intp)\n",
    "    elif interpolation == 'higher':\n",
    "        indices = ceil(indices).astype(intp)\n",
    "    elif interpolation == 'midpoint':\n",
    "        indices = 0.5 * (floor(indices) + ceil(indices))\n",
    "    elif interpolation == 'nearest':\n",
    "        indices = around(indices).astype(intp)\n",
    "    elif interpolation == 'linear':\n",
    "        pass  # keep index as fraction and interpolate\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"interpolation can only be 'linear', 'lower' 'higher', \"\n",
    "            \"'midpoint', or 'nearest'\")\n",
    "\n",
    "    n = np.array(False, dtype=bool)  # check for nan's flag\n",
    "    if np.issubdtype(indices.dtype, np.integer):  # take the points along axis\n",
    "        # Check if the array contains any nan's\n",
    "        if np.issubdtype(a.dtype, np.inexact):\n",
    "            indices = concatenate((indices, [-1]))\n",
    "\n",
    "        ap.partition(indices, axis=axis)\n",
    "        # ensure axis with q-th is first\n",
    "        ap = np.moveaxis(ap, axis, 0)\n",
    "        axis = 0\n",
    "\n",
    "        # Check if the array contains any nan's\n",
    "        if np.issubdtype(a.dtype, np.inexact):\n",
    "            indices = indices[:-1]\n",
    "            n = np.isnan(ap[-1:, ...])\n",
    "\n",
    "        if zerod:\n",
    "            indices = indices[0]\n",
    "        r = take(ap, indices, axis=axis, out=out)\n",
    "\n",
    "    else:  # weight the points above and below the indices\n",
    "        indices_below = floor(indices).astype(intp)\n",
    "        indices_above = indices_below + 1\n",
    "        indices_above[indices_above > Nx - 1] = Nx - 1\n",
    "\n",
    "        # Check if the array contains any nan's\n",
    "        if np.issubdtype(a.dtype, np.inexact):\n",
    "            indices_above = concatenate((indices_above, [-1]))\n",
    "\n",
    "        weights_above = indices - indices_below\n",
    "        weights_below = 1 - weights_above\n",
    "\n",
    "        weights_shape = [1, ] * ap.ndim\n",
    "        weights_shape[axis] = len(indices)\n",
    "        weights_below.shape = weights_shape\n",
    "        weights_above.shape = weights_shape\n",
    "\n",
    "        ap.partition(concatenate((indices_below, indices_above)), axis=axis)\n",
    "\n",
    "        # ensure axis with q-th is first\n",
    "        ap = np.moveaxis(ap, axis, 0)\n",
    "        weights_below = np.moveaxis(weights_below, axis, 0)\n",
    "        weights_above = np.moveaxis(weights_above, axis, 0)\n",
    "        axis = 0\n",
    "\n",
    "        # Check if the array contains any nan's\n",
    "        if np.issubdtype(a.dtype, np.inexact):\n",
    "            indices_above = indices_above[:-1]\n",
    "            n = np.isnan(ap[-1:, ...])\n",
    "\n",
    "        x1 = take(ap, indices_below, axis=axis) * weights_below\n",
    "        x2 = take(ap, indices_above, axis=axis) * weights_above\n",
    "\n",
    "        # ensure axis with q-th is first\n",
    "        x1 = np.moveaxis(x1, axis, 0)\n",
    "        x2 = np.moveaxis(x2, axis, 0)\n",
    "\n",
    "        if zerod:\n",
    "            x1 = x1.squeeze(0)\n",
    "            x2 = x2.squeeze(0)\n",
    "\n",
    "        if out is not None:\n",
    "            r = add(x1, x2, out=out)\n",
    "        else:\n",
    "            r = add(x1, x2)\n",
    "\n",
    "    if np.any(n):\n",
    "        if zerod:\n",
    "            if ap.ndim == 1:\n",
    "                if out is not None:\n",
    "                    out[...] = a.dtype.type(np.nan)\n",
    "                    r = out\n",
    "                else:\n",
    "                    r = a.dtype.type(np.nan)\n",
    "            else:\n",
    "                r[..., n.squeeze(0)] = a.dtype.type(np.nan)\n",
    "        else:\n",
    "            if r.ndim == 1:\n",
    "                r[:] = a.dtype.type(np.nan)\n",
    "            else:\n",
    "                r[..., n.repeat(q.size, 0)] = a.dtype.type(np.nan)\n",
    "\n",
    "    return r\n",
    "\n",
    "\n",
    "def _trapz_dispatcher(y, x=None, dx=None, axis=None):\n",
    "    return (y, x)\n",
    "\n",
    "\n",
    "@array_function_dispatch(_trapz_dispatcher)\n",
    "def trapz(y, x=None, dx=1.0, axis=-1):\n",
    "    \"\"\"\n",
    "    Integrate along the given axis using the composite trapezoidal rule.\n",
    "    Integrate `y` (`x`) along given axis.\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array_like\n",
    "        Input array to integrate.\n",
    "    x : array_like, optional\n",
    "        The sample points corresponding to the `y` values. If `x` is None,\n",
    "        the sample points are assumed to be evenly spaced `dx` apart. The\n",
    "        default is None.\n",
    "    dx : scalar, optional\n",
    "        The spacing between sample points when `x` is None. The default is 1.\n",
    "    axis : int, optional\n",
    "        The axis along which to integrate.\n",
    "    Returns\n",
    "    -------\n",
    "    trapz : float\n",
    "        Definite integral as approximated by trapezoidal rule.\n",
    "    See Also\n",
    "    --------\n",
    "    sum, cumsum\n",
    "    Notes\n",
    "    -----\n",
    "    Image [2]_ illustrates trapezoidal rule -- y-axis locations of points\n",
    "    will be taken from `y` array, by default x-axis distances between\n",
    "    points will be 1.0, alternatively they can be provided with `x` array\n",
    "    or with `dx` scalar.  Return value will be equal to combined area under\n",
    "    the red lines.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Wikipedia page: https://en.wikipedia.org/wiki/Trapezoidal_rule\n",
    "    .. [2] Illustration image:\n",
    "           https://en.wikipedia.org/wiki/File:Composite_trapezoidal_rule_illustration.png\n",
    "    Examples\n",
    "    --------\n",
    "    >>> np.trapz([1,2,3])\n",
    "    4.0\n",
    "    >>> np.trapz([1,2,3], x=[4,6,8])\n",
    "    8.0\n",
    "    >>> np.trapz([1,2,3], dx=2)\n",
    "    8.0\n",
    "    >>> a = np.arange(6).reshape(2, 3)\n",
    "    >>> a\n",
    "    array([[0, 1, 2],\n",
    "           [3, 4, 5]])\n",
    "    >>> np.trapz(a, axis=0)\n",
    "    array([1.5, 2.5, 3.5])\n",
    "    >>> np.trapz(a, axis=1)\n",
    "    array([2.,  8.])\n",
    "    \"\"\"\n",
    "    y = asanyarray(y)\n",
    "    if x is None:\n",
    "        d = dx\n",
    "    else:\n",
    "        x = asanyarray(x)\n",
    "        if x.ndim == 1:\n",
    "            d = diff(x)\n",
    "            # reshape to correct shape\n",
    "            shape = [1]*y.ndim\n",
    "            shape[axis] = d.shape[0]\n",
    "            d = d.reshape(shape)\n",
    "        else:\n",
    "            d = diff(x, axis=axis)\n",
    "    nd = y.ndim\n",
    "    slice1 = [slice(None)]*nd\n",
    "    slice2 = [slice(None)]*nd\n",
    "    slice1[axis] = slice(1, None)\n",
    "    slice2[axis] = slice(None, -1)\n",
    "    try:\n",
    "        ret = (d * (y[tuple(slice1)] + y[tuple(slice2)]) / 2.0).sum(axis)\n",
    "    except ValueError:\n",
    "        # Operations didn't work, cast to ndarray\n",
    "        d = np.asarray(d)\n",
    "        y = np.asarray(y)\n",
    "        ret = add.reduce(d * (y[tuple(slice1)]+y[tuple(slice2)])/2.0, axis)\n",
    "    return ret\n",
    "\n",
    "\n",
    "def _meshgrid_dispatcher(*xi, copy=None, sparse=None, indexing=None):\n",
    "    return xi\n",
    "\n",
    "\n",
    "# Based on scitools meshgrid\n",
    "@array_function_dispatch(_meshgrid_dispatcher)\n",
    "def meshgrid(*xi, copy=True, sparse=False, indexing='xy'):\n",
    "    \"\"\"\n",
    "    Return coordinate matrices from coordinate vectors.\n",
    "    Make N-D coordinate arrays for vectorized evaluations of\n",
    "    N-D scalar/vector fields over N-D grids, given\n",
    "    one-dimensional coordinate arrays x1, x2,..., xn.\n",
    "    .. versionchanged:: 1.9\n",
    "       1-D and 0-D cases are allowed.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x1, x2,..., xn : array_like\n",
    "        1-D arrays representing the coordinates of a grid.\n",
    "    indexing : {'xy', 'ij'}, optional\n",
    "        Cartesian ('xy', default) or matrix ('ij') indexing of output.\n",
    "        See Notes for more details.\n",
    "        .. versionadded:: 1.7.0\n",
    "    sparse : bool, optional\n",
    "        If True a sparse grid is returned in order to conserve memory.\n",
    "        Default is False.\n",
    "        .. versionadded:: 1.7.0\n",
    "    copy : bool, optional\n",
    "        If False, a view into the original arrays are returned in order to\n",
    "        conserve memory.  Default is True.  Please note that\n",
    "        ``sparse=False, copy=False`` will likely return non-contiguous\n",
    "        arrays.  Furthermore, more than one element of a broadcast array\n",
    "        may refer to a single memory location.  If you need to write to the\n",
    "        arrays, make copies first.\n",
    "        .. versionadded:: 1.7.0\n",
    "    Returns\n",
    "    -------\n",
    "    X1, X2,..., XN : ndarray\n",
    "        For vectors `x1`, `x2`,..., 'xn' with lengths ``Ni=len(xi)`` ,\n",
    "        return ``(N1, N2, N3,...Nn)`` shaped arrays if indexing='ij'\n",
    "        or ``(N2, N1, N3,...Nn)`` shaped arrays if indexing='xy'\n",
    "        with the elements of `xi` repeated to fill the matrix along\n",
    "        the first dimension for `x1`, the second for `x2` and so on.\n",
    "    Notes\n",
    "    -----\n",
    "    This function supports both indexing conventions through the indexing\n",
    "    keyword argument.  Giving the string 'ij' returns a meshgrid with\n",
    "    matrix indexing, while 'xy' returns a meshgrid with Cartesian indexing.\n",
    "    In the 2-D case with inputs of length M and N, the outputs are of shape\n",
    "    (N, M) for 'xy' indexing and (M, N) for 'ij' indexing.  In the 3-D case\n",
    "    with inputs of length M, N and P, outputs are of shape (N, M, P) for\n",
    "    'xy' indexing and (M, N, P) for 'ij' indexing.  The difference is\n",
    "    illustrated by the following code snippet::\n",
    "        xv, yv = np.meshgrid(x, y, sparse=False, indexing='ij')\n",
    "        for i in range(nx):\n",
    "            for j in range(ny):\n",
    "                # treat xv[i,j], yv[i,j]\n",
    "        xv, yv = np.meshgrid(x, y, sparse=False, indexing='xy')\n",
    "        for i in range(nx):\n",
    "            for j in range(ny):\n",
    "                # treat xv[j,i], yv[j,i]\n",
    "    In the 1-D and 0-D case, the indexing and sparse keywords have no effect.\n",
    "    See Also\n",
    "    --------\n",
    "    index_tricks.mgrid : Construct a multi-dimensional \"meshgrid\"\n",
    "                     using indexing notation.\n",
    "    index_tricks.ogrid : Construct an open multi-dimensional \"meshgrid\"\n",
    "                     using indexing notation.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> nx, ny = (3, 2)\n",
    "    >>> x = np.linspace(0, 1, nx)\n",
    "    >>> y = np.linspace(0, 1, ny)\n",
    "    >>> xv, yv = np.meshgrid(x, y)\n",
    "    >>> xv\n",
    "    array([[0. , 0.5, 1. ],\n",
    "           [0. , 0.5, 1. ]])\n",
    "    >>> yv\n",
    "    array([[0.,  0.,  0.],\n",
    "           [1.,  1.,  1.]])\n",
    "    >>> xv, yv = np.meshgrid(x, y, sparse=True)  # make sparse output arrays\n",
    "    >>> xv\n",
    "    array([[0. ,  0.5,  1. ]])\n",
    "    >>> yv\n",
    "    array([[0.],\n",
    "           [1.]])\n",
    "    `meshgrid` is very useful to evaluate functions on a grid.\n",
    "    >>> import matplotlib.pyplot as plt\n",
    "    >>> x = np.arange(-5, 5, 0.1)\n",
    "    >>> y = np.arange(-5, 5, 0.1)\n",
    "    >>> xx, yy = np.meshgrid(x, y, sparse=True)\n",
    "    >>> z = np.sin(xx**2 + yy**2) / (xx**2 + yy**2)\n",
    "    >>> h = plt.contourf(x,y,z)\n",
    "    >>> plt.show()\n",
    "    \"\"\"\n",
    "    ndim = len(xi)\n",
    "\n",
    "    if indexing not in ['xy', 'ij']:\n",
    "        raise ValueError(\n",
    "            \"Valid values for `indexing` are 'xy' and 'ij'.\")\n",
    "\n",
    "    s0 = (1,) * ndim\n",
    "    output = [np.asanyarray(x).reshape(s0[:i] + (-1,) + s0[i + 1:])\n",
    "              for i, x in enumerate(xi)]\n",
    "\n",
    "    if indexing == 'xy' and ndim > 1:\n",
    "        # switch first and second axis\n",
    "        output[0].shape = (1, -1) + s0[2:]\n",
    "        output[1].shape = (-1, 1) + s0[2:]\n",
    "\n",
    "    if not sparse:\n",
    "        # Return the full N-D matrix (not only the 1-D vector)\n",
    "        output = np.broadcast_arrays(*output, subok=True)\n",
    "\n",
    "    if copy:\n",
    "        output = [x.copy() for x in output]\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def _delete_dispatcher(arr, obj, axis=None):\n",
    "    return (arr, obj)\n",
    "\n",
    "\n",
    "@array_function_dispatch(_delete_dispatcher)\n",
    "def delete(arr, obj, axis=None):\n",
    "    \"\"\"\n",
    "    Return a new array with sub-arrays along an axis deleted. For a one\n",
    "    dimensional array, this returns those entries not returned by\n",
    "    `arr[obj]`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : array_like\n",
    "        Input array.\n",
    "    obj : slice, int or array of ints\n",
    "        Indicate indices of sub-arrays to remove along the specified axis.\n",
    "        .. versionchanged:: 1.19.0\n",
    "            Boolean indices are now treated as a mask of elements to remove,\n",
    "            rather than being cast to the integers 0 and 1.\n",
    "    axis : int, optional\n",
    "        The axis along which to delete the subarray defined by `obj`.\n",
    "        If `axis` is None, `obj` is applied to the flattened array.\n",
    "    Returns\n",
    "    -------\n",
    "    out : ndarray\n",
    "        A copy of `arr` with the elements specified by `obj` removed. Note\n",
    "        that `delete` does not occur in-place. If `axis` is None, `out` is\n",
    "        a flattened array.\n",
    "    See Also\n",
    "    --------\n",
    "    insert : Insert elements into an array.\n",
    "    append : Append elements at the end of an array.\n",
    "    Notes\n",
    "    -----\n",
    "    Often it is preferable to use a boolean mask. For example:\n",
    "    >>> arr = np.arange(12) + 1\n",
    "    >>> mask = np.ones(len(arr), dtype=bool)\n",
    "    >>> mask[[0,2,4]] = False\n",
    "    >>> result = arr[mask,...]\n",
    "    Is equivalent to `np.delete(arr, [0,2,4], axis=0)`, but allows further\n",
    "    use of `mask`.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> arr = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\n",
    "    >>> arr\n",
    "    array([[ 1,  2,  3,  4],\n",
    "           [ 5,  6,  7,  8],\n",
    "           [ 9, 10, 11, 12]])\n",
    "    >>> np.delete(arr, 1, 0)\n",
    "    array([[ 1,  2,  3,  4],\n",
    "           [ 9, 10, 11, 12]])\n",
    "    >>> np.delete(arr, np.s_[::2], 1)\n",
    "    array([[ 2,  4],\n",
    "           [ 6,  8],\n",
    "           [10, 12]])\n",
    "    >>> np.delete(arr, [1,3,5], None)\n",
    "    array([ 1,  3,  5,  7,  8,  9, 10, 11, 12])\n",
    "    \"\"\"\n",
    "    wrap = None\n",
    "    if type(arr) is not ndarray:\n",
    "        try:\n",
    "            wrap = arr.__array_wrap__\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "    arr = asarray(arr)\n",
    "    ndim = arr.ndim\n",
    "    arrorder = 'F' if arr.flags.fnc else 'C'\n",
    "    if axis is None:\n",
    "        if ndim != 1:\n",
    "            arr = arr.ravel()\n",
    "        # needed for np.matrix, which is still not 1d after being ravelled\n",
    "        ndim = arr.ndim\n",
    "        axis = ndim - 1\n",
    "    else:\n",
    "        axis = normalize_axis_index(axis, ndim)\n",
    "\n",
    "    slobj = [slice(None)]*ndim\n",
    "    N = arr.shape[axis]\n",
    "    newshape = list(arr.shape)\n",
    "\n",
    "    if isinstance(obj, slice):\n",
    "        start, stop, step = obj.indices(N)\n",
    "        xr = range(start, stop, step)\n",
    "        numtodel = len(xr)\n",
    "\n",
    "        if numtodel <= 0:\n",
    "            if wrap:\n",
    "                return wrap(arr.copy(order=arrorder))\n",
    "            else:\n",
    "                return arr.copy(order=arrorder)\n",
    "\n",
    "        # Invert if step is negative:\n",
    "        if step < 0:\n",
    "            step = -step\n",
    "            start = xr[-1]\n",
    "            stop = xr[0] + 1\n",
    "\n",
    "        newshape[axis] -= numtodel\n",
    "        new = empty(newshape, arr.dtype, arrorder)\n",
    "        # copy initial chunk\n",
    "        if start == 0:\n",
    "            pass\n",
    "        else:\n",
    "            slobj[axis] = slice(None, start)\n",
    "            new[tuple(slobj)] = arr[tuple(slobj)]\n",
    "        # copy end chunk\n",
    "        if stop == N:\n",
    "            pass\n",
    "        else:\n",
    "            slobj[axis] = slice(stop-numtodel, None)\n",
    "            slobj2 = [slice(None)]*ndim\n",
    "            slobj2[axis] = slice(stop, None)\n",
    "            new[tuple(slobj)] = arr[tuple(slobj2)]\n",
    "        # copy middle pieces\n",
    "        if step == 1:\n",
    "            pass\n",
    "        else:  # use array indexing.\n",
    "            keep = ones(stop-start, dtype=bool)\n",
    "            keep[:stop-start:step] = False\n",
    "            slobj[axis] = slice(start, stop-numtodel)\n",
    "            slobj2 = [slice(None)]*ndim\n",
    "            slobj2[axis] = slice(start, stop)\n",
    "            arr = arr[tuple(slobj2)]\n",
    "            slobj2[axis] = keep\n",
    "            new[tuple(slobj)] = arr[tuple(slobj2)]\n",
    "        if wrap:\n",
    "            return wrap(new)\n",
    "        else:\n",
    "            return new\n",
    "\n",
    "    if isinstance(obj, (int, integer)) and not isinstance(obj, bool):\n",
    "        # optimization for a single value\n",
    "        if (obj < -N or obj >= N):\n",
    "            raise IndexError(\n",
    "                \"index %i is out of bounds for axis %i with \"\n",
    "                \"size %i\" % (obj, axis, N))\n",
    "        if (obj < 0):\n",
    "            obj += N\n",
    "        newshape[axis] -= 1\n",
    "        new = empty(newshape, arr.dtype, arrorder)\n",
    "        slobj[axis] = slice(None, obj)\n",
    "        new[tuple(slobj)] = arr[tuple(slobj)]\n",
    "        slobj[axis] = slice(obj, None)\n",
    "        slobj2 = [slice(None)]*ndim\n",
    "        slobj2[axis] = slice(obj+1, None)\n",
    "        new[tuple(slobj)] = arr[tuple(slobj2)]\n",
    "    else:\n",
    "        _obj = obj\n",
    "        obj = np.asarray(obj)\n",
    "        if obj.size == 0 and not isinstance(_obj, np.ndarray):\n",
    "            obj = obj.astype(intp)\n",
    "\n",
    "        if obj.dtype == bool:\n",
    "            if obj.shape != (N,):\n",
    "                raise ValueError('boolean array argument obj to delete '\n",
    "                                 'must be one dimensional and match the axis '\n",
    "                                 'length of {}'.format(N))\n",
    "\n",
    "            # optimization, the other branch is slower\n",
    "            keep = ~obj\n",
    "        else:\n",
    "            keep = ones(N, dtype=bool)\n",
    "            keep[obj,] = False\n",
    "\n",
    "        slobj[axis] = keep\n",
    "        new = arr[tuple(slobj)]\n",
    "\n",
    "    if wrap:\n",
    "        return wrap(new)\n",
    "    else:\n",
    "        return new\n",
    "\n",
    "\n",
    "def _insert_dispatcher(arr, obj, values, axis=None):\n",
    "    return (arr, obj, values)\n",
    "\n",
    "\n",
    "@array_function_dispatch(_insert_dispatcher)\n",
    "def insert(arr, obj, values, axis=None):\n",
    "    \"\"\"\n",
    "    Insert values along the given axis before the given indices.\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : array_like\n",
    "        Input array.\n",
    "    obj : int, slice or sequence of ints\n",
    "        Object that defines the index or indices before which `values` is\n",
    "        inserted.\n",
    "        .. versionadded:: 1.8.0\n",
    "        Support for multiple insertions when `obj` is a single scalar or a\n",
    "        sequence with one element (similar to calling insert multiple\n",
    "        times).\n",
    "    values : array_like\n",
    "        Values to insert into `arr`. If the type of `values` is different\n",
    "        from that of `arr`, `values` is converted to the type of `arr`.\n",
    "        `values` should be shaped so that ``arr[...,obj,...] = values``\n",
    "        is legal.\n",
    "    axis : int, optional\n",
    "        Axis along which to insert `values`.  If `axis` is None then `arr`\n",
    "        is flattened first.\n",
    "    Returns\n",
    "    -------\n",
    "    out : ndarray\n",
    "        A copy of `arr` with `values` inserted.  Note that `insert`\n",
    "        does not occur in-place: a new array is returned. If\n",
    "        `axis` is None, `out` is a flattened array.\n",
    "    See Also\n",
    "    --------\n",
    "    append : Append elements at the end of an array.\n",
    "    concatenate : Join a sequence of arrays along an existing axis.\n",
    "    delete : Delete elements from an array.\n",
    "    Notes\n",
    "    -----\n",
    "    Note that for higher dimensional inserts `obj=0` behaves very different\n",
    "    from `obj=[0]` just like `arr[:,0,:] = values` is different from\n",
    "    `arr[:,[0],:] = values`.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> a = np.array([[1, 1], [2, 2], [3, 3]])\n",
    "    >>> a\n",
    "    array([[1, 1],\n",
    "           [2, 2],\n",
    "           [3, 3]])\n",
    "    >>> np.insert(a, 1, 5)\n",
    "    array([1, 5, 1, ..., 2, 3, 3])\n",
    "    >>> np.insert(a, 1, 5, axis=1)\n",
    "    array([[1, 5, 1],\n",
    "           [2, 5, 2],\n",
    "           [3, 5, 3]])\n",
    "    Difference between sequence and scalars:\n",
    "    >>> np.insert(a, [1], [[1],[2],[3]], axis=1)\n",
    "    array([[1, 1, 1],\n",
    "           [2, 2, 2],\n",
    "           [3, 3, 3]])\n",
    "    >>> np.array_equal(np.insert(a, 1, [1, 2, 3], axis=1),\n",
    "    ...                np.insert(a, [1], [[1],[2],[3]], axis=1))\n",
    "    True\n",
    "    >>> b = a.flatten()\n",
    "    >>> b\n",
    "    array([1, 1, 2, 2, 3, 3])\n",
    "    >>> np.insert(b, [2, 2], [5, 6])\n",
    "    array([1, 1, 5, ..., 2, 3, 3])\n",
    "    >>> np.insert(b, slice(2, 4), [5, 6])\n",
    "    array([1, 1, 5, ..., 2, 3, 3])\n",
    "    >>> np.insert(b, [2, 2], [7.13, False]) # type casting\n",
    "    array([1, 1, 7, ..., 2, 3, 3])\n",
    "    >>> x = np.arange(8).reshape(2, 4)\n",
    "    >>> idx = (1, 3)\n",
    "    >>> np.insert(x, idx, 999, axis=1)\n",
    "    array([[  0, 999,   1,   2, 999,   3],\n",
    "           [  4, 999,   5,   6, 999,   7]])\n",
    "    \"\"\"\n",
    "    wrap = None\n",
    "    if type(arr) is not ndarray:\n",
    "        try:\n",
    "            wrap = arr.__array_wrap__\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "    arr = asarray(arr)\n",
    "    ndim = arr.ndim\n",
    "    arrorder = 'F' if arr.flags.fnc else 'C'\n",
    "    if axis is None:\n",
    "        if ndim != 1:\n",
    "            arr = arr.ravel()\n",
    "        # needed for np.matrix, which is still not 1d after being ravelled\n",
    "        ndim = arr.ndim\n",
    "        axis = ndim - 1\n",
    "    else:\n",
    "        axis = normalize_axis_index(axis, ndim)\n",
    "    slobj = [slice(None)]*ndim\n",
    "    N = arr.shape[axis]\n",
    "    newshape = list(arr.shape)\n",
    "\n",
    "    if isinstance(obj, slice):\n",
    "        # turn it into a range object\n",
    "        indices = arange(*obj.indices(N), dtype=intp)\n",
    "    else:\n",
    "        # need to copy obj, because indices will be changed in-place\n",
    "        indices = np.array(obj)\n",
    "        if indices.dtype == bool:\n",
    "            # See also delete\n",
    "            # 2012-10-11, NumPy 1.8\n",
    "            warnings.warn(\n",
    "                \"in the future insert will treat boolean arrays and \"\n",
    "                \"array-likes as a boolean index instead of casting it to \"\n",
    "                \"integer\", FutureWarning, stacklevel=3)\n",
    "            indices = indices.astype(intp)\n",
    "            # Code after warning period:\n",
    "            #if obj.ndim != 1:\n",
    "            #    raise ValueError('boolean array argument obj to insert '\n",
    "            #                     'must be one dimensional')\n",
    "            #indices = np.flatnonzero(obj)\n",
    "        elif indices.ndim > 1:\n",
    "            raise ValueError(\n",
    "                \"index array argument obj to insert must be one dimensional \"\n",
    "                \"or scalar\")\n",
    "    if indices.size == 1:\n",
    "        index = indices.item()\n",
    "        if index < -N or index > N:\n",
    "            raise IndexError(\n",
    "                \"index %i is out of bounds for axis %i with \"\n",
    "                \"size %i\" % (obj, axis, N))\n",
    "        if (index < 0):\n",
    "            index += N\n",
    "\n",
    "        # There are some object array corner cases here, but we cannot avoid\n",
    "        # that:\n",
    "        values = array(values, copy=False, ndmin=arr.ndim, dtype=arr.dtype)\n",
    "        if indices.ndim == 0:\n",
    "            # broadcasting is very different here, since a[:,0,:] = ... behaves\n",
    "            # very different from a[:,[0],:] = ...! This changes values so that\n",
    "            # it works likes the second case. (here a[:,0:1,:])\n",
    "            values = np.moveaxis(values, 0, axis)\n",
    "        numnew = values.shape[axis]\n",
    "        newshape[axis] += numnew\n",
    "        new = empty(newshape, arr.dtype, arrorder)\n",
    "        slobj[axis] = slice(None, index)\n",
    "        new[tuple(slobj)] = arr[tuple(slobj)]\n",
    "        slobj[axis] = slice(index, index+numnew)\n",
    "        new[tuple(slobj)] = values\n",
    "        slobj[axis] = slice(index+numnew, None)\n",
    "        slobj2 = [slice(None)] * ndim\n",
    "        slobj2[axis] = slice(index, None)\n",
    "        new[tuple(slobj)] = arr[tuple(slobj2)]\n",
    "        if wrap:\n",
    "            return wrap(new)\n",
    "        return new\n",
    "    elif indices.size == 0 and not isinstance(obj, np.ndarray):\n",
    "        # Can safely cast the empty list to intp\n",
    "        indices = indices.astype(intp)\n",
    "\n",
    "    indices[indices < 0] += N\n",
    "\n",
    "    numnew = len(indices)\n",
    "    order = indices.argsort(kind='mergesort')   # stable sort\n",
    "    indices[order] += np.arange(numnew)\n",
    "\n",
    "    newshape[axis] += numnew\n",
    "    old_mask = ones(newshape[axis], dtype=bool)\n",
    "    old_mask[indices] = False\n",
    "\n",
    "    new = empty(newshape, arr.dtype, arrorder)\n",
    "    slobj2 = [slice(None)]*ndim\n",
    "    slobj[axis] = indices\n",
    "    slobj2[axis] = old_mask\n",
    "    new[tuple(slobj)] = values\n",
    "    new[tuple(slobj2)] = arr\n",
    "\n",
    "    if wrap:\n",
    "        return wrap(new)\n",
    "    return new\n",
    "\n",
    "\n",
    "def _append_dispatcher(arr, values, axis=None):\n",
    "    return (arr, values)\n",
    "\n",
    "\n",
    "@array_function_dispatch(_append_dispatcher)\n",
    "def append(arr, values, axis=None):\n",
    "    \"\"\"\n",
    "    Append values to the end of an array.\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : array_like\n",
    "        Values are appended to a copy of this array.\n",
    "    values : array_like\n",
    "        These values are appended to a copy of `arr`.  It must be of the\n",
    "        correct shape (the same shape as `arr`, excluding `axis`).  If\n",
    "        `axis` is not specified, `values` can be any shape and will be\n",
    "        flattened before use.\n",
    "    axis : int, optional\n",
    "        The axis along which `values` are appended.  If `axis` is not\n",
    "        given, both `arr` and `values` are flattened before use.\n",
    "    Returns\n",
    "    -------\n",
    "    append : ndarray\n",
    "        A copy of `arr` with `values` appended to `axis`.  Note that\n",
    "        `append` does not occur in-place: a new array is allocated and\n",
    "        filled.  If `axis` is None, `out` is a flattened array.\n",
    "    See Also\n",
    "    --------\n",
    "    insert : Insert elements into an array.\n",
    "    delete : Delete elements from an array.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> np.append([1, 2, 3], [[4, 5, 6], [7, 8, 9]])\n",
    "    array([1, 2, 3, ..., 7, 8, 9])\n",
    "    When `axis` is specified, `values` must have the correct shape.\n",
    "    >>> np.append([[1, 2, 3], [4, 5, 6]], [[7, 8, 9]], axis=0)\n",
    "    array([[1, 2, 3],\n",
    "           [4, 5, 6],\n",
    "           [7, 8, 9]])\n",
    "    >>> np.append([[1, 2, 3], [4, 5, 6]], [7, 8, 9], axis=0)\n",
    "    Traceback (most recent call last):\n",
    "        ...\n",
    "    ValueError: all the input arrays must have same number of dimensions, but\n",
    "    the array at index 0 has 2 dimension(s) and the array at index 1 has 1\n",
    "    dimension(s)\n",
    "    \"\"\"\n",
    "    arr = asanyarray(arr)\n",
    "    if axis is None:\n",
    "        if arr.ndim != 1:\n",
    "            arr = arr.ravel()\n",
    "        values = ravel(values)\n",
    "        axis = arr.ndim-1\n",
    "    return concatenate((arr, values), axis=axis)\n",
    "\n",
    "\n",
    "def _digitize_dispatcher(x, bins, right=None):\n",
    "    return (x, bins)\n",
    "\n",
    "\n",
    "@array_function_dispatch(_digitize_dispatcher)\n",
    "def digitize(x, bins, right=False):\n",
    "    \"\"\"\n",
    "    Return the indices of the bins to which each value in input array belongs.\n",
    "    =========  =============  ============================\n",
    "    `right`    order of bins  returned index `i` satisfies\n",
    "    =========  =============  ============================\n",
    "    ``False``  increasing     ``bins[i-1] <= x < bins[i]``\n",
    "    ``True``   increasing     ``bins[i-1] < x <= bins[i]``\n",
    "    ``False``  decreasing     ``bins[i-1] > x >= bins[i]``\n",
    "    ``True``   decreasing     ``bins[i-1] >= x > bins[i]``\n",
    "    =========  =============  ============================\n",
    "    If values in `x` are beyond the bounds of `bins`, 0 or ``len(bins)`` is\n",
    "    returned as appropriate.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array_like\n",
    "        Input array to be binned. Prior to NumPy 1.10.0, this array had to\n",
    "        be 1-dimensional, but can now have any shape.\n",
    "    bins : array_like\n",
    "        Array of bins. It has to be 1-dimensional and monotonic.\n",
    "    right : bool, optional\n",
    "        Indicating whether the intervals include the right or the left bin\n",
    "        edge. Default behavior is (right==False) indicating that the interval\n",
    "        does not include the right edge. The left bin end is open in this\n",
    "        case, i.e., bins[i-1] <= x < bins[i] is the default behavior for\n",
    "        monotonically increasing bins.\n",
    "    Returns\n",
    "    -------\n",
    "    indices : ndarray of ints\n",
    "        Output array of indices, of same shape as `x`.\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If `bins` is not monotonic.\n",
    "    TypeError\n",
    "        If the type of the input is complex.\n",
    "    See Also\n",
    "    --------\n",
    "    bincount, histogram, unique, searchsorted\n",
    "    Notes\n",
    "    -----\n",
    "    If values in `x` are such that they fall outside the bin range,\n",
    "    attempting to index `bins` with the indices that `digitize` returns\n",
    "    will result in an IndexError.\n",
    "    .. versionadded:: 1.10.0\n",
    "    `np.digitize` is  implemented in terms of `np.searchsorted`. This means\n",
    "    that a binary search is used to bin the values, which scales much better\n",
    "    for larger number of bins than the previous linear search. It also removes\n",
    "    the requirement for the input array to be 1-dimensional.\n",
    "    For monotonically _increasing_ `bins`, the following are equivalent::\n",
    "        np.digitize(x, bins, right=True)\n",
    "        np.searchsorted(bins, x, side='left')\n",
    "    Note that as the order of the arguments are reversed, the side must be too.\n",
    "    The `searchsorted` call is marginally faster, as it does not do any\n",
    "    monotonicity checks. Perhaps more importantly, it supports all dtypes.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> x = np.array([0.2, 6.4, 3.0, 1.6])\n",
    "    >>> bins = np.array([0.0, 1.0, 2.5, 4.0, 10.0])\n",
    "    >>> inds = np.digitize(x, bins)\n",
    "    >>> inds\n",
    "    array([1, 4, 3, 2])\n",
    "    >>> for n in range(x.size):\n",
    "    ...   print(bins[inds[n]-1], \"<=\", x[n], \"<\", bins[inds[n]])\n",
    "    ...\n",
    "    0.0 <= 0.2 < 1.0\n",
    "    4.0 <= 6.4 < 10.0\n",
    "    2.5 <= 3.0 < 4.0\n",
    "    1.0 <= 1.6 < 2.5\n",
    "    >>> x = np.array([1.2, 10.0, 12.4, 15.5, 20.])\n",
    "    >>> bins = np.array([0, 5, 10, 15, 20])\n",
    "    >>> np.digitize(x,bins,right=True)\n",
    "    array([1, 2, 3, 4, 4])\n",
    "    >>> np.digitize(x,bins,right=False)\n",
    "    array([1, 3, 3, 4, 5])\n",
    "    \"\"\"\n",
    "    x = _nx.asarray(x)\n",
    "    bins = _nx.asarray(bins)\n",
    "\n",
    "    # here for compatibility, searchsorted below is happy to take this\n",
    "    if np.issubdtype(x.dtype, _nx.complexfloating):\n",
    "        raise TypeError(\"x may not be complex\")\n",
    "\n",
    "    mono = _monotonicity(bins)\n",
    "    if mono == 0:\n",
    "        raise ValueError(\"bins must be monotonically increasing or decreasing\")\n",
    "\n",
    "    # this is backwards because the arguments below are swapped\n",
    "    side = 'left' if right else 'right'\n",
    "    if mono == -1:\n",
    "        # reverse the bins, and invert the results\n",
    "        return len(bins) - _nx.searchsorted(bins[::-1], x, side=side)\n",
    "    else:\n",
    "        return _nx.searchsorted(bins, x, side=side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass!\n"
     ]
    }
   ],
   "source": [
    "from  itertools import permutations\n",
    "import pickle\n",
    "\n",
    "def add_sample(a, q, w, axis, test_sample,out=None,overwrite_input=False,keepdims=False):\n",
    "    interpolation_list = ['lower','higher','midpoint','nearest','linear']\n",
    "    for interpolation in interpolation_list:\n",
    "        d ={'a':a,\n",
    "            'q':q,\n",
    "            'w':w,\n",
    "            'axis':axis,\n",
    "            'out':out,\n",
    "            'overwrite_input':overwrite_input,\n",
    "            'interpolation':interpolation,\n",
    "            'keepdims':keepdims}\n",
    "        test_sample.append(d)\n",
    "def check_equal(param_list,error_samples):\n",
    "    f = True\n",
    "    for param_dict in param_list:\n",
    "        a = param_dict['a']\n",
    "        q = param_dict['q']\n",
    "        w = param_dict['w']\n",
    "        axis = param_dict['axis']\n",
    "        out = param_dict['out']\n",
    "        overwrite_input = param_dict['overwrite_input']\n",
    "        interpolation = param_dict['interpolation']\n",
    "        keepdims = param_dict['keepdims']\n",
    "        \n",
    "        result_a = quantile(a, q, w, axis=axis, out=out, overwrite_input=overwrite_input, interpolation=interpolation, keepdims=keepdims)\n",
    "        result_b = quantile(a, q, axis=axis, out=out, overwrite_input=overwrite_input, interpolation=interpolation, keepdims=keepdims)\n",
    "        if not np.allclose(result_a,result_b,equal_nan=True):\n",
    "            error_samples.append(param_dict)\n",
    "            print(\"Error occurs!\")\n",
    "            print(\"result_a\",result_a)\n",
    "            print(\"result_b\",result_b)\n",
    "            f = False\n",
    "    if f:\n",
    "        print(\"Pass!\")\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "#     with open(\"test_sample.pkl\",'rb') as f:\n",
    "#         test_sample = pickle.load(f)\n",
    "    error_samples = []\n",
    "    check_equal(test_sample,error_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([2,6,8,1,23,5,7,9,4,15]).reshape(5,2)\n",
    "q = np.random.rand(10)\n",
    "w = np.array([np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan]).reshape(5,2)\n",
    "axis = 0\n",
    "add_sample(a,q,w,axis,test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
