{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections.abc\n",
    "import functools\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import numpy.core.numeric as _nx\n",
    "from numpy.core import transpose\n",
    "from numpy.core.numeric import (\n",
    "    ones, zeros, arange, concatenate, array, asarray, asanyarray, empty,\n",
    "    ndarray, around, floor, ceil, take, dot, where, intp,\n",
    "    integer, isscalar, absolute\n",
    "    )\n",
    "from numpy.core.umath import (\n",
    "    pi, add, arctan2, frompyfunc, cos, less_equal, sqrt, sin,\n",
    "    mod, exp, not_equal, subtract\n",
    "    )\n",
    "from numpy.core.fromnumeric import (\n",
    "    ravel, nonzero, partition, mean, any, sum\n",
    "    )\n",
    "from numpy.core.numerictypes import typecodes\n",
    "from numpy.core.overrides import set_module\n",
    "from numpy.core import overrides\n",
    "from numpy.core.function_base import add_newdoc\n",
    "from numpy.lib.twodim_base import diag\n",
    "from numpy.core.multiarray import (\n",
    "    _insert, add_docstring, bincount, normalize_axis_index, _monotonicity,\n",
    "    interp as compiled_interp, interp_complex as compiled_interp_complex\n",
    "    )\n",
    "from numpy.core.umath import _add_newdoc_ufunc as add_newdoc_ufunc\n",
    "\n",
    "import builtins\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_function_dispatch = functools.partial(\n",
    "    overrides.array_function_dispatch, module='numpy')\n",
    "def _weighted_ureduce(a, func, w, **kwargs):\n",
    "    \"\"\"\n",
    "    Internal Function.\n",
    "    Call `func` with `a` as first argument swapping the axes to use extended\n",
    "    axis on functions that don't support it natively.\n",
    "    Returns result and a.shape with axis dims set to 1.\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : array_like\n",
    "        Input array or object that can be converted to an array.\n",
    "    func : callable\n",
    "        Reduction function capable of receiving a single axis argument.\n",
    "        It is called with `a` as first argument followed by `kwargs`.\n",
    "    w : array_like\n",
    "        Has the sample shape with a.shape.\n",
    "    kwargs : keyword arguments\n",
    "        additional keyword arguments to pass to `func`.\n",
    "    Returns\n",
    "    -------\n",
    "    result : tuple\n",
    "        Result of func(a, **kwargs) and a.shape with axis dims set to 1\n",
    "        which can be used to reshape the result to the same shape a ufunc with\n",
    "        keepdims=True would produce.\n",
    "    \"\"\"        \n",
    "    axis = kwargs.get('axis', None)\n",
    "    if axis is not None:\n",
    "        keepdim = list(a.shape)\n",
    "        nd = a.ndim\n",
    "        axis = _nx.normalize_axis_tuple(axis, nd)\n",
    "\n",
    "        for ax in axis:\n",
    "            keepdim[ax] = 1\n",
    "\n",
    "        if len(axis) == 1:\n",
    "            kwargs['axis'] = axis[0]\n",
    "        else:\n",
    "            keep = set(range(nd)) - set(axis)\n",
    "            nkeep = len(keep)\n",
    "            # swap axis that should not be reduced to front\n",
    "            for i, s in enumerate(sorted(keep)):\n",
    "                a = a.swapaxes(i, s)\n",
    "                w = w.swapaxes(i, s)\n",
    "            # merge reduced axis\n",
    "            a = a.reshape(a.shape[:nkeep] + (-1,))\n",
    "            w = w.reshape(a.shape[:nkeep] + (-1,))\n",
    "            kwargs['axis'] = -1\n",
    "        keepdim = tuple(keepdim)\n",
    "    else:\n",
    "        keepdim = (1,) * a.ndim\n",
    "\n",
    "    r = func(a, w, **kwargs)\n",
    "    return r, keepdim\n",
    "def _weighted_quantile_dispatcher(a, q, w, axis=None, out=None, overwrite_input=None,\n",
    "                         interpolation=None, keepdims=None):\n",
    "    return (a, q, out)\n",
    "\n",
    "@array_function_dispatch(_weighted_quantile_dispatcher)\n",
    "def weighted_quantile(a, q, w, axis=None, out=None, # new w\n",
    "             overwrite_input=False, interpolation='linear', keepdims=False):\n",
    "    \"\"\"\n",
    "    Compute the q-th weighted quantile of the data along the specified axis.\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : array_like\n",
    "        Input array or object that can be converted to an array.\n",
    "    q : array_like of float\n",
    "        Quantile or sequence of quantiles to compute, which must be between\n",
    "        0 and 1 inclusive.\n",
    "    w : array_like\n",
    "        The weights of sample. It must have the same shape with a or be a 1d array for broadcast.\n",
    "        When it's a 1d array, axis should be an integer and w.size == a.shape[axis].\n",
    "        If all elements in w are the same, this function works like np.quantile.\n",
    "    axis : {int, tuple of int, None}, optional\n",
    "        Axis or axes along which the quantiles are computed. The\n",
    "        default is to compute the quantile(s) along a flattened\n",
    "        version of the array.\n",
    "    out : ndarray, optional\n",
    "        Alternative output array in which to place the result. It must\n",
    "        have the same shape and buffer length as the expected output,\n",
    "        but the type (of the output) will be cast if necessary.\n",
    "    overwrite_input : bool, optional\n",
    "        If True, then allow the input array `a` to be modified by intermediate\n",
    "        calculations, to save memory. In this case, the contents of the input\n",
    "        `a` after this function completes is undefined.\n",
    "    interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
    "        This optional parameter specifies the interpolation method to\n",
    "        use when the desired quantile lies between two data points\n",
    "        ``i < j``:\n",
    "            * linear: ``i + (j - i) * fraction``, where ``fraction``\n",
    "              is the fractional part of the index surrounded by ``i``\n",
    "              and ``j``.\n",
    "            * lower: ``i``.\n",
    "            * higher: ``j``.\n",
    "            * nearest: ``i`` or ``j``, whichever is nearest.\n",
    "            * midpoint: ``(i + j) / 2``.\n",
    "    keepdims : bool, optional\n",
    "        If this is set to True, the axes which are reduced are left in\n",
    "        the result as dimensions with size one. With this option, the\n",
    "        result will broadcast correctly against the original array `a`.\n",
    "    Returns\n",
    "    -------\n",
    "    quantile : scalar or ndarray\n",
    "        If `q` is a single quantile and `axis=None`, then the result\n",
    "        is a scalar. If multiple quantiles are given, first axis of\n",
    "        the result corresponds to the quantiles. The other axes are\n",
    "        the axes that remain after the reduction of `a`. If the input\n",
    "        contains integers or floats smaller than ``float64``, the output\n",
    "        data-type is ``float64``. Otherwise, the output data-type is the\n",
    "        same as that of the input. If `out` is specified, that array is\n",
    "        returned instead.\n",
    "    See Also\n",
    "    --------\n",
    "    mean\n",
    "    percentile : equivalent to quantile, but with q in the range [0, 100].\n",
    "    median : equivalent to ``quantile(..., 0.5)``\n",
    "    nanquantile\n",
    "    Notes\n",
    "    -----\n",
    "    Given a vector ``V`` of length ``N``, the q-th quantile of\n",
    "    ``V`` is the value ``q`` of the way from the minimum to the\n",
    "    maximum in a sorted copy of ``V``. The values and distances of\n",
    "    the two nearest neighbors as well as the `interpolation` parameter\n",
    "    will determine the quantile if the normalized ranking does not\n",
    "    match the location of ``q`` exactly. This function is the same as\n",
    "    the median if ``q=0.5``, the same as the minimum if ``q=0.0`` and the\n",
    "    same as the maximum if ``q=1.0``.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> a = np.array([[10, 7, 4], [3, 2, 1]])\n",
    "    >>> a\n",
    "    array([[10,  7,  4],\n",
    "           [ 3,  2,  1]])\n",
    "    >>> np.quantile(a, 0.5)\n",
    "    3.5\n",
    "    >>> np.quantile(a, 0.5, axis=0)\n",
    "    array([6.5, 4.5, 2.5])\n",
    "    >>> np.quantile(a, 0.5, axis=1)\n",
    "    array([7.,  2.])\n",
    "    >>> np.quantile(a, 0.5, axis=1, keepdims=True)\n",
    "    array([[7.],\n",
    "           [2.]])\n",
    "    >>> m = np.quantile(a, 0.5, axis=0)\n",
    "    >>> out = np.zeros_like(m)\n",
    "    >>> np.quantile(a, 0.5, axis=0, out=out)\n",
    "    array([6.5, 4.5, 2.5])\n",
    "    >>> m\n",
    "    array([6.5, 4.5, 2.5])\n",
    "    >>> b = a.copy()\n",
    "    >>> np.quantile(b, 0.5, axis=1, overwrite_input=True)\n",
    "    array([7.,  2.])\n",
    "    >>> assert not np.all(a == b)\n",
    "    \"\"\"\n",
    "    a = np.asanyarray(a)\n",
    "    q = np.asanyarray(q)\n",
    "    w = np.asanyarray(w)\n",
    "    if w.shape!=a.shape:\n",
    "        if w.ndim != 1:\n",
    "            raise TypeError(\n",
    "                \"1D weights expected when shapes of a and weights differ.\")\n",
    "        if w.shape[0] != a.shape[axis]:\n",
    "            raise ValueError(\n",
    "                \"Length of weights not compatible with specified axis.\")\n",
    "        w = np.broadcast_to(w, (a.ndim-1)*(1,) + w.shape)\n",
    "        w = w.swapaxes(-1, axis)\n",
    "\n",
    "    if not _quantile_is_valid(q):\n",
    "        raise ValueError(\"Quantiles must be in the range [0, 1]\")\n",
    "    if not _weight_is_valid(w):\n",
    "        raise ValueError(\"All the weights must be > 0\")\n",
    "    return _weighted_quantile_unchecked(\n",
    "        a, q, w, axis, out, overwrite_input, interpolation, keepdims)\n",
    "\n",
    "\n",
    "def _weighted_quantile_unchecked(a, q, w, axis=None, out=None, overwrite_input=False,\n",
    "                        interpolation='linear', keepdims=False):\n",
    "    \"\"\"Assumes that q is in [0, 1], and is an ndarray\"\"\"\n",
    "    r, k = _weighted_ureduce(a, func=_weighted_quantile_ureduce_func,w=w, q=q, axis=axis, out=out,\n",
    "                    overwrite_input=overwrite_input,\n",
    "                    interpolation=interpolation)\n",
    "    if keepdims:\n",
    "        return r.reshape(q.shape + k)\n",
    "    else:\n",
    "        return r\n",
    "\n",
    "\n",
    "def _quantile_is_valid(q):\n",
    "    # avoid expensive reductions, relevant for arrays with < O(1000) elements\n",
    "    if q.ndim == 1 and q.size < 10:\n",
    "        for i in range(q.size):\n",
    "            if q[i] < 0.0 or q[i] > 1.0:\n",
    "                return False\n",
    "    else:\n",
    "        # faster than any()\n",
    "        if np.count_nonzero(q < 0.0) or np.count_nonzero(q > 1.0):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def _weight_is_valid(w):\n",
    "    # avoid expensive reductions, relevant for arrays with < O(1000) elements\n",
    "    if w.ndim == 1 and w.size < 10:\n",
    "        for i in range(w.size):\n",
    "            if w[i] <= 0.0:\n",
    "                return False\n",
    "    else:\n",
    "        # faster than any()\n",
    "        if np.count_nonzero(w <= 0.0):\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def _weighted_lerp(a, b, sa,sb,qsn, out=None):\n",
    "    \"\"\" Linearly interpolate from a to b by a factor of sk \n",
    "    The weighted quantile formulation is [X_k + (X_{k+1}-X_k)*(q*S_n-S_k)/(S_{k+1}-S_k)]\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : X_k\n",
    "    b : X_{k+1}\n",
    "    sa : S_k\n",
    "    sb : S_b\n",
    "    qsn : q*Sn\n",
    "    \"\"\"\n",
    "    diff_b_a = subtract(b, a)\n",
    "    # asanyarray is a stop-gap until gh-13105\n",
    "    t = (qsn-sa)/(sb-sa)\n",
    "    lerp_interpolation = asanyarray(add(a, diff_b_a*t, out=out))\n",
    "    subtract(b, diff_b_a * (1 - t), out=lerp_interpolation, where=t>=0.5)\n",
    "    if lerp_interpolation.ndim == 0 and out is None:\n",
    "        lerp_interpolation = lerp_interpolation[()]  # unpack 0d arrays\n",
    "    return lerp_interpolation\n",
    "\n",
    "def _find_weighted_index(sk,qsn,interpolation='linear'):\n",
    "    \n",
    "    dim = sk.shape # (N, d1, d2,..., dk)\n",
    "    Nx = dim[0]\n",
    "    _sk = sk.reshape(dim[0],-1) # (N,-1)\n",
    "    _qsn = qsn.reshape(qsn.shape[0],-1) # (q,-1)\n",
    "    indices = []\n",
    "    \n",
    "    for  j in range(_qsn.shape[1]):\n",
    "        k = 0\n",
    "        for i in range(_qsn.shape[0]):\n",
    "            qsn_j = _qsn[i,j]\n",
    "            sk_j = _sk[:,j]\n",
    "            # find Sk\n",
    "            while(True):\n",
    "                if qsn_j==sk_j[k]:\n",
    "                    indices.append(k)\n",
    "                    break\n",
    "                elif sk_j[k] < qsn_j < sk_j[k+1]:\n",
    "                    if interpolation == 'lower':\n",
    "                        indices.append(k)\n",
    "                    elif interpolation == 'higher':\n",
    "                        indices.append(k+1)\n",
    "                    elif interpolation == 'midpoint':\n",
    "                        indices.append(0.5*(2*k+1))\n",
    "                    elif interpolation == 'nearest':\n",
    "                        # np.round(0.5)==0 but np.round(1.5)==2.\n",
    "                        # To get the same result with np.quantile(), test if k==0 and |q*S_n-S_k| == |q*S_n*S_{k+1}|\n",
    "                        if qsn_j-sk_j[k] < sk_j[k+1]-qsn_j or (k==0 and qsn_j-sk_j[k] ==sk_j[k+1]-qsn_j):\n",
    "                            indices.append(k)\n",
    "                        else:\n",
    "                            indices.append(k+1)\n",
    "                    elif interpolation == 'linear':\n",
    "                        # just let the indices to be float temporally\n",
    "                        indices.append(0.5*(2*k+1))\n",
    "                    else:\n",
    "                        raise ValueError(\n",
    "                            \"interpolation can only be 'linear', 'lower' 'higher', \"\n",
    "                            \"'midpoint', or 'nearest'\")\n",
    "                    break\n",
    "                k = k+1\n",
    "    indices = np.asanyarray(indices).reshape(dim[1:]+(qsn.shape[0],))\n",
    "    indices = np.moveaxis(indices, -1, 0)\n",
    "    return indices\n",
    "    \n",
    "def _weighted_quantile_ureduce_func(a, w, q, axis=None, out=None, overwrite_input=False,\n",
    "                           interpolation='linear', keepdims=False):\n",
    "\n",
    "    # ufuncs cause 0d array results to decay to scalars (see gh-13105), which\n",
    "    # makes them problematic for __setitem__ and attribute access. As a\n",
    "    # workaround, we call this on the result of every ufunc on a possibly-0d\n",
    "    # array.\n",
    "    not_scalar = np.asanyarray\n",
    "    # prepare a for partitioning\n",
    "    if overwrite_input:\n",
    "        if axis is None:\n",
    "            ap = a.ravel()\n",
    "            wp = w.ravel()\n",
    "        else:\n",
    "            ap = a\n",
    "            wp = w\n",
    "    else:\n",
    "        if axis is None:\n",
    "            ap = a.flatten()\n",
    "            wp = w.flatten()\n",
    "        else:\n",
    "            ap = a.copy()\n",
    "            wp = w.copy()\n",
    "\n",
    "        \n",
    "    if axis is None:\n",
    "        axis = 0\n",
    "    d = q.ndim\n",
    "    if d > 2:\n",
    "        # The code below works fine for nd, but it might not have useful\n",
    "        # semantics. For now, keep the supported dimensions the same as it was\n",
    "        # before.\n",
    "        raise ValueError(\"q must be a scalar or 1d\")\n",
    "    \n",
    "    Nx = ap.shape[axis]\n",
    "    \n",
    "    # reshape to (Nx, d1,d2,...,dk)\n",
    "    ap = np.moveaxis(ap, axis, 0)\n",
    "    wp = np.moveaxis(wp, axis, 0)\n",
    "    # sort ap and wp to compute Sk\n",
    "    sorted_index = ap.argsort(axis=0)\n",
    "    ap = np.take_along_axis(ap, sorted_index, axis=0)\n",
    "    wp = np.take_along_axis(wp, sorted_index, axis=0) # (N, group)\n",
    "    \n",
    "    # compute Sk for k = 1,...,n and q*Sn\n",
    "    sk = np.asarray([k*wp[k,...]+(Nx-1)*sum(wp[:k,...],axis=0) for k in range(Nx)])\n",
    "    sn = sk[-1,...]\n",
    "    print(sn.shape)\n",
    "    \n",
    "    qp = np.atleast_1d(q)\n",
    "    sorted_index_q = qp.argsort(axis=0)\n",
    "    qp = np.take_along_axis(qp, sorted_index_q, axis=0)\n",
    "    qsn = qp.reshape((-1,)+(1,)*(sn.ndim))*sn # (q,d1,d2,...,dk)\n",
    "    print(qsn.shape)\n",
    "    return\n",
    "    # round fractional indices according to interpolation method\n",
    "    indices = _find_weighted_index(sk,qsn,interpolation)\n",
    "\n",
    "    if np.issubdtype(indices.dtype, np.integer):\n",
    "        # take the points along axis\n",
    "        if np.issubdtype(a.dtype, np.inexact):\n",
    "            n = np.isnan(ap[-1])\n",
    "        else:\n",
    "            # cannot contain nan\n",
    "            n = np.array(False, dtype=bool)          \n",
    "        r = np.take_along_axis(ap,indices,0)\n",
    "\n",
    "    else:\n",
    "        # weight the points above and below the indices\n",
    "        indices_below = not_scalar(floor(indices)).astype(intp)\n",
    "        indices_above = not_scalar(indices_below + 1)\n",
    "        indices_above[indices_above > Nx - 1] = Nx - 1\n",
    "        if np.issubdtype(a.dtype, np.inexact):\n",
    "            # may contain nan, which would sort to the end\n",
    "            n = np.isnan(ap[-1])\n",
    "        else:\n",
    "            # cannot contain nan\n",
    "            n = np.array(False, dtype=bool)\n",
    "\n",
    "        # get Xk, Xk+1, Sk, Sk+1 to do interpolation\n",
    "        x_below = np.take_along_axis(ap,indices_below,0)\n",
    "        x_above = np.take_along_axis(ap,indices_above,0)\n",
    "\n",
    "        if interpolation == 'midpoint':\n",
    "            r = 0.5*(x_below + x_above)\n",
    "        else:\n",
    "            s_below = np.take_along_axis(sk,indices_below,0)\n",
    "            s_above = np.take_along_axis(sk,indices_above,0)\n",
    "            r = _weighted_lerp(x_below, x_above, s_below,s_above,qsn, out=out)\n",
    "    # if any slice contained a nan, then all results on that slice are also nan\n",
    "    if np.any(n):\n",
    "        if r.ndim == 0 and out is None:\n",
    "            # can't write to a scalar\n",
    "            r = a.dtype.type(np.nan)\n",
    "        else:\n",
    "            r[..., n] = a.dtype.type(np.nan)\n",
    "    if d==0:\n",
    "        r[sorted_index_q] = r\n",
    "        return r[0]\n",
    "    else:\n",
    "        r[sorted_index_q] = r\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "param_dict = error_samples[0]\n",
    "a = param_dict['a']\n",
    "q = param_dict['q']\n",
    "w = param_dict['w']\n",
    "axis = param_dict['axis']\n",
    "out = param_dict['out']\n",
    "overwrite_input = param_dict['overwrite_input']\n",
    "interpolation = param_dict['interpolation']\n",
    "keepdims = param_dict['keepdims']\n",
    "weighted_quantile(a, q, w, axis=axis, out=out, overwrite_input=overwrite_input, interpolation=interpolation, keepdims=keepdims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(10,)\n",
      "(10,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(10,)\n",
      "(10,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(10,)\n",
      "(10,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(10,)\n",
      "(10,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(10,)\n",
      "(10,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(10,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.70311216 0.36330996 0.41850459 0.24488416 0.36330996 0.42428094\n",
      " 0.70311216 0.24488416 0.42428094 0.70311216]\n",
      "result_b [0.89942614 0.69836862 0.41850459 0.75343021 0.36330996 0.89942614\n",
      " 0.70311216 0.24488416 0.42428094 0.72029605]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.70311216 0.36330996 0.41850459 0.24488416 0.36330996 0.42428094\n",
      " 0.70311216 0.24488416 0.42428094 0.70311216]\n",
      "result_b [0.89942614 0.69836862 0.41850459 0.75343021 0.36330996 0.89942614\n",
      " 0.70311216 0.24488416 0.42428094 0.72029605]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.70311216 0.36330996 0.41850459 0.24488416 0.36330996 0.42428094\n",
      " 0.70311216 0.24488416 0.42428094 0.70311216]\n",
      "result_b [0.89942614 0.69836862 0.41850459 0.75343021 0.36330996 0.89942614\n",
      " 0.70311216 0.24488416 0.42428094 0.72029605]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.70311216 0.36330996 0.41850459 0.24488416 0.36330996 0.42428094\n",
      " 0.70311216 0.24488416 0.42428094 0.70311216]\n",
      "result_b [0.89942614 0.69836862 0.41850459 0.75343021 0.36330996 0.89942614\n",
      " 0.70311216 0.24488416 0.42428094 0.72029605]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.70311216 0.36330996 0.41850459 0.24488416 0.36330996 0.42428094\n",
      " 0.70311216 0.24488416 0.42428094 0.70311216]\n",
      "result_b [0.89942614 0.69836862 0.41850459 0.75343021 0.36330996 0.89942614\n",
      " 0.70311216 0.24488416 0.42428094 0.72029605]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.70311216 0.36330996 0.41850459 0.24488416 0.36330996 0.42428094\n",
      " 0.70311216 0.24488416 0.42428094 0.70311216]\n",
      "result_b [0.89942614 0.69836862 0.41850459 0.75343021 0.36330996 0.89942614\n",
      " 0.70311216 0.24488416 0.42428094 0.72029605]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.70311216 0.36330996 0.41850459 0.24488416 0.36330996 0.42428094\n",
      " 0.70311216 0.24488416 0.42428094 0.70311216]\n",
      "result_b [0.89942614 0.69836862 0.41850459 0.75343021 0.36330996 0.89942614\n",
      " 0.70311216 0.24488416 0.42428094 0.72029605]\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.71210303 0.36765655 0.42428094 0.24537966 0.36765655 0.42654671\n",
      " 0.71210303 0.24537966 0.42654671 0.71210303]\n",
      "result_b [0.9077476  0.70311216 0.42428094 0.78279071 0.36765655 0.9077476\n",
      " 0.71210303 0.24537966 0.42654671 0.75343021]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.71210303 0.36765655 0.42428094 0.24537966 0.36765655 0.42654671\n",
      " 0.71210303 0.24537966 0.42654671 0.71210303]\n",
      "result_b [0.9077476  0.70311216 0.42428094 0.78279071 0.36765655 0.9077476\n",
      " 0.71210303 0.24537966 0.42654671 0.75343021]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.71210303 0.36765655 0.42428094 0.24537966 0.36765655 0.42654671\n",
      " 0.71210303 0.24537966 0.42654671 0.71210303]\n",
      "result_b [0.9077476  0.70311216 0.42428094 0.78279071 0.36765655 0.9077476\n",
      " 0.71210303 0.24537966 0.42654671 0.75343021]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.71210303 0.36765655 0.42428094 0.24537966 0.36765655 0.42654671\n",
      " 0.71210303 0.24537966 0.42654671 0.71210303]\n",
      "result_b [0.9077476  0.70311216 0.42428094 0.78279071 0.36765655 0.9077476\n",
      " 0.71210303 0.24537966 0.42654671 0.75343021]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.71210303 0.36765655 0.42428094 0.24537966 0.36765655 0.42654671\n",
      " 0.71210303 0.24537966 0.42654671 0.71210303]\n",
      "result_b [0.9077476  0.70311216 0.42428094 0.78279071 0.36765655 0.9077476\n",
      " 0.71210303 0.24537966 0.42654671 0.75343021]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.71210303 0.36765655 0.42428094 0.24537966 0.36765655 0.42654671\n",
      " 0.71210303 0.24537966 0.42654671 0.71210303]\n",
      "result_b [0.9077476  0.70311216 0.42428094 0.78279071 0.36765655 0.9077476\n",
      " 0.71210303 0.24537966 0.42654671 0.75343021]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.71210303 0.36765655 0.42428094 0.24537966 0.36765655 0.42654671\n",
      " 0.71210303 0.24537966 0.42654671 0.71210303]\n",
      "result_b [0.9077476  0.70311216 0.42428094 0.78279071 0.36765655 0.9077476\n",
      " 0.71210303 0.24537966 0.42654671 0.75343021]\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.70760759 0.36548325 0.42139277 0.24513191 0.36548325 0.42541383\n",
      " 0.70760759 0.24513191 0.42541383 0.70760759]\n",
      "result_b [0.90358687 0.70074039 0.42139277 0.76811046 0.36548325 0.90358687\n",
      " 0.70760759 0.24513191 0.42541383 0.73686313]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.70760759 0.36548325 0.42139277 0.24513191 0.36548325 0.42541383\n",
      " 0.70760759 0.24513191 0.42541383 0.70760759]\n",
      "result_b [0.90358687 0.70074039 0.42139277 0.76811046 0.36548325 0.90358687\n",
      " 0.70760759 0.24513191 0.42541383 0.73686313]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.70760759 0.36548325 0.42139277 0.24513191 0.36548325 0.42541383\n",
      " 0.70760759 0.24513191 0.42541383 0.70760759]\n",
      "result_b [0.90358687 0.70074039 0.42139277 0.76811046 0.36548325 0.90358687\n",
      " 0.70760759 0.24513191 0.42541383 0.73686313]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.70760759 0.36548325 0.42139277 0.24513191 0.36548325 0.42541383\n",
      " 0.70760759 0.24513191 0.42541383 0.70760759]\n",
      "result_b [0.90358687 0.70074039 0.42139277 0.76811046 0.36548325 0.90358687\n",
      " 0.70760759 0.24513191 0.42541383 0.73686313]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.70760759 0.36548325 0.42139277 0.24513191 0.36548325 0.42541383\n",
      " 0.70760759 0.24513191 0.42541383 0.70760759]\n",
      "result_b [0.90358687 0.70074039 0.42139277 0.76811046 0.36548325 0.90358687\n",
      " 0.70760759 0.24513191 0.42541383 0.73686313]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.70760759 0.36548325 0.42139277 0.24513191 0.36548325 0.42541383\n",
      " 0.70760759 0.24513191 0.42541383 0.70760759]\n",
      "result_b [0.90358687 0.70074039 0.42139277 0.76811046 0.36548325 0.90358687\n",
      " 0.70760759 0.24513191 0.42541383 0.73686313]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.70760759 0.36548325 0.42139277 0.24513191 0.36548325 0.42541383\n",
      " 0.70760759 0.24513191 0.42541383 0.70760759]\n",
      "result_b [0.90358687 0.70074039 0.42139277 0.76811046 0.36548325 0.90358687\n",
      " 0.70760759 0.24513191 0.42541383 0.73686313]\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.71210303 0.36330996 0.41850459 0.24537966 0.36330996 0.42428094\n",
      " 0.71210303 0.24537966 0.42428094 0.71210303]\n",
      "result_b [0.9077476  0.69836862 0.41850459 0.75343021 0.36330996 0.89942614\n",
      " 0.71210303 0.24537966 0.42428094 0.72029605]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.71210303 0.36330996 0.41850459 0.24537966 0.36330996 0.42428094\n",
      " 0.71210303 0.24537966 0.42428094 0.71210303]\n",
      "result_b [0.9077476  0.69836862 0.41850459 0.75343021 0.36330996 0.89942614\n",
      " 0.71210303 0.24537966 0.42428094 0.72029605]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.71210303 0.36330996 0.41850459 0.24537966 0.36330996 0.42428094\n",
      " 0.71210303 0.24537966 0.42428094 0.71210303]\n",
      "result_b [0.9077476  0.69836862 0.41850459 0.75343021 0.36330996 0.89942614\n",
      " 0.71210303 0.24537966 0.42428094 0.72029605]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.71210303 0.36330996 0.41850459 0.24537966 0.36330996 0.42428094\n",
      " 0.71210303 0.24537966 0.42428094 0.71210303]\n",
      "result_b [0.9077476  0.69836862 0.41850459 0.75343021 0.36330996 0.89942614\n",
      " 0.71210303 0.24537966 0.42428094 0.72029605]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.71210303 0.36330996 0.41850459 0.24537966 0.36330996 0.42428094\n",
      " 0.71210303 0.24537966 0.42428094 0.71210303]\n",
      "result_b [0.9077476  0.69836862 0.41850459 0.75343021 0.36330996 0.89942614\n",
      " 0.71210303 0.24537966 0.42428094 0.72029605]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.71210303 0.36330996 0.41850459 0.24537966 0.36330996 0.42428094\n",
      " 0.71210303 0.24537966 0.42428094 0.71210303]\n",
      "result_b [0.9077476  0.69836862 0.41850459 0.75343021 0.36330996 0.89942614\n",
      " 0.71210303 0.24537966 0.42428094 0.72029605]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.71210303 0.36330996 0.41850459 0.24537966 0.36330996 0.42428094\n",
      " 0.71210303 0.24537966 0.42428094 0.71210303]\n",
      "result_b [0.9077476  0.69836862 0.41850459 0.75343021 0.36330996 0.89942614\n",
      " 0.71210303 0.24537966 0.42428094 0.72029605]\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.71133564 0.36539293 0.42080104 0.245223   0.36539293 0.4243243\n",
      " 0.71133564 0.245223   0.4243243  0.71133564]\n",
      "result_b [0.90625807 0.70041003 0.42080104 0.76005999 0.36539293 0.90204313\n",
      " 0.71133564 0.245223   0.4243243  0.72669086]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.71133564 0.36539293 0.42080104 0.245223   0.36539293 0.4243243\n",
      " 0.71133564 0.245223   0.4243243  0.71133564]\n",
      "result_b [0.90625807 0.70041003 0.42080104 0.76005999 0.36539293 0.90204313\n",
      " 0.71133564 0.245223   0.4243243  0.72669086]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.71133564 0.36539293 0.42080104 0.245223   0.36539293 0.4243243\n",
      " 0.71133564 0.245223   0.4243243  0.71133564]\n",
      "result_b [0.90625807 0.70041003 0.42080104 0.76005999 0.36539293 0.90204313\n",
      " 0.71133564 0.245223   0.4243243  0.72669086]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.71133564 0.36539293 0.42080104 0.245223   0.36539293 0.4243243\n",
      " 0.71133564 0.245223   0.4243243  0.71133564]\n",
      "result_b [0.90625807 0.70041003 0.42080104 0.76005999 0.36539293 0.90204313\n",
      " 0.71133564 0.245223   0.4243243  0.72669086]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.71133564 0.36539293 0.42080104 0.245223   0.36539293 0.4243243\n",
      " 0.71133564 0.245223   0.4243243  0.71133564]\n",
      "result_b [0.90625807 0.70041003 0.42080104 0.76005999 0.36539293 0.90204313\n",
      " 0.71133564 0.245223   0.4243243  0.72669086]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.71133564 0.36539293 0.42080104 0.245223   0.36539293 0.4243243\n",
      " 0.71133564 0.245223   0.4243243  0.71133564]\n",
      "result_b [0.90625807 0.70041003 0.42080104 0.76005999 0.36539293 0.90204313\n",
      " 0.71133564 0.245223   0.4243243  0.72669086]\n",
      "(10,)\n",
      "Error occurs!\n",
      "result_a [0.71133564 0.36539293 0.42080104 0.245223   0.36539293 0.4243243\n",
      " 0.71133564 0.245223   0.4243243  0.71133564]\n",
      "result_b [0.90625807 0.70041003 0.42080104 0.76005999 0.36539293 0.90204313\n",
      " 0.71133564 0.245223   0.4243243  0.72669086]\n"
     ]
    }
   ],
   "source": [
    "from  itertools import permutations\n",
    "import pickle\n",
    "\n",
    "def add_sample(a,test_sample,out=None,overwrite_input=False,keepdims=False):\n",
    "    w = np.ones_like(a)\n",
    "    interpolation_list = ['lower','higher','midpoint','nearest','linear']\n",
    "    q_list = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,np.random.rand(10)]\n",
    "    axis_list = [None,0,(0,-1)]\n",
    "    for d in permutations(tuple(range(a.ndim))):\n",
    "        axis_list.append(d)\n",
    "    for interpolation in interpolation_list:\n",
    "        for q in q_list:\n",
    "            for axis in axis_list:\n",
    "                d ={'a':a,\n",
    "                    'q':q,\n",
    "                    'w':w,\n",
    "                    'axis':axis,\n",
    "                    'out':out,\n",
    "                    'overwrite_input':overwrite_input,\n",
    "                    'interpolation':interpolation,\n",
    "                    'keepdims':keepdims}\n",
    "                test_sample.append(d)\n",
    "def check_equal(param_list,error_samples):\n",
    "    f = True\n",
    "    for param_dict in param_list:\n",
    "        a = param_dict['a']\n",
    "        q = param_dict['q']\n",
    "        w = param_dict['w']\n",
    "        axis = param_dict['axis']\n",
    "        out = param_dict['out']\n",
    "        overwrite_input = param_dict['overwrite_input']\n",
    "        interpolation = param_dict['interpolation']\n",
    "        keepdims = param_dict['keepdims']\n",
    "        \n",
    "        result_a = weighted_quantile(a, q, w, axis=axis, out=out, overwrite_input=overwrite_input, interpolation=interpolation, keepdims=keepdims)\n",
    "        result_b = np.quantile(a, q, axis=axis, out=out, overwrite_input=overwrite_input, interpolation=interpolation, keepdims=keepdims)\n",
    "        if not np.allclose(result_a,result_b,equal_nan=True):\n",
    "            error_samples.append(param_dict)\n",
    "            print(\"Error occurs!\")\n",
    "            print(\"result_a\",result_a)\n",
    "            print(\"result_b\",result_b)\n",
    "            f = False\n",
    "    if f:\n",
    "        print(\"Pass!\")\n",
    "\n",
    "\n",
    "# if __name__==\"__main__\":\n",
    "#     with open(\"test_sample.pkl\",'rb') as f:\n",
    "#         test_sample = pickle.load(f)\n",
    "#     error_samples = []\n",
    "#     check_equal(test_sample,error_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,3,8,4,6,1,3,4,5,6,9,7]).reshape(2,2,3)\n",
    "add_sample(a,test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurs!\n",
      "result_a [3 1 5 4 3 3 1 3 5 6]\n",
      "result_b [4 6 6 4 3 6 1 3 5 6]\n",
      "Error occurs!\n",
      "result_a [[3 4]\n",
      " [1 1]\n",
      " [3 6]\n",
      " [3 4]\n",
      " [3 4]\n",
      " [3 4]\n",
      " [1 1]\n",
      " [3 4]\n",
      " [3 6]\n",
      " [4 6]]\n",
      "result_b [[3 6]\n",
      " [4 6]\n",
      " [4 6]\n",
      " [3 4]\n",
      " [3 4]\n",
      " [4 6]\n",
      " [1 1]\n",
      " [3 4]\n",
      " [3 6]\n",
      " [4 6]]\n",
      "Error occurs!\n",
      "result_a [3 1 5 4 3 3 1 3 5 6]\n",
      "result_b [4 6 6 4 3 6 1 3 5 6]\n",
      "Error occurs!\n",
      "result_a [3 1 5 4 3 3 1 3 5 6]\n",
      "result_b [4 6 6 4 3 6 1 3 5 6]\n",
      "Error occurs!\n",
      "result_a [3 1 5 4 3 3 1 3 5 6]\n",
      "result_b [4 6 6 4 3 6 1 3 5 6]\n",
      "Error occurs!\n",
      "result_a [3 1 5 4 3 3 1 3 5 6]\n",
      "result_b [4 6 6 4 3 6 1 3 5 6]\n",
      "Error occurs!\n",
      "result_a [3 1 5 4 3 3 1 3 5 6]\n",
      "result_b [4 6 6 4 3 6 1 3 5 6]\n",
      "Error occurs!\n",
      "result_a [3 1 5 4 3 3 1 3 5 6]\n",
      "result_b [4 6 6 4 3 6 1 3 5 6]\n",
      "Error occurs!\n",
      "result_a [3 3 6 4 3 4 3 4 6 7]\n",
      "result_b [5 6 7 4 3 6 3 4 6 7]\n",
      "Error occurs!\n",
      "result_a [[3 6]\n",
      " [3 4]\n",
      " [4 6]\n",
      " [3 6]\n",
      " [3 6]\n",
      " [3 6]\n",
      " [3 4]\n",
      " [3 6]\n",
      " [4 6]\n",
      " [5 7]]\n",
      "result_b [[4 6]\n",
      " [5 7]\n",
      " [5 7]\n",
      " [3 6]\n",
      " [3 6]\n",
      " [5 7]\n",
      " [3 4]\n",
      " [3 6]\n",
      " [4 6]\n",
      " [5 7]]\n",
      "Error occurs!\n",
      "result_a [3 3 6 4 3 4 3 4 6 7]\n",
      "result_b [5 6 7 4 3 6 3 4 6 7]\n",
      "Error occurs!\n",
      "result_a [3 3 6 4 3 4 3 4 6 7]\n",
      "result_b [5 6 7 4 3 6 3 4 6 7]\n",
      "Error occurs!\n",
      "result_a [3 3 6 4 3 4 3 4 6 7]\n",
      "result_b [5 6 7 4 3 6 3 4 6 7]\n",
      "Error occurs!\n",
      "result_a [3 3 6 4 3 4 3 4 6 7]\n",
      "result_b [5 6 7 4 3 6 3 4 6 7]\n",
      "Error occurs!\n",
      "result_a [3 3 6 4 3 4 3 4 6 7]\n",
      "result_b [5 6 7 4 3 6 3 4 6 7]\n",
      "Error occurs!\n",
      "result_a [3 3 6 4 3 4 3 4 6 7]\n",
      "result_b [5 6 7 4 3 6 3 4 6 7]\n",
      "Error occurs!\n",
      "result_a [3.  2.  5.5 4.  3.  3.5 2.  3.5 5.5 6.5]\n",
      "result_b [4.5 6.  6.5 4.  3.  6.  2.  3.5 5.5 6.5]\n",
      "Error occurs!\n",
      "result_a [[3.  5. ]\n",
      " [2.  2.5]\n",
      " [3.5 6. ]\n",
      " [3.  5. ]\n",
      " [3.  5. ]\n",
      " [3.  5. ]\n",
      " [2.  2.5]\n",
      " [3.  5. ]\n",
      " [3.5 6. ]\n",
      " [4.5 6.5]]\n",
      "result_b [[3.5 6. ]\n",
      " [4.5 6.5]\n",
      " [4.5 6.5]\n",
      " [3.  5. ]\n",
      " [3.  5. ]\n",
      " [4.5 6.5]\n",
      " [2.  2.5]\n",
      " [3.  5. ]\n",
      " [3.5 6. ]\n",
      " [4.5 6.5]]\n",
      "Error occurs!\n",
      "result_a [3.  2.  5.5 4.  3.  3.5 2.  3.5 5.5 6.5]\n",
      "result_b [4.5 6.  6.5 4.  3.  6.  2.  3.5 5.5 6.5]\n",
      "Error occurs!\n",
      "result_a [3.  2.  5.5 4.  3.  3.5 2.  3.5 5.5 6.5]\n",
      "result_b [4.5 6.  6.5 4.  3.  6.  2.  3.5 5.5 6.5]\n",
      "Error occurs!\n",
      "result_a [3.  2.  5.5 4.  3.  3.5 2.  3.5 5.5 6.5]\n",
      "result_b [4.5 6.  6.5 4.  3.  6.  2.  3.5 5.5 6.5]\n",
      "Error occurs!\n",
      "result_a [3.  2.  5.5 4.  3.  3.5 2.  3.5 5.5 6.5]\n",
      "result_b [4.5 6.  6.5 4.  3.  6.  2.  3.5 5.5 6.5]\n",
      "Error occurs!\n",
      "result_a [3.  2.  5.5 4.  3.  3.5 2.  3.5 5.5 6.5]\n",
      "result_b [4.5 6.  6.5 4.  3.  6.  2.  3.5 5.5 6.5]\n",
      "Error occurs!\n",
      "result_a [3.  2.  5.5 4.  3.  3.5 2.  3.5 5.5 6.5]\n",
      "result_b [4.5 6.  6.5 4.  3.  6.  2.  3.5 5.5 6.5]\n",
      "Error occurs!\n",
      "result_a [4 6]\n",
      "result_b [3 6]\n",
      "Error occurs!\n",
      "result_a [8 9]\n",
      "result_b [5 7]\n",
      "Error occurs!\n",
      "result_a [3 3 5 4 3 4 3 4 5 7]\n",
      "result_b [4 6 6 4 3 6 3 4 5 7]\n",
      "Error occurs!\n",
      "result_a [[[1 3 5]\n",
      "  [4 6 1]]\n",
      "\n",
      " [[1 3 5]\n",
      "  [4 6 1]]\n",
      "\n",
      " [[3 4 8]\n",
      "  [6 9 7]]\n",
      "\n",
      " [[1 3 5]\n",
      "  [4 6 1]]\n",
      "\n",
      " [[1 3 5]\n",
      "  [4 6 1]]\n",
      "\n",
      " [[1 3 5]\n",
      "  [4 6 1]]\n",
      "\n",
      " [[1 3 5]\n",
      "  [4 6 1]]\n",
      "\n",
      " [[1 3 5]\n",
      "  [4 6 1]]\n",
      "\n",
      " [[3 4 8]\n",
      "  [6 9 7]]\n",
      "\n",
      " [[3 4 8]\n",
      "  [6 9 7]]]\n",
      "result_b [[[1 3 5]\n",
      "  [4 6 1]]\n",
      "\n",
      " [[3 4 8]\n",
      "  [6 9 7]]\n",
      "\n",
      " [[3 4 8]\n",
      "  [6 9 7]]\n",
      "\n",
      " [[1 3 5]\n",
      "  [4 6 1]]\n",
      "\n",
      " [[1 3 5]\n",
      "  [4 6 1]]\n",
      "\n",
      " [[3 4 8]\n",
      "  [6 9 7]]\n",
      "\n",
      " [[1 3 5]\n",
      "  [4 6 1]]\n",
      "\n",
      " [[1 3 5]\n",
      "  [4 6 1]]\n",
      "\n",
      " [[3 4 8]\n",
      "  [6 9 7]]\n",
      "\n",
      " [[3 4 8]\n",
      "  [6 9 7]]]\n",
      "Error occurs!\n",
      "result_a [[3 4]\n",
      " [3 4]\n",
      " [4 6]\n",
      " [3 6]\n",
      " [3 4]\n",
      " [3 6]\n",
      " [3 4]\n",
      " [3 6]\n",
      " [4 6]\n",
      " [5 7]]\n",
      "result_b [[3 6]\n",
      " [4 6]\n",
      " [5 7]\n",
      " [3 6]\n",
      " [3 4]\n",
      " [5 7]\n",
      " [3 4]\n",
      " [3 6]\n",
      " [4 6]\n",
      " [5 7]]\n",
      "Error occurs!\n",
      "result_a [3 3 5 4 3 4 3 4 5 7]\n",
      "result_b [4 6 6 4 3 6 3 4 5 7]\n",
      "Error occurs!\n",
      "result_a [3 3 5 4 3 4 3 4 5 7]\n",
      "result_b [4 6 6 4 3 6 3 4 5 7]\n",
      "Error occurs!\n",
      "result_a [3 3 5 4 3 4 3 4 5 7]\n",
      "result_b [4 6 6 4 3 6 3 4 5 7]\n",
      "Error occurs!\n",
      "result_a [3 3 5 4 3 4 3 4 5 7]\n",
      "result_b [4 6 6 4 3 6 3 4 5 7]\n",
      "Error occurs!\n",
      "result_a [3 3 5 4 3 4 3 4 5 7]\n",
      "result_b [4 6 6 4 3 6 3 4 5 7]\n",
      "Error occurs!\n",
      "result_a [3 3 5 4 3 4 3 4 5 7]\n",
      "result_b [4 6 6 4 3 6 3 4 5 7]\n",
      "Error occurs!\n",
      "result_a [3.         2.95773069 5.04386911 4.         3.         3.90129783\n",
      " 2.95773069 3.90129783 5.04386911 6.7796003 ]\n",
      "result_b [4.01138033 6.         6.24569001 4.         3.         6.\n",
      " 2.95773069 3.90129783 5.04386911 6.7796003 ]\n",
      "Error occurs!\n",
      "result_a [[[1.4842896  3.2421448  5.7264344 ]\n",
      "  [4.4842896  6.7264344  2.45286879]]\n",
      "\n",
      " [[1.3597937  3.17989685 5.53969055]\n",
      "  [4.3597937  6.53969055 2.0793811 ]]\n",
      "\n",
      " [[2.09888529 3.54944265 6.64832794]\n",
      "  [5.09888529 7.64832794 4.29665588]]\n",
      "\n",
      " [[1.7851715  3.39258575 6.17775725]\n",
      "  [4.7851715  7.17775725 3.3555145 ]]\n",
      "\n",
      " [[1.4842896  3.2421448  5.7264344 ]\n",
      "  [4.4842896  6.7264344  2.45286879]]\n",
      "\n",
      " [[1.70932688 3.35466344 6.06399032]\n",
      "  [4.70932688 7.06399032 3.12798063]]\n",
      "\n",
      " [[1.3597937  3.17989685 5.53969055]\n",
      "  [4.3597937  6.53969055 2.0793811 ]]\n",
      "\n",
      " [[1.70932688 3.35466344 6.06399032]\n",
      "  [4.70932688 7.06399032 3.12798063]]\n",
      "\n",
      " [[2.09888529 3.54944265 6.64832794]\n",
      "  [5.09888529 7.64832794 4.29665588]]\n",
      "\n",
      " [[2.59629096 3.79814548 7.39443644]\n",
      "  [5.59629096 8.39443644 5.78887289]]]\n",
      "result_b [[[1.91116006 3.45558003 6.36674009]\n",
      "  [4.91116006 7.36674009 3.73348018]]\n",
      "\n",
      " [[2.37301018 3.68650509 7.05951527]\n",
      "  [5.37301018 8.05951527 5.11903054]]\n",
      "\n",
      " [[2.49921637 3.74960818 7.24882455]\n",
      "  [5.49921637 8.24882455 5.4976491 ]]\n",
      "\n",
      " [[1.7851715  3.39258575 6.17775725]\n",
      "  [4.7851715  7.17775725 3.3555145 ]]\n",
      "\n",
      " [[1.4842896  3.2421448  5.7264344 ]\n",
      "  [4.4842896  6.7264344  2.45286879]]\n",
      "\n",
      " [[2.42977888 3.71488944 7.14466832]\n",
      "  [5.42977888 8.14466832 5.28933663]]\n",
      "\n",
      " [[1.3597937  3.17989685 5.53969055]\n",
      "  [4.3597937  6.53969055 2.0793811 ]]\n",
      "\n",
      " [[1.70932688 3.35466344 6.06399032]\n",
      "  [4.70932688 7.06399032 3.12798063]]\n",
      "\n",
      " [[2.09888529 3.54944265 6.64832794]\n",
      "  [5.09888529 7.64832794 4.29665588]]\n",
      "\n",
      " [[2.59629096 3.79814548 7.39443644]\n",
      "  [5.59629096 8.39443644 5.78887289]]]\n",
      "Error occurs!\n",
      "result_a [[3.         4.42144799]\n",
      " [2.79896849 3.69845274]\n",
      " [3.74721323 6.        ]\n",
      " [3.         5.9258575 ]\n",
      " [3.         4.42144799]\n",
      " [3.         5.54663439]\n",
      " [2.79896849 3.69845274]\n",
      " [3.         5.54663439]\n",
      " [3.74721323 6.        ]\n",
      " [4.99072741 6.99072741]]\n",
      "result_b [[3.27790015 6.        ]\n",
      " [4.43252545 6.43252545]\n",
      " [4.74804091 6.74804091]\n",
      " [3.         5.9258575 ]\n",
      " [3.         4.42144799]\n",
      " [4.57444719 6.57444719]\n",
      " [2.79896849 3.69845274]\n",
      " [3.         5.54663439]\n",
      " [3.74721323 6.        ]\n",
      " [4.99072741 6.99072741]]\n",
      "Error occurs!\n",
      "result_a [3.         2.95773069 5.04386911 4.         3.         3.90129783\n",
      " 2.95773069 3.90129783 5.04386911 6.7796003 ]\n",
      "result_b [4.01138033 6.         6.24569001 4.         3.         6.\n",
      " 2.95773069 3.90129783 5.04386911 6.7796003 ]\n",
      "Error occurs!\n",
      "result_a [3.         2.95773069 5.04386911 4.         3.         3.90129783\n",
      " 2.95773069 3.90129783 5.04386911 6.7796003 ]\n",
      "result_b [4.01138033 6.         6.24569001 4.         3.         6.\n",
      " 2.95773069 3.90129783 5.04386911 6.7796003 ]\n",
      "Error occurs!\n",
      "result_a [3.         2.95773069 5.04386911 4.         3.         3.90129783\n",
      " 2.95773069 3.90129783 5.04386911 6.7796003 ]\n",
      "result_b [4.01138033 6.         6.24569001 4.         3.         6.\n",
      " 2.95773069 3.90129783 5.04386911 6.7796003 ]\n",
      "Error occurs!\n",
      "result_a [3.         2.95773069 5.04386911 4.         3.         3.90129783\n",
      " 2.95773069 3.90129783 5.04386911 6.7796003 ]\n",
      "result_b [4.01138033 6.         6.24569001 4.         3.         6.\n",
      " 2.95773069 3.90129783 5.04386911 6.7796003 ]\n",
      "Error occurs!\n",
      "result_a [3.         2.95773069 5.04386911 4.         3.         3.90129783\n",
      " 2.95773069 3.90129783 5.04386911 6.7796003 ]\n",
      "result_b [4.01138033 6.         6.24569001 4.         3.         6.\n",
      " 2.95773069 3.90129783 5.04386911 6.7796003 ]\n",
      "Error occurs!\n",
      "result_a [3.         2.95773069 5.04386911 4.         3.         3.90129783\n",
      " 2.95773069 3.90129783 5.04386911 6.7796003 ]\n",
      "result_b [4.01138033 6.         6.24569001 4.         3.         6.\n",
      " 2.95773069 3.90129783 5.04386911 6.7796003 ]\n"
     ]
    }
   ],
   "source": [
    "error_samples = []\n",
    "check_equal(test_sample,error_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
